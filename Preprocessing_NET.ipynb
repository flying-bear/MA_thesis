{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "025733f7-1966-465f-a4c7-9f7bd9c8784c",
   "metadata": {
    "id": "025733f7-1966-465f-a4c7-9f7bd9c8784c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#! pip install matplotlib spacy nltk gensim numpy scipy scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b166876c-99a7-4c41-95e1-04c7dddd31fb",
   "metadata": {
    "id": "b166876c-99a7-4c41-95e1-04c7dddd31fb",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!python -m spacy download de_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "73e86e43-b92b-479a-86c1-4c392505f00e",
   "metadata": {
    "id": "73e86e43-b92b-479a-86c1-4c392505f00e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!curl -O https://int-emb-glove-de-wiki.s3.eu-central-1.amazonaws.com/vectors.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "06c6f375-80aa-4d55-b8b7-cfea2ba003ba",
   "metadata": {
    "id": "06c6f375-80aa-4d55-b8b7-cfea2ba003ba",
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!curl -O https://int-emb-glove-de-wiki.s3.eu-central-1.amazonaws.com/vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "08ceed31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python3(64044) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/galina.ryazanskaya/miniconda3/lib/python3.9/site-packages (1.4.3)\n",
      "Requirement already satisfied: chardet in /Users/galina.ryazanskaya/miniconda3/lib/python3.9/site-packages (5.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/galina.ryazanskaya/miniconda3/lib/python3.9/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/galina.ryazanskaya/miniconda3/lib/python3.9/site-packages (from pandas) (1.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/galina.ryazanskaya/miniconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/galina.ryazanskaya/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c1be30c0-3ca8-413b-b859-853a67e7cca5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1be30c0-3ca8-413b-b859-853a67e7cca5",
    "outputId": "0a94812a-83f9-4c92-e8c4-1c354eeef1d7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/galina.ryazanskaya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/galina.ryazanskaya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import os\n",
    "import chardet\n",
    "\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d15fce5d-9f08-4bb3-b6fa-bd3a9f821e07",
   "metadata": {
    "id": "d15fce5d-9f08-4bb3-b6fa-bd3a9f821e07",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  Function to flatten elements of different lists in one list of lists 'l' into a single list\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7635caa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# change your directories here\n",
    "IN_DIR = '/Users/galina.ryazanskaya/Downloads/thesis?/code?/transcripts_NET/in/' \n",
    "OUT_DIR_TRANSCRIPTS = '/Users/galina.ryazanskaya/Downloads/thesis?/code?/transcripts_NET/out/'\n",
    "OUT_DIR = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4a6228-3001-4e5d-b0ac-95978daa8100",
   "metadata": {
    "id": "dc4a6228-3001-4e5d-b0ac-95978daa8100"
   },
   "source": [
    "<h1>Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045c5635-9738-4869-9be8-f29f427e7c36",
   "metadata": {
    "id": "045c5635-9738-4869-9be8-f29f427e7c36"
   },
   "source": [
    "<h3>Preparing preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "cbd779f6-57ea-4330-a489-d06b0964d8d6",
   "metadata": {
    "id": "cbd779f6-57ea-4330-a489-d06b0964d8d6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to detect the encoding of a file\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        detector = chardet.universaldetector.UniversalDetector()\n",
    "        for line in f:\n",
    "            detector.feed(line)\n",
    "            if detector.done:\n",
    "                break\n",
    "        detector.close()\n",
    "        return detector.result['encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8ca9e5ef-4572-461b-960a-87719df13aac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ca9e5ef-4572-461b-960a-87719df13aac",
    "outputId": "7a37e427-8bb9-4692-dd43-f24681fad558",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define list of stopwords and fillers\n",
    "stopwords = stopwords.words('german')\n",
    "fillers = ['Ja', 'ja', 'Joa', 'joa', 'Ähm', 'ähm', 'Äh', 'äh', 'Oh', 'oh', 'Ohje', 'ohje',  'Hm', 'hm', 'Mh', 'mh', 'Mhm', 'mhm', 'Na', 'na', 'Naja', 'naja', 'Ne', 'ne', 'EM', 'em', 'Ehm', 'ehm', '[unv]', '(...)', '(..)', '(.)', '[...]', '[..]', '[.]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a7f9bcbb-203b-457e-9db0-ebc181e189a8",
   "metadata": {
    "id": "a7f9bcbb-203b-457e-9db0-ebc181e189a8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define dictionary of encoding errors to use in replace_chars function\n",
    "\n",
    "encoding_errors_dict = {'Ã¼':'ü', 'Ãœ':'Ü', 'Ã¤':'ä', 'Ã„':'Ä', 'Ã¶':'ö', 'Ã–':'Ö', 'ÃŸ':'ß', 'Ÿ':'ü', '§':'ß', '€':'ä', 'Š':'ä', 'š':'ö', 'д': 'ä', 'ь':'ü', 'ц': 'ö', 'Я': 'ß', 'Д': 'Ä', 'Ь': 'Ü', 'Ц': 'Ö', 'й': 'é', 'Й': 'É', 'б': 'à', 'Б': 'À'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51f34d5-f0f3-438c-87c7-988e8f34de7a",
   "metadata": {
    "id": "f51f34d5-f0f3-438c-87c7-988e8f34de7a"
   },
   "source": [
    "<h3>All preprocessing functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c07c7fa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "punct = '\\!\"#$%&\\'\\(\\)\\*\\+,\\-\\./:;<=>\\?@[\\\\]^_`{|}~\\^„“/…'\n",
    "\n",
    "def test_unicode(text):\n",
    "    non_unicode = re.findall(f'[^A-Za-zÀ-ž0-9\\\\n {punct}]', text)\n",
    "    return not bool(non_unicode), non_unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "6ab03a0d-6231-4190-b4a6-62f49439441b",
   "metadata": {
    "id": "6ab03a0d-6231-4190-b4a6-62f49439441b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  Function designed to replace specific characters in a given text with corresponding replacement characters defined in a dictionary (or mapping)\n",
    "def replace_chars(text, char_map):\n",
    "    for char in char_map:\n",
    "        text = text.replace(char, char_map[char])\n",
    "    return text\n",
    "\n",
    "def multiple_replace(text, rep_dict):\n",
    "    pattern = re.compile(\"|\".join([re.escape(k) for k in rep_dict]), flags=re.DOTALL)\n",
    "    return pattern.sub(lambda x: rep_dict[x.group(0)], text)\n",
    "\n",
    "#Remove timestamps\n",
    "def remove_timestamps(text):\n",
    "    return re.sub('#\\d\\d:\\d\\d:\\d\\d-\\d#', '', text)\n",
    "\n",
    "# function to take a text, tokenize it, preprocess, remove stopwords\n",
    "def clean_stopwords(text, stopwords=[]):\n",
    "    tokens = nltk.word_tokenize(text) # tokenize text\n",
    "    tokens = [w for w in tokens if not w in stopwords] # remove stopwords\n",
    "    text_cleaned = ' '.join(tokens)\n",
    "    return text_cleaned\n",
    "\n",
    "# function to take a text, tokenize it, preprocess, remove fillers\n",
    "def clean_fillers(text, fillers=[]):\n",
    "    tokens = nltk.word_tokenize(text) # tokenize text\n",
    "    tokens = [w for w in tokens if not w in fillers] # remove fillers\n",
    "    text_cleaned = ' '.join(tokens)\n",
    "    return text_cleaned\n",
    "\n",
    "def remove_comma_space(text):\n",
    "    text = text.replace(', ', ' ')\n",
    "    return text\n",
    "\n",
    "def remove_hanging_punct(text):\n",
    "    text = re.sub('\\?+', '?', text)\n",
    "    text = text.replace('. .', '.').replace('. ,', '.').replace(': .', ':').replace(' .', '.')\n",
    "    if text.startswith('.'):\n",
    "        text = text.strip('. ')\n",
    "    text = re.sub('\\s+([\\.\\,\\:\\?\\(\\)!\\[\\]])', r\"\\g<1>\", text)\n",
    "    text = re.sub(':\\s+, ', ': ', text)\n",
    "    return text\n",
    "\n",
    "def remove_unwanted_punct(text):\n",
    "    text = re.sub(\"\"\"[\\(\\[]\\.+[\\)\\]]|\\[ ?unv\\.?]|['`«»е]|\\(? ?…\\)?\"\"\", '', text)\n",
    "    text = text.replace('„', '\"').replace('“', '\"')\n",
    "    return text\n",
    "\n",
    "def remove_dots(text):\n",
    "    text = text.replace('...', '.').replace('..', '.')\n",
    "    return text\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    text = re.sub('[ \\t]+', ' ', text)\n",
    "    text = re.sub('\\n+', '\\n', text)\n",
    "    return text\n",
    "\n",
    "def fix_questions(text):\n",
    "    q_errors = {\n",
    "        'T:\\n': '',\n",
    "        'P:\\n': '',\n",
    "        'T: Hat sich das im Nachhinein gelöst? \\nP:' : '',\n",
    "        'T: Klappt das im Traum dass sie sich dann auch manchmal ein bisschen zur Wehr setzen? \\nP:': '', \n",
    "        'T: Was ist dann da? \\nP:': '',\n",
    "        'T: Sind das ganz bunte Bilder? \\nP:': '',\n",
    "        \n",
    "\n",
    "        'T: Fällt Ihnen eine Situation ein in der Sie Freude erlebt haben?': 'T: Schildern Sie eine Situation in der Sie Freude empfunden haben.', \n",
    "        'T: Fällt Ihnen eine Situation ein in der Sie Wut erlebt haben?': 'T: Schildern Sie eine Situation in der Sie Wut empfunden haben.', \n",
    "        'T: Fällt Ihnen eine Situation ein in der Sie Angst erlebt haben?': 'T: Schildern Sie eine Situation in der Sie Angst empfunden haben.', \n",
    "        'T: Fällt Ihnen eine Situation ein in der Sie Traurigkeit erlebt haben?': 'T: Schildern Sie eine Situation in der Sie Traurigkeit empfunden haben.', \n",
    "        'T: Fällt Ihnen eine Situation ein in der Sie Freude empfunden haben?': 'T: Schildern Sie eine Situation in der Sie Freude empfunden haben.', \n",
    "        'T: Fällt Ihnen eine Situation ein in der Sie Wut empfunden haben?': 'T: Schildern Sie eine Situation in der Sie Wut empfunden haben.', \n",
    "        'T: Fällt Ihnen eine Situation ein in der Sie Angst empfunden haben?': 'T: Schildern Sie eine Situation in der Sie Angst empfunden haben.', \n",
    "        'T: Fällt Ihnen eine Situation ein in der Sie Traurigkeit empfunden haben?': 'T: Schildern Sie eine Situation in der Sie Traurigkeit empfunden haben.', \n",
    "\n",
    "        'T: Warum haben Sie in dieser Situation Freude erlebt?': 'T: Warum haben Sie in dieser Situation Freude empfunden?', \n",
    "        'T: Warum haben Sie in dieser Situation Angst erlebt?': 'T: Warum haben Sie in dieser Situation Angst empfunden?', \n",
    "        'T: Warum haben Sie in dieser Situation Traurigkeit erlebt?': 'T: Warum haben Sie in dieser Situation Traurigkeit empfunden?', \n",
    "        'T: Warum haben Sie in dieser Situation Wut erlebt?': 'T: Warum haben Sie in dieser Situation Wut empfunden?', \n",
    "\n",
    "        'T: Was gehört denn zu erleben von Angst dazu?': 'T: Warum haben Sie in dieser Situation Wut empfunden?', \n",
    "        'T: Was bedeutet denn sauer sein?': 'T: Was bedeutet Wut für Sie?', \n",
    "\n",
    "\n",
    "        'T: Beschreiben Sie eine Situation in der Sie Wut empfunden haben.': 'T: Schildern Sie eine Situation in der Sie Wut empfunden haben.', \n",
    "        'T: Können Sie uns eine Situation schildern in der Sie Wut empfunden haben.': 'T: Schildern Sie eine Situation in der Sie Wut empfunden haben.', \n",
    "        'T: Beschreiben Sie eine Situation in der Sie Angst empfunden haben.': 'T: Schildern Sie eine Situation in der Sie Angst empfunden haben.',  \n",
    "        'T: Können Sie auch eine Situation beschreiben in der Sie Angst empfunden haben.': 'T: Schildern Sie eine Situation in der Sie Angst empfunden haben.', \n",
    "        'T: Können Sie mir eine Situation schildern in der Sie Angst empfunden haben.': 'T: Schildern Sie eine Situation in der Sie Angst empfunden haben.',  \n",
    "        'T: Schildern Sie eine Situation in der Angst empfunden haben.': 'T: Schildern Sie eine Situation in der Sie Angst empfunden haben.', \n",
    "        'T: Beschreiben Sie eine Situation in der Sie Traurigkeit empfunden haben.': 'T: Schildern Sie eine Situation in der Sie Traurigkeit empfunden haben.', \n",
    "        'T: Und könnten Sie eine Situation schildern in der Sie Traurigkeit empfunden haben.': 'T: Schildern Sie eine Situation in der Sie Traurigkeit empfunden haben.', \n",
    "        'T: Schildern Sie bitte eine Situation in der Sie Traurigkeit empfunden haben.': 'T: Schildern Sie eine Situation in der Sie Traurigkeit empfunden haben.', \n",
    "        'T: Beschreiben Sie eine Situation in der Sie Freude empfunden haben.': 'T: Schildern Sie eine Situation in der Sie Freude empfunden haben.', \n",
    "        'T: Schildern Sie eine Situation ein in der Sie Freude empfunden haben.': 'T: Schildern Sie eine Situation in der Sie Freude empfunden haben.', \n",
    "\n",
    "        'T: Warum haben Sie in diesen Situationen Traurigkeit empfunden?': 'T: Warum haben Sie in dieser Situation Traurigkeit empfunden?', \n",
    "        'T: Warum haben Sie in dieser Situation mit der Oma Traurigkeit erlebt?': 'T: Warum haben Sie in dieser Situation Traurigkeit empfunden?',  \n",
    "        'T: Da waren Sie traurig? Warum haben Sie in dieser Situation Traurigkeit erlebt?': 'T: Warum haben Sie in dieser Situation Traurigkeit empfunden?', \n",
    "        'T: Warum haben Sie in dieser Situation Trauer empfunden?': 'T: Warum haben Sie in dieser Situation Traurigkeit empfunden?', \n",
    "        'T: Warum waren Sie in der Situation traurig?': 'T: Warum haben Sie in dieser Situation Traurigkeit empfunden?', \n",
    "        'T: Warum waren Sie wütend in der Situation?': 'T: Warum haben Sie in dieser Situation Wut empfunden?', \n",
    "        'T: Warum waren Sie in der Situation wütend?': 'T: Warum haben Sie in dieser Situation Wut empfunden?', \n",
    "        'T: Haben Sie beantwortet. Warum haben Sie in dieser Situation Wut erlebt?': 'T: Warum haben Sie in dieser Situation Wut empfunden?',   \n",
    "        'T: Warum haben Sie in er Situation Angst empfunden?': 'T: Warum haben Sie in dieser Situation Angst empfunden?', \n",
    "        'T: Warum haben Sie denn in der Situation Angst empfunden?': 'T: Warum haben Sie in dieser Situation Angst empfunden?', \n",
    "        'T: Warum haben Sie in dieser Situation Angst?': 'T: Warum haben Sie in dieser Situation Angst empfunden?', \n",
    "        'T: Warum haben Sie sich in der Situation so gefreut?': 'T: Warum haben Sie in dieser Situation Freude empfunden?', \n",
    "        'T: Warum haben Sie sich in der Situation gefreut?': 'T: Warum haben Sie in dieser Situation Freude empfunden?', \n",
    "        'T: Warum empfinden Sie in dieser Situation dann Freude?': 'T: Warum haben Sie in dieser Situation Freude empfunden?', \n",
    "        'T: Warum haben Sie in dieser Situation Wut empfunden? Weil Sie nicht durchgehalten haben sagten Sie?': 'T: Warum haben Sie in dieser Situation Wut empfunden?',\n",
    "        'T: Warum haben Sie in der Sitaution Traurigkeit empfunden?': 'T: Warum haben Sie in dieser Situation Traurigkeit empfunden?', \n",
    "        'T: Warum haben Sie in dieser Situation Wut empfunden ': 'T: Warum haben Sie in dieser Situation Wut empfunden?',\n",
    "    \n",
    "        'T: Was bedeutet denn Freude für Sie?': 'T: Was bedeutet Freude für Sie?', \n",
    "        'T: Und was bedeutet Wut für Sie?': 'T: Was bedeutet Wut für Sie?', \n",
    "        'T: Was bedeutet für Sie Angst?': 'T: Was bedeutet Angst für Sie?', \n",
    "        'T: Was bedeutet Trauigkeit für Sie?': 'T: Was bedeutet Traurigkeit für Sie?', \n",
    "        'T: Wie merken Sie dann die Wut?': 'T: Was bedeutet Wut für Sie?', \n",
    "        'T: Was bedeutet das denn? Traurig zu sein?': 'T: Was bedeutet Traurigkeit für Sie?', \n",
    "        'T: Was bedeutet Traurigkeit für Sie? Können Sie das ein bisschen beschreiben?': 'T: Was bedeutet Traurigkeit für Sie?', \n",
    "    }\n",
    "    patterns = {\n",
    "        'T: Und könnten Sie eine Situation schildern,': 'T: Schildern Sie eine Situation', \n",
    "        'T: Schildern Sie bitte eine Situation,': 'T: Schildern Sie eine Situation', \n",
    "        'T: Können Sie auch eine Situation beschreiben,': 'T: Schildern Sie eine Situation', \n",
    "        'T: Können Sie eine Situation schildern': 'T: Schildern Sie eine Situation', \n",
    "        'T: Und können Sie eine Situation schildern': 'T: Schildern Sie eine Situation', \n",
    "        'T: Beschreiben Sie eine Situation,': 'T: Schildern Sie eine Situation', \n",
    "\n",
    "        'T: Warum haben Sie in der Situation': 'T: Warum haben Sie in dieser Situation', \n",
    "\n",
    "        'in der Sie Freude empfunden haben?': 'in der Sie Freude empfunden haben.', \n",
    "        'in der Sie Wut empfunden haben?': 'in der Sie Wut empfunden haben.', \n",
    "        'in der Sie Angst empfunden haben?': 'in der Sie Angst empfunden haben.', \n",
    "        'in der Sie Traurigkeit empfunden haben?': 'in der Sie Traurigkeit empfunden haben.'\n",
    "    }\n",
    "    text = multiple_replace(text, q_errors)\n",
    "    text = multiple_replace(text, patterns)\n",
    "    return text\n",
    "\n",
    "\n",
    "def replace_questions(text):\n",
    "    text = text.replace('T: Was bedeutet Freude für Sie? P:', '\\n\\nhappy1:')\n",
    "    text = text.replace('T: Was bedeutet Wut für Sie? P:', '\\n\\nanger1:')\n",
    "    text = text.replace('T: Was bedeutet Angst für Sie? P:', '\\n\\nfear1:')\n",
    "    text = text.replace('T: Was bedeutet Traurigkeit für Sie? P:', '\\n\\nsad1:')\n",
    "    text = text.replace('T: Schildern Sie eine Situation in der Sie Freude empfunden haben. P:', '\\n\\nhappy2:')\n",
    "    text = text.replace('T: Schildern Sie eine Situation in der Sie Wut empfunden haben. P:', '\\n\\nanger2:')\n",
    "    text = text.replace('T: Schildern Sie eine Situation in der Sie Angst empfunden haben. P:', '\\n\\nfear2:')\n",
    "    text = text.replace('T: Schildern Sie eine Situation in der Sie Traurigkeit empfunden haben. P:', '\\n\\nsad2:')\n",
    "    text = text.replace('T: Warum haben Sie in dieser Situation Freude empfunden? P:', '\\n\\nhappy3:')\n",
    "    text = text.replace('T: Warum haben Sie in dieser Situation Wut empfunden? P:', '\\n\\nanger3:')\n",
    "    text = text.replace('T: Warum haben Sie in dieser Situation Angst empfunden? P:', '\\n\\nfear3:')\n",
    "    text = text.replace('T: Warum haben Sie in dieser Situation Traurigkeit empfunden? P:', '\\n\\nsad3:')\n",
    "    return text\n",
    "\n",
    "\n",
    "def fix_turn_beginnings(text):\n",
    "    text = text.replace('B:', 'P:')\n",
    "    return text\n",
    "\n",
    "# Sometimes the interviewer says other things as well \n",
    "# (e.g. T: Was gehört denn zu erleben von Angst dazu?)\n",
    "def remove_extra_qestions(text):\n",
    "    text = re.sub('T: .+? P:', '', text)\n",
    "    return text\n",
    "\n",
    "#Function for replacing number digits to number words in German\n",
    "\n",
    "def number_to_german_word(number):\n",
    "    german_mapping = {\n",
    "    '1': 'eins', '2': 'zwei', '3': 'drei', '4': 'vier', '5': 'fünf', '6': 'sechs', '7': 'sieben', '8': 'acht', '9': 'neun','10': 'zehn',\n",
    "    '11': 'elf', '12': 'zwölf', '13': 'dreizehn', '14': 'vierzehn', '15': 'fünfzehn', '16': 'sechzehn', '17': 'siebzehn', '18': 'achtzehn', '19': 'neunzehn', '20': 'zwanzig',\n",
    "    '21': 'einundzwanzig', '22': 'zweiundzwanzig', '23': 'dreiundzwanzig', '24': 'vierundzwanzig', '25': 'fünfundzwanzig', '26': 'sechsundzwanzig', '27': 'siebenundzwanzig', '28': 'achtundzwanzig','29': 'neunundzwanzig', '30': 'dreißig', \n",
    "    '40': 'vierzig', '50': 'fünfzig', '60': 'sechzig', '70': 'siebzig', '80': 'achtzig', '90': 'neunzig', '100': 'hundert',\n",
    "    '1000': 'tausend', '2000': 'zweitausend', '3000': 'dreitausend', '4000': 'viertausend', '5000': 'fünftausend', \n",
    "    '6000': 'sechstausend', '7000': 'siebentausend', '8000': 'achttausend', '9000': 'neuntausend', '10000': 'zehntausend',\n",
    "    '1930': 'neunzehnhundertdreißig', '1931': 'neunzehnhunderteinunddreißig', '1932': 'neunzehnhundertzweiunddreißig', '1933': 'neunzehnhundertdreiunddreißig', '1934': 'neunzehnhundertvierunddreißig', '1935': 'neunzehnhundertfünfunddreißig', '1936': 'neunzehnhundertsechsunddreißig','1937': 'neunzehnhundertsiebenunddreißig', '1938': 'neunzehnhundertachtunddreißig', '1939': 'neunzehnhundertneununddreißig', \n",
    "    '1940': 'neunzehnhundertvierzig', '1941': 'neunzehnhunderteinundvierzig', '1942': 'neunzehnhundertzweiundvierzig', '1943': 'neunzehnhundertdreiundvierzig', '1944': 'neunzehnhundertvierundvierzig',  '1945': 'neunzehnhundertfünfundvierzig', '1946': 'neunzehnhundertsechsundvierzig', '1947': 'neunzehnhundertsiebenundvierzig', '1948': 'neunzehnhundertachtundvierzig', '1949': 'neunzehnhundertneunundvierzig', \n",
    "    '1950': 'neunzehnhundertfünfzig', '1951': 'neunzehnhunderteinundfünfzig', '1952': 'neunzehnhundertzweiundfünfzig', '1953': 'neunzehnhundertdreiundfünfzig', '1954': 'neunzehnhundertvierundfünfzig', '1955': 'neunzehnhundertfünfundfünfzig', '1956': 'neunzehnhundertsechsundfünfzig', '1957': 'neunzehnhundertsiebenundfünfzig', '1958': 'neunzehnhundertachtundfünfzig', '1959': 'neunzehnhundertneunundfünfzig',\n",
    "    '1960': 'neunzehnhundertsechszig', '1961': 'neunzehnhunderteinundsechszig', '1962': 'neunzehnhundertzweiundsechszig', '1963': 'neunzehnhundertdreiundsechszig', '1964': 'neunzehnhundertvierundsechszig', '1965': 'neunzehnhundertfünfundsechszig', '1966': 'neunzehnhundertsechsundsechszig', '1967': 'neunzehnhundertsiebenundsechszig', '1968': 'neunzehnhundertachtundsechszig', '1969': 'neunzehnhundertneunundsechszig', \n",
    "    '1970': 'neunzehnhundertsiebzig', '1971': 'neunzehnhunderteinundsiebzig', '1972': 'neunzehnhundertzweiundsiebzig', '1973': 'neunzehnhundertdreiundsiebzig', '1974': 'neunzehnhundertvierundsiebzig',\n",
    "    '1975': 'neunzehnhundertfünfundsiebzig', '1976': 'neunzehnhundertsechsundsiebzig', '1977': 'neunzehnhundertsiebenundsiebzig', '1978': 'neunzehnhundertachtundsiebzig', '1979': 'neunzehnhundertneunundsiebzig', \n",
    "    '1980': 'neunzehnhundertachtzig', '1981': 'neunzehnhunderteinundachtzig', '1982': 'neunzehnhundertzweiundachtzig', '1983': 'neunzehnhundertdreiundachtzig', '1984': 'neunzehnhundertvierundachtzig', '1985': 'neunzehnhundertfünfundachtzig', '1986': 'neunzehnhundertsechsundachtzig', '1987': 'neunzehnhundertsiebenundachtzig', '1988': 'neunzehnhundertachtundachtzig', '1989': 'neunzehnhundertneunundachtzig', \n",
    "    '1990': 'neunzehnhundertneunziger', '1991': 'neunzehnhunderteinundneunzig', '1992': 'neunzehnhundertzweiundneunzig', '1993': 'neunzehnhundertdreiundneunzig', '1994': 'neunzehnhundertvierundneunzig', '1995': 'neunzehnhundertfünfundneunzig', '1996': 'neunzehnhundertsechsundneunzig', '1997': 'neunzehnhundertsiebenundneunzig', '1998': 'neunzehnhundertachtundneunzig', '1999': 'neunzehnhundertneunundneunzig',\n",
    "    '2000': 'zweitausend', '2001': 'zweitausendeins', '2002': 'zweitausendzwei', '2003': 'zweitausenddrei', '2004': 'zweitausendvier', '2005': 'zweitausendfünf', '2006': 'zweitausendsechs', '2007': 'zweitausendsieben', '2008': 'zweitausendacht', '2009': 'zweitausendneun',\n",
    "    '2010': 'zweitausendzehn', '2011': 'zweitausendeinszehn', '2012': 'zweitausendzwölf', '2013': 'zweitausenddreizehn', '2014': 'zweitausendvierzehn', '2015': 'zweitausendfünfzehn', '2016': 'zweitausendsechzehn', '2017': 'zweitausendsiebzehn', '2018': 'zweitausendachtzehn', '2019': 'zweitausendneunzehn',\n",
    "    '2020': 'zweitausendzwanzig', '2021': 'zweitausendeinundzwanzig', '2022': 'zweitausendzweiundzwanzig', '2023': 'zweitausenddreiundzwanzig', '2024': 'zweitausendvierundzwanzig', '2025': 'zweitausendfünfundzwanzig', '2026': 'zweitausendsechsundzwanzig', '2027': 'zweitausendsiebenundzwanzig', '2028': 'zweitausendachtundzwanzig', '2029': 'zweitausendneunundzwanzig',\n",
    "    '2030': 'zweitausenddreißig',\n",
    "    # Add more if needed\n",
    "}\n",
    "\n",
    "    return german_mapping.get(str(number), str(number))\n",
    "\n",
    "# Example usage:\n",
    "#number = '10000'\n",
    "#word = number_to_german_word(number)\n",
    "#print(word)\n",
    "\n",
    "\n",
    "def replace_digits_with_german_words(text):\n",
    "    # Regular expression to find all digits in the text\n",
    "    digit_pattern = re.compile(r'\\b\\d+\\b')\n",
    "\n",
    "    # Find all matches in the text\n",
    "    matches = digit_pattern.findall(text)\n",
    "\n",
    "    # Replace each match with its corresponding German word\n",
    "    for match in matches:\n",
    "        german_word = number_to_german_word(int(match))\n",
    "        text = text.replace(match, german_word)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "#Final function for preprocessing text, consider not running clean_stopwords or clean_fillers depending on analysis\n",
    "def preprocess(text, char_map, fillers=[], stopwords=[]):\n",
    "    text = replace_chars(text, char_map)\n",
    "    text = remove_timestamps(text)\n",
    "    text = fix_turn_beginnings(text)\n",
    "    text = remove_hanging_punct(text)\n",
    "    text = remove_comma_space(text)\n",
    "    text = remove_extra_spaces(text)\n",
    "    text = fix_questions(fix_questions(text))\n",
    "#     text = remove_extra_qestions(text)\n",
    "    text = clean_stopwords(text, stopwords=stopwords)\n",
    "    text = clean_fillers(text, fillers=fillers)\n",
    "\n",
    "    text = remove_hanging_punct(text)\n",
    "    text = remove_unwanted_punct(text)\n",
    "#     text = replace_digits_with_german_words(text)\n",
    "    text = remove_dots(text)\n",
    "    text = remove_extra_spaces(text)\n",
    "    ok, non_unicode = test_unicode(text)\n",
    "    if '\\x00' in text:\n",
    "        return ''\n",
    "    assert ok, non_unicode\n",
    "    text = text.strip().strip('\\n').strip('1')\n",
    "    text = replace_questions(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fd1279-a064-45f7-a302-cbe1c103f7ae",
   "metadata": {
    "id": "99fd1279-a064-45f7-a302-cbe1c103f7ae"
   },
   "source": [
    "<h3>Testing the preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "c038f46d-c3fc-4768-937c-a6e32bb13997",
   "metadata": {
    "id": "c038f46d-c3fc-4768-937c-a6e32bb13997",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#open transcript with the correct encoding\n",
    "\n",
    "# File path\n",
    "file_path = IN_DIR + r'13_6M_manual.txt'\n",
    "\n",
    "# Detect the encoding\n",
    "detected_encoding = detect_encoding(file_path)\n",
    "\n",
    "# Open the file with the detected encoding\n",
    "with open(file_path, encoding=detected_encoding) as f:\n",
    "    raw = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "75b0b36b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "T: Was bedeutet Traurigkeit für Sie?  #00:00:05-2#\n",
      "\n",
      "P: Traurigkeit bedeutet für mich einen Verlust. Einen Verlust oder Reue. #00:00:20-2#\n",
      "\n",
      "T: Können Sie eine Situation schildern, in der Sie Traurigkeit empfunden haben?   #00:00:25-4#\n",
      "\n",
      "P: Ja, ich habe meine Kinder damals verloren. Und habe es bereut, warum ich sie verloren habe. Wieso das passiert ist. Traurigkeit ist auch, wenn man sich bewusst wird, dass Dinge mit einem gemacht wurden, die man. Also nein, das kann ich nicht so richtig nein. Aber wenn einem bewusst wird, dass etwas nicht richtig ist. Also wenn man es nicht versteht. Das kann ich jetzt nicht richtig beschreiben. Aber Traurigkeit ist traurig. #00:01:05-2#\n",
      "\n",
      "T: Warum haben Sie in dieser Situation Traurigkeit empfunden?  #00:01:19-2#\n",
      "\n",
      "P: Ja. Traurigkeit ist auch ein Gefühl könnte man sagen. Und ja weil ich starke Emotionen halt entwickelt habe für meine Kinder und deswegen.  #00:01:36-1#\n",
      "\n",
      "T: Was bedeutet Angst für Sie?  #00:01:43-9#\n",
      "\n",
      "P: Ja Angst. Angst, es bedeutet, dass man in die Enge geführt wird, beziehungsweise bedroht wird. Vielleicht sogar erpresst oder irgendwas. Angst ist ein Gefühl. Also man zieht sich körperlich total, man kehrt in sich ein. Man zittert vielleicht sogar auch.  #00:02:10-1#\n",
      "\n",
      "T: Können Sie auch eine Situation beschreiben, in der Sie Angst empfunden haben?  #00:02:14-7#\n",
      "\n",
      "P: Ja also, wenn mir jemand auflauert in meiner Wohnung, jemand einbricht. Wenn ich die Tür aufmache und mir jemand auflauert.  #00:02:22-7#\n",
      "\n",
      "T: Warum haben Sie in der Situation Angst empfunden?  #00:02:24-0#\n",
      "\n",
      "P: Weil die Stimmen mir das oft genug sagen. Ich soll nur warten, bis sie haben meine Wohnung und. Oder wenn die sagen: „Ja ich bringe dich um oder so.“ Dafür kann ich keine richtige. Das ist ja, das ist wahrscheinlich auch ein Problem, was ich habe. Mit meinem eigenen Tod kann ich kaum ein Gefühl für entwickeln, aber ich hatte es schon einmal. Oh Gott oh Gott wie bescheuert bin ich eigentlich, ne? Ich hatte es schon oft. Und ich habe mal gespürt, da dachte ich so „Nein, eigentlich willst du nicht sterben. Das wäre das Schlimmste, was es gibt.“ Aber wenn man merkt, man wird alleine, man ist immer mehr alleine und da ist nicht viel. Und dann kommen solche Gedanken, also solche Stimmen dann noch dazu. Das macht es einem dann wirklich nicht gerade leicht.  #00:03:16-4#\n",
      "\n",
      "T: Was bedeutet Wut für Sie?  #00:03:16-4#\n",
      "\n",
      "P: Unverstandenheit. Und hm kein (...) Unverstandenheit, ja.  #00:03:29-4#\n",
      "\n",
      "T: Können Sie eine Situation schildern, in der Sie Wut empfunden haben?  #00:03:34-0#\n",
      "\n",
      "P: Ja, also zum Beispiel, wenn ich anfange Sport zu machen und die Leute halten mich davon ab. Und verbieten mir das, dann fühle ich mich total unverstanden. Und bin sauer da drüber, warum die das machen. Weshalb die das, dass die das überhaupt machen. Mir solche Vorschriften machen. Dieses, das, hm, wie nennt sich das? Ja wenn miteinander das Eingestehen also wenn, die Vereinbarlichkeit. Das ist irgendwie nicht vorhanden.  #00:04:17-1#\n",
      "\n",
      "T: Warum haben Sie in dieser Situation Wut empfunden?  #00:04:24-4#\n",
      "\n",
      "P: Ja weil ich denke das ist mein Recht auch das machen zu dürfen. Ja.  #00:04:25-8#\n",
      "\n",
      "T: Was bedeutet Freude für Sie?  #00:04:33-2#\n",
      "\n",
      "P: Freude ist, wenn man glücklich ist, ja. #00:04:35-7#\n",
      "\n",
      "T: Können Sie eine Situation schildern, in der Sie Freude empfunden haben?  #00:04:45-7#\n",
      "\n",
      "P: (...) Ja wenn man lacht. Wenn man lacht über irgendwas oder über sich selbst oder… Ja ich lache eigentlich oft, jeden Tag manchmal sogar, also in guten Zeiten. Ja meistens, wenn ich mit anderen zusammen bin oder so, dann lachen wir schon viel.  #00:05:12-4#\n",
      "\n",
      "T: Warum haben Sie in dieser Situation Freude empfunden?  #00:05:18-0#\n",
      "\n",
      "P: Ja weil es lustig war, ja. Weil, was weiß ich, weil lustige Dinge erzählt wurden und das ja.  #00:05:31-2#\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "6501225e-695f-4187-a92c-ad16b31f68cb",
   "metadata": {
    "id": "6501225e-695f-4187-a92c-ad16b31f68cb",
    "outputId": "176a3831-95cc-4efc-d2a8-bdbb16cd330c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "sad1: Traurigkeit bedeutet für mich einen Verlust. Einen Verlust oder Reue. \n",
      "\n",
      "sad2: Ja ich habe meine Kinder damals verloren. Und habe es bereut warum ich sie verloren habe. Wieso das passiert ist. Traurigkeit ist auch wenn man sich bewusst wird dass Dinge mit einem gemacht wurden die man. Also nein das kann ich nicht so richtig nein. Aber wenn einem bewusst wird dass etwas nicht richtig ist. Also wenn man es nicht versteht. Das kann ich jetzt nicht richtig beschreiben. Aber Traurigkeit ist traurig. \n",
      "\n",
      "sad3: Ja. Traurigkeit ist auch ein Gefühl könnte man sagen. Und ja weil ich starke Emotionen halt entwickelt habe für meine Kinder und deswegen. \n",
      "\n",
      "fear1: Ja Angst. Angst es bedeutet dass man in die Enge geführt wird beziehungsweise bedroht wird. Vielleicht sogar erpresst oder irgendwas. Angst ist ein Gefühl. Also man zieht sich körperlich total man kehrt in sich ein. Man zittert vielleicht sogar auch. \n",
      "\n",
      "fear2: Ja also wenn mir jemand auflauert in meiner Wohnung jemand einbricht. Wenn ich die Tür aufmache und mir jemand auflauert. \n",
      "\n",
      "fear3: Weil die Stimmen mir das oft genug sagen. Ich soll nur warten bis sie haben meine Wohnung und. Oder wenn die sagen: \" Ja ich bringe dich um oder so. \" Dafür kann ich keine richtige. Das ist ja das ist wahrscheinlich auch ein Problem was ich habe. Mit meinem eigenen Tod kann ich kaum ein Gefühl für entwickeln aber ich hatte es schon einmal. Oh Gott oh Gott wie bescheuert bin ich eigentlich ne? Ich hatte es schon oft. Und ich habe mal gespürt da dachte ich so \" Nein eigentlich willst du nicht sterben. Das wäre das Schlimmste was es gibt. \" Aber wenn man merkt man wird alleine man ist immer mehr alleine und da ist nicht viel. Und dann kommen solche Gedanken also solche Stimmen dann noch dazu. Das macht es einem dann wirklich nicht gerade leicht. \n",
      "\n",
      "anger1: Unverstandenheit. Und hm kein Unverstandenheit ja. \n",
      "\n",
      "anger2: Ja also zum Beispiel wenn ich anfange Sport zu machen und die Leute halten mich davon ab. Und verbieten mir das dann fühle ich mich total unverstanden. Und bin sauer da drüber warum die das machen. Weshalb die das dass die das überhaupt machen. Mir solche Vorschriften machen. Dieses das hm wie nennt sich das? Ja wenn miteinander das Eingestehen also wenn die Vereinbarlichkeit. Das ist irgendwie nicht vorhanden. \n",
      "\n",
      "anger3: Ja weil ich denke das ist mein Recht auch das machen zu dürfen. Ja. \n",
      "\n",
      "happy1: Freude ist wenn man glücklich ist ja. \n",
      "\n",
      "happy2: Ja wenn man lacht. Wenn man lacht über irgendwas oder über sich selbst oder Ja ich lache eigentlich oft jeden Tag manchmal sogar also in guten Zeiten. Ja meistens wenn ich mit anderen zusammen bin oder so dann lachen wir schon viel. \n",
      "\n",
      "happy3: Ja weil es lustig war ja. Weil was weiß ich weil lustige Dinge erzählt wurden und das ja.\n"
     ]
    }
   ],
   "source": [
    "cleaned = preprocess(raw, char_map=encoding_errors_dict)\n",
    "print(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c58358b-bc1a-4adc-9a03-c0fbbe598595",
   "metadata": {
    "id": "1c58358b-bc1a-4adc-9a03-c0fbbe598595"
   },
   "source": [
    "<h3>Preprocessing of all transcripts</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "3adcf416-79ae-4897-8b1c-c9fbea6da923",
   "metadata": {
    "id": "3adcf416-79ae-4897-8b1c-c9fbea6da923",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to detect the encoding of a file\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        detector = chardet.universaldetector.UniversalDetector()\n",
    "        for line in f:\n",
    "            detector.feed(line)\n",
    "            if detector.done:\n",
    "                break\n",
    "        detector.close()\n",
    "        return detector.result['encoding']\n",
    "\n",
    "# Function to read a file with multiple encodings\n",
    "def read_file_with_encodings(file_path, encodings):\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(file_path, encoding=encoding) as f:\n",
    "                return f.read()\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise UnicodeDecodeError(\"Failed to decode the file with any of the specified encodings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "4d0786c6-55b8-4625-a86f-80b39b525308",
   "metadata": {
    "id": "4d0786c6-55b8-4625-a86f-80b39b525308",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ids = []\n",
    "transcripts = []\n",
    "\n",
    "for (root, dirs, files) in os.walk(IN_DIR, topdown=True):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            try:\n",
    "                detected_encoding = detect_encoding(os.path.join(root, file))\n",
    "                current_id = file.split('.')[0]  # Use [0] to get the part before the dot\n",
    "                ids.append(current_id)\n",
    "                raw = read_file_with_encodings(os.path.join(root, file), [detected_encoding, 'utf-8', 'latin-1'])\n",
    "                cleaned = preprocess(raw, char_map=encoding_errors_dict)\n",
    "                transcripts.append(cleaned)\n",
    "            except (AssertionError, UnicodeDecodeError) as e:\n",
    "                print(f\"Error processing file: {file}\")\n",
    "                print(e)\n",
    "\n",
    "# Save cleaned transcripts as new text files with id_c.txt format\n",
    "for i, transcript in enumerate(transcripts):\n",
    "    output_file_path = os.path.join(OUT_DIR_TRANSCRIPTS, f'{ids[i]}_c.txt')\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "        output_file.write(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eed9fb-7101-4091-93ab-f277d579fdde",
   "metadata": {
    "id": "93eed9fb-7101-4091-93ab-f277d579fdde"
   },
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "e77adaef-160d-415a-9d6b-092b537a71e8",
   "metadata": {
    "id": "e77adaef-160d-415a-9d6b-092b537a71e8",
    "outputId": "adfed300-a501-491b-b2fb-86d155c0c174",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45_6M_manual_c</th>\n",
       "      <td>\\n\\nsad1: Ja was bedeutet Traurigkeit. Also ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61_6M_manual_c</th>\n",
       "      <td>\\n\\nsad1: Ähm. Was bedeutet Traurigkeit für mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26_6M_manual_c</th>\n",
       "      <td>\\n\\nsad1: Äh dass jemand von mir Abschied geno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53_6M_manual_c</th>\n",
       "      <td>\\n\\nsad1: Ja Traurigkeit bedeutet wenn man wen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29_6M_manual_c</th>\n",
       "      <td>\\n\\nsad1: Also wenn man viel über was nachdenk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          preprocessed_transcript\n",
       "45_6M_manual_c  \\n\\nsad1: Ja was bedeutet Traurigkeit. Also ge...\n",
       "61_6M_manual_c  \\n\\nsad1: Ähm. Was bedeutet Traurigkeit für mi...\n",
       "26_6M_manual_c  \\n\\nsad1: Äh dass jemand von mir Abschied geno...\n",
       "53_6M_manual_c  \\n\\nsad1: Ja Traurigkeit bedeutet wenn man wen...\n",
       "29_6M_manual_c  \\n\\nsad1: Also wenn man viel über was nachdenk..."
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = []\n",
    "transcripts = []\n",
    "\n",
    "for (root, dirs, files) in os.walk(OUT_DIR_TRANSCRIPTS, topdown=True):\n",
    "    for file in files:\n",
    "        try:\n",
    "            detected_encoding = detect_encoding(os.path.join(root, file))\n",
    "            current_id = file.split('.')[0]  # Use [0] to get the part before the dot\n",
    "            ids.append(current_id)\n",
    "            preprocessed = read_file_with_encodings(os.path.join(root, file), [detected_encoding, 'utf-8', 'latin-1'])\n",
    "            transcripts.append(preprocessed)\n",
    "        except (AssertionError, UnicodeDecodeError) as e:\n",
    "            print(f\"Error processing file: {file}\")\n",
    "            print(e)\n",
    "\n",
    "df = pd.DataFrame(index=ids)\n",
    "df['preprocessed_transcript'] = transcripts\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "2690d9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: preprocessed_transcript, dtype: object)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['preprocessed_transcript'][df['preprocessed_transcript'].apply(lambda text: 'P:' in text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af56d21a-812d-4f1e-b83b-9d346e939815",
   "metadata": {
    "id": "af56d21a-812d-4f1e-b83b-9d346e939815"
   },
   "source": [
    "### Split into questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "75edfcf3-bcb4-47ab-9521-6493c3421bfd",
   "metadata": {
    "id": "75edfcf3-bcb4-47ab-9521-6493c3421bfd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_into_questions(interview):\n",
    "    # Define emotion-related questions and their corresponding identifiers\n",
    "    emotion_questions = {\n",
    "        'anger': ['anger1:', 'anger2:', 'anger3:'],\n",
    "        'fear': ['fear1:', 'fear2:', 'fear3:'],\n",
    "        'sadness': ['sad1:', 'sad2:', 'sad3:'],\n",
    "        'happiness': ['happy1:', 'happy2:', 'happy3:']\n",
    "    }\n",
    "    \n",
    "    # Map indexes onto emotions, not the other way around\n",
    "    qids_emotions = {} \n",
    "\n",
    "    # Find the positions (indices) of emotion-related questions in the interview\n",
    "    # The same question may be asked several times\n",
    "    for emotion, questions in emotion_questions.items():\n",
    "        for q in questions:\n",
    "            if q in interview:\n",
    "                ids = [m.start() for m in re.finditer(q, interview)]\n",
    "                for i in ids:\n",
    "                    # If several times the same question is asked, \n",
    "                    # they are assigned to the same emotion \n",
    "                    qids_emotions[i] = emotion\n",
    "\n",
    "    # Initialize containers for emotion-related text segments\n",
    "    emotion_texts = {emotion: '' for emotion in emotion_questions}\n",
    "    \n",
    "    sorted_qids = sorted(qids_emotions.keys())\n",
    "    \n",
    "    # Go through all qestion indicies\n",
    "    for i, qid in enumerate(sorted_qids):\n",
    "        # Look up which emotion this idex is\n",
    "        emotion = qids_emotions[qid]\n",
    "        if i + 1 < len(sorted_qids):\n",
    "            next_qid = sorted_qids[i + 1]\n",
    "            emotion_texts[emotion] += interview[qid:next_qid]\n",
    "        else:\n",
    "            emotion_texts[emotion] += interview[qid:]\n",
    "\n",
    "    return emotion_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "af307cb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 'anger1: Wut ist eine Kraft. Eine spezifische. Und auch eine Kraft Menschen zu schützen und sie gleichzeitig zu besiegen. Da sind glaube ich zwei Facetten der Wut. Ich habe halt wie gesagt immer wieder so Kämpferphantasien die ich aber tatsächlich nicht auslebe. Und ich glaube dass die Wut sehr zentral für mich ist. Dass ich sehr viel Wut aufgestaut habe. Und dass sie auch für meine Zukunft so eine Art Taktgeber sein wird. Dass ich darüber eben eine Kraft aufbaue und die Wut halt auch rauslasse. \\n\\nanger2: Ne ähm es ist immer. Diese Phantasien die sind auch relativ unabhängig oft von dem was meine Umfeld gerade so gibt. Na gut doch. Meine Mutter da bin ich öfters sehr wütend. Da aber fällt es mir sehr schwer die Wut rauszulassen. Weil ich halt auch über meine Mutter da so geprägt bin. Die hatte selber immer so Ausraster. Und dass ich da so mich in mein Schneckenhaus zurückziehe. Und das ist eben auch so eine Sache der Wut. Dass ich die eben nutze um aus dieser Einschüchterung herauszukommen. Weil ich eigentlich glaube ich kein Mensch bin der wirklich schüchtern. Das ist eher so Prägung die ich erhalten habe über meine Mutter und über meine Umwelt. Aber so ansonsten bin ich doch eher ein gelassener Typ. Und ich neige nicht zu Jähzorn und Gefühlausbrüchen. \\n\\nanger3: Na das ist halt das Gefühl mit dem sie einem begegnet. Das ist so wie auch das Gesicht das sie aufsetzt. Dass sie halt einen so grundlos irgendwie so anscheißt so ankeift und einem halt so eine Schwulzt aus bad Emotions halt gibt. Und einfach so relativ grundlos. Und da so. wieso kannst du mich so behandeln? Also ich habe dir gar nichts getan. Das ist so ein bisschen. Dass man halt angegriffen wird so vollkommen grundlos. Ja das ist so ein bisschen der Hintergrund. \\n\\n',\n",
       " 'fear': 'fear1: Ähm. Angst ist immer ein eine Aufgabe die zu akzeptieren und zu überwinden und. Ja Angst. Angst ist eine Warnung. Und ist eigentlich ähm ein Gefühl dass einen Prozess provoziert in dem ich eine Überwindung leisten muss. Ja. \\n\\nfear2: Ähm. Ne fällt mir nicht ein. Ist auch so im Alltag nicht so häufig der Fall. Obwohl ich glaube ich bin ständig irgendwie konfrontiert mit Ängsten aber nicht nie so ganz konkret. Ich überlege gerade ob bei Person X irgendwie. Ja doch. Da habe ich mich einmal mit ihr ausgesprochen. Und hab ihr so versucht so ein bisschen meine Gefühle zu ähm zu veranschaulichen. Da hab ich glaube ich Angst mal versucht zu überwinden. Ja. \\n\\nfear3: Ja Gefühl zu zeigen. Gefühle zu offenbaren. Und wahrscheinlich dann verletzt zu werden. Doch genau kann ich es gar nicht sagen. Es ist eher auch dieses Gefühl der Offenbarung der Offenlegung. Was auch so eben so eine Nacktheit mit sich bringt. Und dieses Gefühl ist halt auch relativ unangenehm. Sich halt so zu öffnen. Ja. Und vielleicht auch dass so ein bisschen so tiefer liegende stärkere Ängste dadurch hochkommen. Dieses Gefühl der Unsicherheit das mich auch oft begleitet. Dass das halt irgendwie so hochkommt und ich dann wieder nicht richtig damit umgehe. Das könnte glaube ich gut ein Grund sein. Ja. \\n\\n',\n",
       " 'sadness': 'sad1: Tränen. Blau. Dunkelblau. Ähm eigentlich bedeutet Traurigkeit. Ist positiv für mich. Weil ich es immer wieder verbinde mit einer Befreiung. Ja. \\n\\nsad2: Ja ich glaube ich glaube als ich noch in Person X verliebt war. In das letzte Mädchen in das ich verliebt war. Und zu Hause allein war. Und irgendwie ich gemerkt habe dass sie wieder einen Freund hatte. Ich glaube da war ich traurig. Obwohl ich das gar nicht so unter unbedigt dazu ordnen würde. Das ist eher so eine Erschütterung. Ja. Lange her glaube ich dass ich mal traurig war. Obwohl ich habe es einmal ähm irgendwie erzeugen können über ein Youtube Video. Aber das ist eher so eine fröhliche Traurigkeit. Da wurde jemand gerettet von einem Gleis. Ja. Ist glaube ich lange her dass ich wirklich traurig war. Wüsste ich. Ich wüsste keine wirkliche Situation gerade. \\n\\nsad2: Doch in meiner Kindheit noch. Da stimmt das auch nicht so ganz dass Trauer eine Befreiung ist. Ich hatte mit 11 schon sehr starke Depressionen. Und da war das dann über ein halbes Jahr hinweg dass ich eigentlich alle 2 3 Tage geweint habe. Und das war wirklich eine erschütternde tiefe Trauer und ja. Das weiß ich noch. \\n\\nsad3: Es war halt das Problem dass es keinen Grund dafür gab. Und das ich eigentlich auch mit meinem damaligen Therapeuten und mit meinen Eltern nie herausfinden konnte was die Ursache eigentlich war. Und das war immer so ein schwebendes Gefühl dass plötzlich von Außen kam. In mich. Oder auch aus mir heraus in mich. So. Und da habe ich nicht wirklich eine Antwort drauf gefunden warum dieses Gefühl jetzt kam. \\n\\n',\n",
       " 'happiness': 'happy1: Freude ist Lebenssinn. Gold. Also nicht Gold selbst sondern so in der Verbildlichung: Goldbild oder goldenes Licht. Und Freude ist auch so ein bisschen der Kitt der Freundschaft. Na und ist halt so: Wer Freude empfindet der hat auch einen Lebenssinn. Naja wer zusammen Freude erlebt der bindet sich halt. Das meine ich so damit. Und das ist halt auch wenn du selbst fröhlich und freundlich und freudvoll bist dass es auch sehr leicht ist Freundschaften zu schließen. Ja. Und das so ein bisschen mit eine ein Fundament eine Säule die Basis von freundschaftlichen Beziehungen. Denke ich. \\n\\nhappy2: Heute? Ähm beim Hacken. Körperliche Arbeit viel Sonne. Und dabei habe ich dann Freude empfunden. Ja. \\n\\nhappy3: Solche Emotionen die kommen ja dann auf einmal oder haben sich halt gerade aufgebaut. Ich denke die Vorarbeit war halt die Arbeit vorher die 3 4 Stunden. Und dann der körperliche der körperliche Akt. Und die Konzentration währenddessen auf das was ich getan habe. Ich glaube es war die Bewegung die mir Freude bereitet hat. Ja.'}"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_into_questions(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "3a8dcfb5-0002-4efc-917f-68d63f3a4607",
   "metadata": {
    "id": "3a8dcfb5-0002-4efc-917f-68d63f3a4607",
    "outputId": "4df57e90-a7fb-4349-faf8-375444660f28",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_transcript</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>sadness</th>\n",
       "      <th>happiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45_6M_manual_c</th>\n",
       "      <td>\\n\\nsad1: Ja was bedeutet Traurigkeit. Also ge...</td>\n",
       "      <td>anger1: Ja hm. Okay. Wut beruht auf Unsicherhe...</td>\n",
       "      <td>fear1: Naja. Also es ist halt so wenn nach dem...</td>\n",
       "      <td>sad1: Ja was bedeutet Traurigkeit. Also genere...</td>\n",
       "      <td>happy1: Naja. Mh. Ja das ist halt das Anstrebe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61_6M_manual_c</th>\n",
       "      <td>\\n\\nsad1: Ähm. Was bedeutet Traurigkeit für mi...</td>\n",
       "      <td>anger1: Ja. Was bedeutet Wut für mich? Wut? Ja...</td>\n",
       "      <td>fear1: Ja das mir irgendwas passiert. Ja. \\n\\n...</td>\n",
       "      <td>sad1: Ähm. Was bedeutet Traurigkeit für mich? ...</td>\n",
       "      <td>happy1: Ja ähm wenn ich ähm. Ja weiß nicht. Wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26_6M_manual_c</th>\n",
       "      <td>\\n\\nsad1: Äh dass jemand von mir Abschied geno...</td>\n",
       "      <td>anger1: Ist ein unangenehmes Gefühl Wut. Also ...</td>\n",
       "      <td>fear1: Ein Zustand den ich nicht gern habe. Ei...</td>\n",
       "      <td>sad1: Äh dass jemand von mir Abschied genommen...</td>\n",
       "      <td>happy1: Das sind Fragen. Ähm Freude. Frei sein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53_6M_manual_c</th>\n",
       "      <td>\\n\\nsad1: Ja Traurigkeit bedeutet wenn man wen...</td>\n",
       "      <td>anger1: Ähm Wut ja Wut wenn sich alles so aufs...</td>\n",
       "      <td>fear1: Ja Angst bedeutet Gefahr äh große Gefah...</td>\n",
       "      <td>sad1: Ja Traurigkeit bedeutet wenn man wenn ma...</td>\n",
       "      <td>happy1: Freude bedeutet für mich so eine Art L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29_6M_manual_c</th>\n",
       "      <td>\\n\\nsad1: Also wenn man viel über was nachdenk...</td>\n",
       "      <td>anger1: Wenn ich auf was sauer bin. Stinkig. K...</td>\n",
       "      <td>fear1: Wenn ich mich zurückhalte vor irgendwas...</td>\n",
       "      <td>sad1: Also wenn man viel über was nachdenkt un...</td>\n",
       "      <td>happy1: Wenn mein Partner nach Hause kommt. Ja...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          preprocessed_transcript  \\\n",
       "45_6M_manual_c  \\n\\nsad1: Ja was bedeutet Traurigkeit. Also ge...   \n",
       "61_6M_manual_c  \\n\\nsad1: Ähm. Was bedeutet Traurigkeit für mi...   \n",
       "26_6M_manual_c  \\n\\nsad1: Äh dass jemand von mir Abschied geno...   \n",
       "53_6M_manual_c  \\n\\nsad1: Ja Traurigkeit bedeutet wenn man wen...   \n",
       "29_6M_manual_c  \\n\\nsad1: Also wenn man viel über was nachdenk...   \n",
       "\n",
       "                                                            anger  \\\n",
       "45_6M_manual_c  anger1: Ja hm. Okay. Wut beruht auf Unsicherhe...   \n",
       "61_6M_manual_c  anger1: Ja. Was bedeutet Wut für mich? Wut? Ja...   \n",
       "26_6M_manual_c  anger1: Ist ein unangenehmes Gefühl Wut. Also ...   \n",
       "53_6M_manual_c  anger1: Ähm Wut ja Wut wenn sich alles so aufs...   \n",
       "29_6M_manual_c  anger1: Wenn ich auf was sauer bin. Stinkig. K...   \n",
       "\n",
       "                                                             fear  \\\n",
       "45_6M_manual_c  fear1: Naja. Also es ist halt so wenn nach dem...   \n",
       "61_6M_manual_c  fear1: Ja das mir irgendwas passiert. Ja. \\n\\n...   \n",
       "26_6M_manual_c  fear1: Ein Zustand den ich nicht gern habe. Ei...   \n",
       "53_6M_manual_c  fear1: Ja Angst bedeutet Gefahr äh große Gefah...   \n",
       "29_6M_manual_c  fear1: Wenn ich mich zurückhalte vor irgendwas...   \n",
       "\n",
       "                                                          sadness  \\\n",
       "45_6M_manual_c  sad1: Ja was bedeutet Traurigkeit. Also genere...   \n",
       "61_6M_manual_c  sad1: Ähm. Was bedeutet Traurigkeit für mich? ...   \n",
       "26_6M_manual_c  sad1: Äh dass jemand von mir Abschied genommen...   \n",
       "53_6M_manual_c  sad1: Ja Traurigkeit bedeutet wenn man wenn ma...   \n",
       "29_6M_manual_c  sad1: Also wenn man viel über was nachdenkt un...   \n",
       "\n",
       "                                                        happiness  \n",
       "45_6M_manual_c  happy1: Naja. Mh. Ja das ist halt das Anstrebe...  \n",
       "61_6M_manual_c  happy1: Ja ähm wenn ich ähm. Ja weiß nicht. Wa...  \n",
       "26_6M_manual_c  happy1: Das sind Fragen. Ähm Freude. Frei sein...  \n",
       "53_6M_manual_c  happy1: Freude bedeutet für mich so eine Art L...  \n",
       "29_6M_manual_c  happy1: Wenn mein Partner nach Hause kommt. Ja...  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_splits = []\n",
    "for i, transcript in zip(ids, transcripts):\n",
    "    questions_splits.append(split_into_questions(transcript))\n",
    "\n",
    "df = pd.concat([df, pd.DataFrame(questions_splits, index=ids)], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "c78d494a-1089-4791-8355-e2543466afec",
   "metadata": {
    "id": "c78d494a-1089-4791-8355-e2543466afec",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert the column to string type\n",
    "df['anger'] = df['anger'].astype(str)\n",
    "df['fear'] = df['fear'].astype(str)\n",
    "df['sadness'] = df['sadness'].astype(str)\n",
    "df['happiness'] = df['happiness'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "5bf44354-8fe9-4de9-bd85-a9764614adb0",
   "metadata": {
    "id": "5bf44354-8fe9-4de9-bd85-a9764614adb0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace prompts in emotion columns\n",
    "df['anger'] = df['anger'].replace({'\\n\\n': '', 'anger1:': '', 'anger2:': '', 'anger3:': ''}, regex=True)\n",
    "df['sadness'] = df['sadness'].replace({'\\n\\n': '', 'sad1:': '', 'sad2:': '', 'sad3:': ''}, regex=True)\n",
    "df['happiness'] = df['happiness'].replace({'\\n\\n': '', 'happy1:': '', 'happy2:': '', 'happy3:': ''}, regex=True)\n",
    "df['fear'] = df['fear'].replace({'\\n\\n': '', 'fear1:': '', 'fear2:': '', 'fear3:': ''}, regex=True)\n",
    "df['preprocessed_transcript'] = df['preprocessed_transcript'].replace({'\\n\\n': '', 'happy1:': '', 'happy2:': '', 'happy3:': '', 'sad1:': '', 'sad2:': '', 'sad3:': '', 'fear1:': '', 'fear2:': '', 'fear3:': '', 'anger1:': '', 'anger2:': '', 'anger3:': ''}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "526890aa-437e-4f7e-bece-4c1031939c93",
   "metadata": {
    "id": "526890aa-437e-4f7e-bece-4c1031939c93",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply tokenization to the whole transcript\n",
    "for colname in ['anger', 'fear', 'sadness', 'happiness', 'preprocessed_transcript']:\n",
    "    df[colname+'_token_sents'] = df[colname].apply(lambda x: sent_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "045cfe96-501d-4a87-ab52-8161d4032bac",
   "metadata": {
    "id": "045cfe96-501d-4a87-ab52-8161d4032bac",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate number of tokenized sentences per emotion column\n",
    "for colname in ['anger','fear','sadness','happiness', 'preprocessed_transcript']:\n",
    "    df[colname+'_token_sents_len'] = df[colname+'_token_sents'].apply(len)\n",
    "\n",
    "# Calculate number of tokenized sentences for whole transcript\n",
    "df['total_token_sents_len'] = sum([df[colname+'_token_sents_len'] for colname in ['anger','fear','sadness','happiness', 'preprocessed_transcript']])\n",
    "\n",
    "# Save the results to CSV\n",
    "df[['anger_token_sents_len',\n",
    " 'fear_token_sents_len',\n",
    " 'sadness_token_sents_len',\n",
    " 'happiness_token_sents_len',\n",
    " 'total_token_sents_len']].to_csv(OUT_DIR + 'count_token_sents_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "9e67bf4e-bc15-4d4c-af0a-35d03b1b1efe",
   "metadata": {
    "id": "9e67bf4e-bc15-4d4c-af0a-35d03b1b1efe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['anger','fear', 'sadness', 'happiness', 'preprocessed_transcript']].to_csv(OUT_DIR + r'split_questions_cp_0.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "49a02239",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv = df[['anger', 'fear', 'sadness', 'happiness', \n",
    "          'preprocessed_transcript']].applymap(lambda text: \n",
    "                                               preprocess(text, fillers=fillers, char_map={})).to_csv(sep='\\t')\n",
    "\n",
    "with open(OUT_DIR + r'split_questions_cp_wo_fillers.tsv', 'w') as f:\n",
    "    f.write(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "30b9953a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle(OUT_DIR + 'df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "8da033bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(OUT_DIR + 'df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f65036-dfc8-42df-8cff-a299727c0871",
   "metadata": {
    "id": "12f65036-dfc8-42df-8cff-a299727c0871"
   },
   "source": [
    "# Spacy w2v Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2fd677-a432-43f4-a765-a2adf5ccb8e0",
   "metadata": {
    "id": "fc2fd677-a432-43f4-a765-a2adf5ccb8e0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the German SpaCy model\n",
    "nlp = spacy.load(\"de_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef9a8e6-40f1-44b3-9e17-0a2b6c9dddc6",
   "metadata": {
    "id": "8ef9a8e6-40f1-44b3-9e17-0a2b6c9dddc6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oov = set()\n",
    "\n",
    "def vectorize_sent(text, oov=oov, stopwords=fillers):\n",
    "    doc = nlp(text)\n",
    "#     oovs = set(token.text for token in doc if (token.text not in stopwords\n",
    "#                                                and token.is_oov\n",
    "#                                                and token.pos_ not in ['PUNCT', 'NUM']))\n",
    "#     oov |= oovs\n",
    "    return [token.vector for token in doc if ((token.text not in stopwords\n",
    "                                               and not token.is_oov\n",
    "                                               and token.pos_ not in ['PUNCT', 'NUM']))]\n",
    "\n",
    "def vectorize_turn_history(turn_history, stopwords=fillers):\n",
    "    turns_sentences_word_vectors = [[vectorize_sent(s, stopwords=stopwords) for s in t] for t in turn_history]\n",
    "    sentences_word_vectors = flatten(turns_sentences_word_vectors)\n",
    "    sentence_vectors = [np.mean(t, axis=0) for t in sentences_word_vectors if t]\n",
    "    return sentence_vectors\n",
    "\n",
    "def vectorize_sents(sents, stopwords=fillers):\n",
    "    sentences_word_vectors = [vectorize_sent(s, stopwords=stopwords) for s in sents]\n",
    "    sentence_vectors = [np.mean(t, axis=0) for t in sentences_word_vectors if t]\n",
    "    return sentence_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc208739-600e-43a5-9bb7-0e7e612f0fca",
   "metadata": {
    "id": "bc208739-600e-43a5-9bb7-0e7e612f0fca",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for colname in ['anger','fear','sadness','happiness']:\n",
    "    df[colname+'_sent_vectors'] = df[colname+'_token_sents'].map(vectorize_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa9048d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['preprocessed_transcript_sent_vectors'] = df['preprocessed_transcript_token_sents'].map(vectorize_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cde9d60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(OUT_DIR + 'vec_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c4768",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ex = vectorize_sents(df['fear_token_sents'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065505af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df['fear_token_sents'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267a77ae-0997-43cf-bdc0-ec9835a616eb",
   "metadata": {
    "id": "267a77ae-0997-43cf-bdc0-ec9835a616eb"
   },
   "source": [
    "### Get tokens, total and unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce315de-016b-46de-8fab-4d11cf410246",
   "metadata": {
    "id": "8ce315de-016b-46de-8fab-4d11cf410246",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_text_tokens(text, stopwords=fillers):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_.lower() for token in doc if ((token.text not in stopwords\n",
    "                                             and token.pos_ not in ['PUNCT', 'NUM']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c631f272-7eb7-4b9d-a54e-5860b7400be4",
   "metadata": {
    "id": "c631f272-7eb7-4b9d-a54e-5860b7400be4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for colname in ['anger','fear','sadness','happiness']:\n",
    "    df[colname+'_tokens'] = df[colname].apply(lambda x: get_text_tokens(' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32efed3f-1c73-4ce8-8428-2fa85a7e711c",
   "metadata": {
    "id": "32efed3f-1c73-4ce8-8428-2fa85a7e711c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for colname in ['anger','fear','sadness','happiness']:\n",
    "    df[colname+'_tokens_len'] = df[colname+'_tokens'].apply(len)\n",
    "    df[colname+'_tokens_unique'] = df[colname+'_tokens'].apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8662fc1a-b290-4e60-9eae-5cef71c2f415",
   "metadata": {
    "id": "8662fc1a-b290-4e60-9eae-5cef71c2f415",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['total_tokens_wo_fillers'] = sum([df[colname+'_tokens_len'] for colname in ['anger','fear','sadness','happiness']])\n",
    "df['unique_tokens_wo_fillers'] = sum([df[colname+'_tokens_unique'] for colname in ['anger','fear','sadness','happiness']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ea5d6e-9061-46fb-990e-a3e67c0412a6",
   "metadata": {
    "id": "45ea5d6e-9061-46fb-990e-a3e67c0412a6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['anger_tokens_len',\n",
    " 'anger_tokens_unique',\n",
    " 'fear_tokens_len',\n",
    " 'fear_tokens_unique',\n",
    " 'sadness_tokens_len',\n",
    " 'sadness_tokens_unique',\n",
    " 'happiness_tokens_len',\n",
    " 'happiness_tokens_unique',\n",
    " 'unique_tokens_wo_fillers',\n",
    " 'total_tokens_wo_fillers']].to_csv(OUT_DIR + 'total_tokens_with_stopwords_cp_0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a1082-177a-41ed-94a9-0099189d609c",
   "metadata": {
    "id": "936a1082-177a-41ed-94a9-0099189d609c"
   },
   "source": [
    "### oov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3297811f-6d21-40e3-bb7f-21eca71e9c79",
   "metadata": {
    "id": "3297811f-6d21-40e3-bb7f-21eca71e9c79",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the German SpaCy model\n",
    "# nlp = spacy.load(\"de_core_news_lg\")\n",
    "\n",
    "# Create a set to store OOV words\n",
    "# Uncomment to reset OOV\n",
    "# oov = set()\n",
    "\n",
    "# Create a defaultdict to store OOV words along with their corresponding indices\n",
    "oov2id = defaultdict(list)\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Process the transcript using SpaCy\n",
    "    doc = nlp(row['preprocessed_transcript'])\n",
    "\n",
    "    # Find OOV words and update the set and defaultdict\n",
    "    for token in doc:\n",
    "        if token.is_oov and token.text not in ['PUNCT', 'NUM']:\n",
    "            oov.add(token.text)\n",
    "            oov2id[index].append(token.text)\n",
    "\n",
    "# Create a DataFrame from the defaultdict\n",
    "ids, oovs_for_ids = zip(*((k, ', '.join(v)) for k, v in oov2id.items()))\n",
    "oov_df = pd.DataFrame(index=ids)\n",
    "oov_df['oov'] = oovs_for_ids\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "oov_df.to_csv(OUT_DIR + 'oov_table_spacy_cp_0.csv')\n",
    "\n",
    "# Print the OOV words\n",
    "#print(\"OOV words:\", oov)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9f8e5-3d56-496f-accd-14f7ea24b724",
   "metadata": {
    "id": "e0a9f8e5-3d56-496f-accd-14f7ea24b724"
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140c6a08-381c-4621-881b-24820b240bb0",
   "metadata": {
    "id": "140c6a08-381c-4621-881b-24820b240bb0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I redefine cosine similarity because some standard implementations have precision errors \n",
    "def cos_sim(v1, v2):\n",
    "    return np.inner(v1, v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934aa255-5476-45f4-aa11-18aa9e9fdfd7",
   "metadata": {
    "id": "934aa255-5476-45f4-aa11-18aa9e9fdfd7"
   },
   "source": [
    "### Local Coherence\n",
    "(let i = cosine distance between an averaged vector of the neighbouring clauses)\n",
    "a plot:\n",
    "x axis: number of the current clause\n",
    "y axis: i\n",
    "\n",
    "- the differences between the averages for the groups\n",
    "- the differences between the averages for the averages of the groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a7b5e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_local_coherence(clause_vectors):\n",
    "    if len(clause_vectors) <= 1:\n",
    "        return [np.nan]\n",
    "    local_coherence_list = []\n",
    "    for i in range(len(clause_vectors)-1):\n",
    "        local_coherence_list.append(cos_sim(clause_vectors[i], clause_vectors[i+1]))\n",
    "    return local_coherence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a188eb09-1a96-46a7-af33-55fa7f778024",
   "metadata": {
    "id": "a188eb09-1a96-46a7-af33-55fa7f778024",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for colname in ['anger','fear','sadness','happiness', 'preprocessed_transcript']:\n",
    "    df[f'{colname}_lcoh'] = df[f'{colname}_sent_vectors' ][~pd.isnull(df[f'{colname}_sent_vectors'])].apply(get_local_coherence)\n",
    "    df[f'{colname}_mean_lcoh'] = df[f'{colname}_lcoh'][~pd.isnull(df[f'{colname}_lcoh'])].apply(np.mean)\n",
    "    df[f'{colname}_std_lcoh'] = df[f'{colname}_lcoh'][~pd.isnull(df[f'{colname}_lcoh'])].apply(np.std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08889e3-4501-4ab0-8913-c234d0fbec81",
   "metadata": {
    "id": "b08889e3-4501-4ab0-8913-c234d0fbec81"
   },
   "source": [
    "### Global coherence\n",
    "\n",
    "(let us take a weighted average of each clause, then an average of these centroids in one text, then a average of the averages of all the texts at hand)\n",
    "\n",
    "- cosine distance between the average of all the texts and the average of the current text for each participant\n",
    "- cosine distance between the average of all the control texts and the average of the current text for each participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2bd87e-1078-44f9-ab7c-ea784f42466e",
   "metadata": {
    "id": "4b2bd87e-1078-44f9-ab7c-ea784f42466e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compare_text_to_a_standard_vector(clause_vectors, standard_vector):\n",
    "    \"\"\"\n",
    "    cosine similarity of a given vector and a list of vectors\n",
    "\n",
    "    :param clause_vectors: list of np.arrays (vectors) or a np.array of shape (sent_len, emb_size)\n",
    "    :param standard_vector: np.array of int or float of shape (emb_size)\n",
    "    \"\"\"\n",
    "    average_file_vector = np.average(clause_vectors, axis=0)\n",
    "    return cos_sim(average_file_vector, standard_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f654ca-8175-4b95-9a4c-1871c78a0559",
   "metadata": {
    "id": "27f654ca-8175-4b95-9a4c-1871c78a0559",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_standard_vectors(data, column_name):\n",
    "    \"\"\"\n",
    "    gets average vector across all vectors in a givem column, unlisting them\n",
    "\n",
    "    :param data: pd.Dataframe\n",
    "    :param column_name: str, column with list of lists or np.arrays of int ot float of shape (sent_len, emb_size)\n",
    "    :return: np.array of int or float of shape (emb_size)\n",
    "    \"\"\"\n",
    "    column = data[column_name][~pd.isnull(data[column_name])]\n",
    "    return np.nanmean(np.vstack(flatten(column.values)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8ebf95-44ac-4f0a-a1ed-9e578da083df",
   "metadata": {
    "id": "1e8ebf95-44ac-4f0a-a1ed-9e578da083df",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_global_coherence(clause_vectors, standard_vector):\n",
    "    \"\"\"\n",
    "    calculates global coherence\n",
    "\n",
    "    :param clause_vectors: list of np.arrays (vectors) or a np.array of shape (sent_len, emb_size)\n",
    "    :param standard_vector:  np.array of int or float of shape (emb_size)\n",
    "    :return: list of float of len sent_len, global coherence of each clasue\n",
    "    \"\"\"\n",
    "    if len(clause_vectors) <= 1:\n",
    "        return np.nan\n",
    "    return [cos_sim(vec, standard_vector) for vec in clause_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f2d69f-34bf-47ac-9103-363e5ed8a394",
   "metadata": {
    "id": "c1f2d69f-34bf-47ac-9103-363e5ed8a394",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for colname in ['anger','fear','sadness','happiness', 'preprocessed_transcript']:\n",
    "    standard = get_standard_vectors(df, f'{colname}_sent_vectors')\n",
    "    df[f'{colname}_gcoh'] = df[f'{colname}_sent_vectors'][~pd.isnull(df[f'{colname}_sent_vectors'])].apply(lambda vecs: get_global_coherence(vecs, standard))\n",
    "    df[f'{colname}_mean_gcoh'] = df[f'{colname}_gcoh'][~pd.isnull(df[f'{colname}_gcoh'])].apply(np.mean)\n",
    "    df[f'{colname}_std_gcoh'] = df[f'{colname}_gcoh'][~pd.isnull(df[f'{colname}_gcoh'])].apply(np.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc91133-dd00-42f4-882b-5d63eb47c950",
   "metadata": {
    "id": "0dc91133-dd00-42f4-882b-5d63eb47c950",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['anger_mean_lcoh', 'anger_std_lcoh','fear_mean_lcoh', 'fear_std_lcoh',\n",
    "       'sadness_mean_lcoh', 'sadness_std_lcoh',\n",
    "       'happiness_mean_lcoh', 'happiness_std_lcoh', \n",
    "       'preprocessed_transcript_mean_lcoh', 'preprocessed_transcript_std_lcoh',\n",
    "    'anger_mean_gcoh',\n",
    "       'anger_std_gcoh', 'fear_mean_gcoh', 'fear_std_gcoh',\n",
    "       'sadness_mean_gcoh', 'sadness_std_gcoh',\n",
    "       'happiness_mean_gcoh', 'happiness_std_gcoh',\n",
    "   'preprocessed_transcript_mean_gcoh', 'preprocessed_transcript_std_gcoh']].to_csv(OUT_DIR + 'w2v_results_cp_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1bc878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['anger_mean_lcoh', 'fear_mean_lcoh',\n",
    "    'sadness_mean_lcoh', 'happiness_mean_lcoh', \n",
    "    'anger_mean_gcoh', 'fear_mean_gcoh', \n",
    "    'sadness_mean_gcoh', 'happiness_mean_gcoh']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0b4124-883d-4fb6-ab0d-4dc6d3549dbd",
   "metadata": {
    "id": "1a0b4124-883d-4fb6-ab0d-4dc6d3549dbd"
   },
   "source": [
    "# GloVe vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e3eb02-fef9-4f05-99eb-86ee18afaae5",
   "metadata": {
    "id": "48e3eb02-fef9-4f05-99eb-86ee18afaae5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('vectors.txt', encoding='utf-8') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c62f5ef-a6af-4919-8ba1-bb6f9f1c25eb",
   "metadata": {
    "id": "6c62f5ef-a6af-4919-8ba1-bb6f9f1c25eb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_line(line):\n",
    "    key, str_value = line.strip().split(' ', 1)\n",
    "    return key, np.array([float(x) for x in str_value.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab133b5-024d-4e6b-af60-4a875237c67d",
   "metadata": {
    "id": "bab133b5-024d-4e6b-af60-4a875237c67d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "glove = {}\n",
    "for line in lines:\n",
    "    key, value = process_line(line)\n",
    "    if test_unicode(key):\n",
    "        glove[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0777f35-135e-4911-870e-c29172476f69",
   "metadata": {
    "id": "d0777f35-135e-4911-870e-c29172476f69",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glove_oov = set()\n",
    "def get_glove_vector(word):\n",
    "    if word.lower() in glove:\n",
    "        return glove[word.lower()]\n",
    "    else:\n",
    "        glove_oov.add(word)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e92176c-750e-4818-8431-7de7cc36611d",
   "metadata": {
    "id": "6e92176c-750e-4818-8431-7de7cc36611d",
    "outputId": "1799823c-979c-446f-81fb-776bd0f8769f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_glove_vector('angst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e595e669-ae8c-4020-aba9-bd5c17a92f6e",
   "metadata": {
    "id": "e595e669-ae8c-4020-aba9-bd5c17a92f6e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def vectorize_sent_glove(text, oov=glove_oov):\n",
    "    doc = nlp(text)\n",
    "    oovs = set(token.text for token in doc if token.lemma_.lower() not in glove)\n",
    "    oov |= oovs\n",
    "    return [get_glove_vector(token.lemma_.lower()) for token in doc if (token.pos_ not in ['PUNCT', 'NUM'] and get_glove_vector(token.lemma_.lower()) is not None)]\n",
    "\n",
    "def vectorize_turn_history_glove(turn_history):\n",
    "    turns_sentences_word_vectors = [[vectorize_sent_glove(s) for s in t] for t in turn_history]\n",
    "    sentences_word_vectors = flatten(turns_sentences_word_vectors)\n",
    "    sentence_vectors = [np.mean(t, axis=0) for t in sentences_word_vectors if t]\n",
    "    return sentence_vectors\n",
    "\n",
    "def vectorize_sents_glove(sents, stopwords=fillers):\n",
    "    sentences_word_vectors = [vectorize_sent_glove(s, oov=glove_oov) for s in sents]\n",
    "    sentence_vectors = [np.mean(t, axis=0) for t in sentences_word_vectors if t]\n",
    "    return sentence_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80afafc6-7644-4475-a4e8-3521a26e6e0b",
   "metadata": {
    "id": "80afafc6-7644-4475-a4e8-3521a26e6e0b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for colname in ['anger','fear','sadness','happiness', 'preprocessed_transcript']:\n",
    "    df[colname+'_glove_sent_vectors'] = df[colname+'_token_sents'].apply(vectorize_sents_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabc92f4-87d5-4f37-a6bd-2bf5e8878925",
   "metadata": {
    "id": "aabc92f4-87d5-4f37-a6bd-2bf5e8878925",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for colname in ['anger','fear','sadness','happiness', 'preprocessed_transcript']:\n",
    "    df[f'{colname}_glove_lcoh'] = df[f'{colname}_glove_sent_vectors' ][~pd.isnull(df[f'{colname}_glove_sent_vectors' ])].apply(get_local_coherence)\n",
    "    df[f'{colname}_glove_mean_lcoh'] = df[f'{colname}_glove_lcoh'][~pd.isnull(df[f'{colname}_glove_lcoh'])].apply(np.mean)\n",
    "    df[f'{colname}_glove_std_lcoh'] = df[f'{colname}_glove_lcoh'][~pd.isnull(df[f'{colname}_glove_lcoh'])].apply(np.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358348eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['anger_glove_sent_vectors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692ba3bd-ab11-44df-8f48-3ad2d765fd6f",
   "metadata": {
    "id": "692ba3bd-ab11-44df-8f48-3ad2d765fd6f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for colname in ['anger','fear','sadness','happiness', 'preprocessed_transcript']:\n",
    "    standard = get_standard_vectors(df, f'{colname}_glove_sent_vectors')\n",
    "    df[f'{colname}_glove_gcoh'] = df[f'{colname}_glove_sent_vectors'][~pd.isnull(df[f'{colname}_glove_sent_vectors'])].apply(lambda vecs: get_global_coherence(vecs, standard))\n",
    "    df[f'{colname}_glove_mean_gcoh'] = df[f'{colname}_glove_gcoh'][~pd.isnull(df[f'{colname}_glove_gcoh'])].apply(np.mean)\n",
    "    df[f'{colname}_glove_std_gcoh'] = df[f'{colname}_glove_gcoh'][~pd.isnull(df[f'{colname}_glove_gcoh'])].apply(np.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754597f1-8885-4d0a-9d6a-87316e280db5",
   "metadata": {
    "id": "754597f1-8885-4d0a-9d6a-87316e280db5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['anger_glove_mean_lcoh', 'anger_glove_std_lcoh','fear_glove_mean_lcoh', 'fear_glove_std_lcoh',\n",
    "       'sadness_glove_mean_lcoh', 'sadness_glove_std_lcoh',\n",
    "       'happiness_glove_mean_lcoh', 'happiness_glove_std_lcoh',\n",
    "   'preprocessed_transcript_glove_mean_lcoh', 'preprocessed_transcript_glove_mean_lcoh',\n",
    "    'anger_glove_mean_gcoh',\n",
    "       'anger_glove_std_gcoh', 'fear_glove_mean_gcoh', 'fear_glove_std_gcoh',\n",
    "       'sadness_glove_mean_gcoh', 'sadness_glove_std_gcoh',\n",
    "       'happiness_glove_mean_gcoh', 'happiness_glove_std_gcoh',\n",
    "   'preprocessed_transcript_glove_mean_gcoh', 'preprocessed_transcript_glove_mean_gcoh']].to_csv(OUT_DIR + 'glove_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4fa451-0240-47f2-8c95-da07f0fa4779",
   "metadata": {
    "id": "7b4fa451-0240-47f2-8c95-da07f0fa4779",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle(OUT_DIR + 'net.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded09cdf-e700-4b36-bbfa-64b1f2a745a1",
   "metadata": {
    "id": "ded09cdf-e700-4b36-bbfa-64b1f2a745a1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6f69eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['anger_glove_mean_lcoh', 'fear_glove_mean_lcoh', 'sadness_glove_mean_lcoh', 'happiness_glove_mean_lcoh', \n",
    "    'anger_glove_mean_gcoh', 'fear_glove_mean_gcoh', 'sadness_glove_mean_gcoh', 'happiness_glove_mean_gcoh']]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
