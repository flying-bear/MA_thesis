{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98d5e3a",
   "metadata": {},
   "source": [
    "# Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "243abe99",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f58a50c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288a9339",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45a3c435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices\n",
    "from scipy import stats\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a71cf51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_utils import style, mean_std, display_test, display_group_test, \\\n",
    "    scatter_annotate, show_corrtest_mask_corr, pointplot, pointplot_horizontal, add_grey, \\\n",
    "    prep_horizontal_pointplot_errobar_data, map_model, prep_LM_pointplot, draw_sample_with_replacement, t_test\n",
    "from ortogonolize_utils import compute_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4f7917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=np.VisibleDeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore', message='All-NaN slice encountered')\n",
    "warnings.filterwarnings(action='ignore', message='Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.')\n",
    "warnings.filterwarnings(action='ignore', message='Mean of empty slice')\n",
    "warnings.filterwarnings(action='ignore', category=stats.ConstantInputWarning)\n",
    "warnings.filterwarnings(action='ignore', message='indexing past lexsort depth may impact performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe37e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4bb2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/Users/galina.ryazanskaya/Downloads/thesis?/code?/processed_values'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8665931",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_FIG = '/Users/galina.ryazanskaya/Downloads/thesis?/figures/de/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ed4dd1",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6091e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_averaged = pd.read_csv('/Users/galina.ryazanskaya/Downloads/thesis?/code?/processed_values/de_averaged.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23339b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_averaged.columns = [c if '(' not in c else ast.literal_eval(c) for c in combined_data_averaged.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8e780f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_all = pd.read_csv('/Users/galina.ryazanskaya/Downloads/thesis?/code?/processed_values/de_all.csv', index_col=0, header=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd631e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS = ['anger', 'fear', 'happiness', 'sadness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ebee551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_data(df, task, keep_target=True, fill_synt=True):\n",
    "    subset = df[task].dropna(axis=0, how='any')\n",
    "    if task == 'fear' and 'KG_018' in subset.index:\n",
    "        subset = subset.drop(['KG_018'])   # incorrect task\n",
    "    if fill_synt:\n",
    "        subset['syntactic'] = subset['syntactic'].fillna(0.0)\n",
    "    if keep_target:\n",
    "        subset = pd.concat([subset, df['target'].loc[subset.index]], axis=1)\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ff475a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplly_to_all_tasks(df, f, tasks=TASKS, to_df=True, *args, **kwargs):\n",
    "    res = {}\n",
    "    for task in tasks:\n",
    "        data = task_data(df, task)\n",
    "        res[task] = f(data, *args, **kwargs)\n",
    "    if to_df:\n",
    "        if all(isinstance(v, pd.Series) for v in res.values()):\n",
    "            return pd.DataFrame(res)\n",
    "        elif all(isinstance(v, pd.DataFrame) for v in res.values()):\n",
    "            return pd.concat(list(res.values()), keys=list(res.keys()), names=['task'], axis=1)\n",
    "        else:\n",
    "            return res\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad915ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_means = combined_data_all.groupby([('target', 'target', 'group')]).mean().T\n",
    "group_means.columns = ['control', 'NAP']\n",
    "group_means.index.rename(['task', 'feature_group', 'feature'], inplace=True)\n",
    "group_means.to_csv(\"feature_means_de.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef22de1d",
   "metadata": {},
   "source": [
    "# Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9927af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_cols = ['saps_total',\n",
    "             'sans_total',\n",
    "             'panss_pos',\n",
    "             'panss_neg',\n",
    "             'panss_o',\n",
    "             'panss_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14b96d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_LM = [col for col in combined_data_averaged.columns if col[0] == 'LM']\n",
    "cols_synt = [col for col in combined_data_averaged.columns if col[0] == 'syntactic']\n",
    "cols_lex = [col for col in combined_data_averaged.columns if col[0] == 'lexical']\n",
    "cols_graph = [col for col in combined_data_averaged.columns if col[0] == 'graph']\n",
    "cols_av = cols_LM + cols_synt + cols_lex + cols_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17e44cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_correct_for = [('syntactic', 'mean_sent_len'), ('syntactic', 'n_sents'), ('lexical', 'n_words')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea75aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1 sample with replacement\n",
    "## 1.1 compute r for each scale for each iteration\n",
    "## 1.2 compute t test for each iteration\n",
    "\n",
    "def bootstrap_with_corrections(df, cols_av, scale_cols, N, columns_to_correct_for=cols_to_correct_for, group=None):\n",
    "    correction_corr_names = tuple(f'r_corr_w_{x[-1]}' for x in columns_to_correct_for)\n",
    "    dict_scales_sapmles = {k: {scale: {metric: [] for metric in cols_av} for scale in scale_cols} \\\n",
    "                           for k in ('sample_raw', 'r', 't') + correction_corr_names}\n",
    "    for i in tqdm(range(N)):\n",
    "        sample = draw_sample_with_replacement(df, seed=i)\n",
    "        for scale in scale_cols:\n",
    "            for col in cols_av:\n",
    "                if group:\n",
    "                    t_test_res = t_test(sample, col, group)\n",
    "                    dict_scales_sapmles['t'][scale][col].append(t_test_res)\n",
    "                    \n",
    "                r_raw = compute_coefficient(sample, scale, col)[0]\n",
    "                dict_scales_sapmles['sample_raw'][scale][col].append(r_raw)\n",
    "                \n",
    "                droped = sample.dropna(subset=[col, scale])\n",
    "                r = stats.pearsonr(droped[col], droped[scale])[0]\n",
    "                dict_scales_sapmles['r'][scale][col].append(r)\n",
    "                for col_to_correct_for in columns_to_correct_for:\n",
    "                    if col != col_to_correct_for:\n",
    "                        droped_c = sample.dropna(subset=[col, col_to_correct_for])\n",
    "                        r_c = stats.pearsonr(droped_c[col], droped_c[col_to_correct_for])[0]\n",
    "                        dict_scales_sapmles[f'r_corr_w_{col_to_correct_for[-1]}'][scale][col].append(r_c)\n",
    "                    \n",
    "    return dict_scales_sapmles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1292b7b1",
   "metadata": {},
   "source": [
    "**expensive to compute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "a74b3c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 1000\n",
    "# dict_scales_sapmles = bootstrap_with_corrections(combined_data_averaged, cols_av, \n",
    "#                                                  scale_cols, N, \n",
    "#                                                  columns_to_correct_for=cols_to_correct_for, \n",
    "#                                                  group='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "9853b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reform_v = {(scale, measure): dict_scales_sapmles[measure][scale] for scale in scale_cols for measure in dict_scales_sapmles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "390b94bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('processed_values/de_scales_samples_w_verbosity.pickle', 'wb') as f:\n",
    "#     pickle.dump(reform_v, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "967e5396",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_values/de_scales_samples_w_verbosity.pickle', 'rb') as f:\n",
    "    reform_v = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a6c01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "reformed_d_w_verbosity = pd.DataFrame(reform_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb7105c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1 sample with replacement\n",
    "## 1.1 compute r for each scale for each iteration\n",
    "## 1.2 compute t test for each iteration\n",
    "\n",
    "def bootstrap(df, cols_av, scale_cols, N, col_to_correct_for=('syntactic', 'mean_sent_len'), group=None):\n",
    "    dict_scales_sapmles = {k: {scale: {metric: [] for metric in cols_av} for scale in scale_cols} \\\n",
    "                           for k in ('sample_raw', 'r', 't', 'r_corr_w_control')}\n",
    "    for i in tqdm(range(N)):\n",
    "        sample = draw_sample_with_replacement(df, seed=i)\n",
    "        for scale in scale_cols:\n",
    "            for col in cols_av:\n",
    "                if group:\n",
    "                    t_test_res = t_test(sample, col, group)\n",
    "                    dict_scales_sapmles['t'][scale][col].append(t_test_res)\n",
    "                    \n",
    "                r_raw = compute_coefficient(sample, scale, col)[0]\n",
    "                dict_scales_sapmles['sample_raw'][scale][col].append(r_raw)\n",
    "                \n",
    "                droped = sample.dropna(subset=[col, scale])\n",
    "                r = stats.pearsonr(droped[col], droped[scale])[0]\n",
    "                dict_scales_sapmles['r'][scale][col].append(r)\n",
    "                \n",
    "                if col != col_to_correct_for:\n",
    "                    \n",
    "                    droped_c = sample.dropna(subset=[col, col_to_correct_for])\n",
    "                    r_c = stats.pearsonr(droped_c[col], droped_c[col_to_correct_for])[0]\n",
    "                    dict_scales_sapmles['r_corr_w_control'][scale][col].append(r_c)\n",
    "                    \n",
    "    return dict_scales_sapmles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18d46a3",
   "metadata": {},
   "source": [
    "**expensive to compute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "cdec6c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 1000\n",
    "# dict_scales_sapmles = bootstrap(combined_data_averaged, cols_av, scale_cols, N, col_to_correct_for=('syntactic', 'mean_sent_len'), group='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "c5c428cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reform = {(scale, measure): dict_scales_sapmles[measure][scale] for scale in scale_cols for measure in dict_scales_sapmles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "4bb500a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('processed_values/de_scales_samples_wo_o.pickle', 'wb') as f:\n",
    "#     pickle.dump(reform, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f53035f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_values/de_scales_samples_wo_o.pickle', 'rb') as f:\n",
    "    reform = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d658f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "reformed_d = pd.DataFrame(reform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9a5aae",
   "metadata": {},
   "source": [
    "### Bootstrap for each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "498cf2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_tasks_with_corrections(df, cols_av, scale_cols, N, columns_to_correct_for=cols_to_correct_for, group=None):\n",
    "    correction_corr_names = tuple(f'r_corr_w_{x[-1]}' for x in columns_to_correct_for)\n",
    "    res_c = ('sample_raw', 'r', 't') + correction_corr_names\n",
    "    dict_scales_sapmles = {k: {scale: {metric: [] for metric in cols_av} for scale in scale_cols} for k in res_c}\n",
    "    for i in tqdm(range(N)):\n",
    "        sample = draw_sample_with_replacement(df, seed=i)\n",
    "        scale_independent = {k: {metric: [] for metric in cols_av} for k in ('t', ) + correction_corr_names}\n",
    "        for col in cols_av:\n",
    "            if group:\n",
    "                t_test_res = t_test(sample, col, group)\n",
    "                scale_independent['t'][col].append(t_test_res)\n",
    "            for col_to_correct_for in cols_to_correct_for:\n",
    "                if col != col_to_correct_for:\n",
    "                    dropped_c = sample.dropna(subset=[col, col_to_correct_for])\n",
    "                    r_c = stats.pearsonr(dropped_c[col], dropped_c[col_to_correct_for])[0]\n",
    "                    scale_independent[f'r_corr_w_{col_to_correct_for[-1]}'][col] = r_c\n",
    "            for scale in scale_cols:\n",
    "                scale_ = ('target', scale)\n",
    "                r_raw = compute_coefficient(sample, scale_, col)[0]\n",
    "                dict_scales_sapmles['sample_raw'][scale][col].append(r_raw)\n",
    "                \n",
    "                dropped = sample.dropna(subset=[col, scale_])\n",
    "                r = stats.pearsonr(dropped[col], dropped[scale_])[0]\n",
    "                dict_scales_sapmles['r'][scale][col].append(r)\n",
    "                               \n",
    "                for k in scale_independent:\n",
    "                    dict_scales_sapmles[k][scale][col].append(scale_independent[k][col])\n",
    "                \n",
    "    return dict_scales_sapmles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2285663a",
   "metadata": {},
   "source": [
    "**expensive to compute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "afbff1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 1000\n",
    "# dict_scales_sapmles_tasks = aplly_to_all_tasks(combined_data_all, bootstrap_tasks_with_corrections, cols_av=cols_av, scale_cols=scale_cols, N=N, columns_to_correct_for=cols_to_correct_for, group=('target', 'group'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "a508d851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reform_tasks_v = {(task, scale, measure): dict_scales_sapmles_tasks[task][measure][scale] for scale in scale_cols \n",
    "#                 for task in dict_scales_sapmles_tasks\n",
    "#                 for measure in dict_scales_sapmles_tasks[task]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "665ed863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('processed_values/de_scales_samples_wo_o_tasks_w_verbosity.pickle', 'wb') as f:\n",
    "#     pickle.dump(reform_tasks_v, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb8cc7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_values/de_scales_samples_wo_o_tasks_w_verbosity.pickle', 'rb') as f:\n",
    "    reform_tasks_v = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7d8ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reformed_tasks_v = pd.DataFrame(reform_tasks_v)\n",
    "reformed_tasks_v.columns.names = ['TASK', 'scale', 'measure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b10babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_tasks(df, cols_av, scale_cols, N, col_to_correct_for=('syntactic', 'mean_sent_len'), group=None):\n",
    "    res_c = ('sample_raw', 'r', 't', 'r_corr_w_control')\n",
    "    dict_scales_sapmles = {k: {scale: {metric: [] for metric in cols_av} for scale in scale_cols} for k in res_c}\n",
    "    for i in tqdm(range(N)):\n",
    "        sample = draw_sample_with_replacement(df, seed=i)\n",
    "        scale_independent = {k: {metric: [] for metric in cols_av} for k in ('t', 'r_corr_w_control')}\n",
    "        for col in cols_av:\n",
    "            if group:\n",
    "                t_test_res = t_test(sample, col, group)\n",
    "                scale_independent['t'][col].append(t_test_res)\n",
    "            if col != col_to_correct_for:\n",
    "                dropped_c = sample.dropna(subset=[col, col_to_correct_for])\n",
    "                r_c = stats.pearsonr(dropped_c[col], dropped_c[col_to_correct_for])[0]\n",
    "                scale_independent['r_corr_w_control'][col] = r_c\n",
    "            for scale in scale_cols:\n",
    "                scale_ = ('target', scale)\n",
    "                r_raw = compute_coefficient(sample, scale_, col)[0]\n",
    "                dict_scales_sapmles['sample_raw'][scale][col].append(r_raw)\n",
    "                \n",
    "                dropped = sample.dropna(subset=[col, scale_])\n",
    "                r = stats.pearsonr(dropped[col], dropped[scale_])[0]\n",
    "                dict_scales_sapmles['r'][scale][col].append(r)\n",
    "                               \n",
    "                for k in scale_independent:\n",
    "                    dict_scales_sapmles[k][scale][col].append(scale_independent[k][col])\n",
    "                \n",
    "    return dict_scales_sapmles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9e7daa",
   "metadata": {},
   "source": [
    "**expensive to compute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "9661c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 1000\n",
    "# dict_scales_sapmles_tasks = aplly_to_all_tasks(combined_data_all, bootstrap_tasks, cols_av=cols_av, scale_cols=scale_cols, N=N, col_to_correct_for=('syntactic', 'mean_sent_len'), group=('target', 'group'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "b009adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reform_tasks = {(task, scale, measure): dict_scales_sapmles_tasks[task][measure][scale] for scale in scale_cols \n",
    "#                 for task in dict_scales_sapmles_tasks\n",
    "#                 for measure in dict_scales_sapmles_tasks[task]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "11175210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('processed_values/de_scales_samples_wo_o_tasks.pickle', 'wb') as f:\n",
    "#     pickle.dump(reform_tasks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "725b7547",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_values/de_scales_samples_wo_o_tasks.pickle', 'rb') as f:\n",
    "    reform_tasks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de4985de",
   "metadata": {},
   "outputs": [],
   "source": [
    "reformed_tasks = pd.DataFrame(reform_tasks)\n",
    "reformed_tasks.columns.names = ['TASK', 'scale', 'measure']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399775b6",
   "metadata": {},
   "source": [
    "# Plot & Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37df6a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "figprms = {'syntactic': \n",
    "               {'subplot_size': (9, 4.5),\n",
    "                'wspace': 0.25,\n",
    "                'hspace': 0.125,\n",
    "                'yt': 0.925\n",
    "                }, \n",
    "           'LM': \n",
    "               {'subplot_size': (9, 5.5),\n",
    "                'wspace': 0.275,\n",
    "                'hspace': 0.125,\n",
    "                'yt': 0.92\n",
    "               }, \n",
    "           'lexical': \n",
    "               {'subplot_size': (9, 2),\n",
    "                'wspace': 0.2,\n",
    "                'hspace': 0.25,\n",
    "                'yt': 0.925\n",
    "               }, \n",
    "           'graph': \n",
    "               {'subplot_size': (9, 3.5), \n",
    "                'wspace': 0.3,\n",
    "                'hspace': 0.125,\n",
    "                'yt': 0.925\n",
    "               }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60c0dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fparams(m_type, n_sublots_height, n_sublots_width, figparams):\n",
    "    subplot_size = figprms[m_type]['subplot_size']\n",
    "    width = subplot_size[0] * n_sublots_width\n",
    "    height = subplot_size[1] * n_sublots_height\n",
    "    figsize = (width, height)\n",
    "    wspace = figprms[m_type]['wspace']\n",
    "    hspace = figprms[m_type]['hspace']\n",
    "    yt = figprms[m_type]['yt']\n",
    "    return figsize, wspace, hspace, yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81e93fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORDERED_SCALES = ['panss_pos', 'panss_neg', 'panss_o', 'panss_total', 'saps_total', 'sans_total']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c1c203",
   "metadata": {},
   "source": [
    "### Plot horizontal bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "d86fc32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_horizontal_tasks(df, title, measure, m_type='syntactic', plot_abs=False, figparams=figprms):\n",
    "    figsize, wspace, hspace, yt = get_fparams(m_type, 3, 2, figparams)\n",
    "    fig, axes = plt.subplots(3, 2, figsize=figsize, sharex=True)\n",
    "    fig.suptitle(title, y=yt+0.25)\n",
    "    plt.subplots_adjust(wspace=wspace) #left=None, bottom=None, right=None, top=None, wspace=None, hspace=None)\n",
    "    \n",
    "    ab = 'abs ' if plot_abs else ''\n",
    "    \n",
    "    axs = axes.flatten()\n",
    "\n",
    "    for i, scale in enumerate(ORDERED_SCALES):\n",
    "        ax = axs[i]\n",
    "        d = prep_horizontal_pointplot_errobar_data(df[scale].loc[m_type], measure, plot_abs=plot_abs)\n",
    "        pointplot_horizontal(d, x=measure, ax=ax)\n",
    "        ax.set_title(f'{ab}{measure} {scale}')\n",
    "    \n",
    "    add_grey(axes)\n",
    "\n",
    "    if plot_abs:\n",
    "        for ax in axes.reshape(-1): \n",
    "            ax.set_xlabel('abs ' + measure);\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e796797",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbosity_control_cols = ['r_corr_w_mean_sent_len', 'r_corr_w_n_sents', 'r_corr_w_n_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24b0faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_col_names = ['mean sentence length', 'sentence count', 'word count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "0a3fbc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all(df, m_type='syntactic', measure='r', path=PATH_FIG, dpi=150, plot_abs=False, figparams=figprms,\n",
    "                         control_cols=['r_corr_w_control'], control_col_names=['mean sentence length']):\n",
    "    ab = 'abs_' if plot_abs else ''\n",
    "    absolute_value = f' (absolute {measure} value)' if plot_abs else ''\n",
    "    if len(control_cols) != len(control_col_names):\n",
    "        raise ValueError('The names of the columns must match the columns in length.')\n",
    "        \n",
    "    fig = plot_horizontal_tasks(df, title=f'cross-scale comparison for {m_type} metrics{absolute_value}', \n",
    "                                measure=measure, m_type=m_type, plot_abs=plot_abs, figparams=figprms)\n",
    "    plt.savefig(f'{path}{m_type}/{ab}scale_r.png', dpi=dpi)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    figsize, wspace, hspace, yt = get_fparams(m_type, 1, 1, figparams)\n",
    "    d_t = prep_horizontal_pointplot_errobar_data(df['panss_o'].loc[m_type], 't')\n",
    "    d_t['t'] = d_t['t'] * -1\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    fig.suptitle(f'group difference (t-test) for {m_type} metrics')\n",
    "    pointplot_horizontal(d_t, 't', ax=ax)\n",
    "    add_grey(ax, r=2)\n",
    "    plt.savefig(f'{path}{m_type}/t.png', dpi=dpi, bbox_inches = 'tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    figsize, wspace, hspace, yt = get_fparams(m_type, len(control_cols), 1, figparams)\n",
    "    fig, axes = plt.subplots(len(control_cols), figsize=figsize)\n",
    "    fig.suptitle(f'correlation with verbosity for {m_type} metrics', y=yt-0.02)\n",
    "    plt.subplots_adjust(wspace=wspace, hspace=hspace+0.08)\n",
    "    for i, control_col in enumerate(control_cols):\n",
    "        ax = axes[i] if len(control_cols) > 1 else axes\n",
    "        name = control_col_names[i]\n",
    "        d_c = prep_horizontal_pointplot_errobar_data(df['panss_o'].loc[m_type], control_col)\n",
    "\n",
    "        pointplot_horizontal(d_c, control_col, ax=ax)\n",
    "        ax.set_title(f'correlation with {name}');\n",
    "        ax.set_xlabel('r');\n",
    "        add_grey(ax)\n",
    "    plt.savefig(f'{path}{m_type}/corr_verbosity.png', dpi=dpi, bbox_inches = 'tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    figsize, wspace, hspace, yt = get_fparams(m_type, len(control_cols), 2, figparams)\n",
    "    fig, axes = plt.subplots(len(control_cols), 2, figsize=figsize)\n",
    "    fig.suptitle(f'group difference and correlation with verbosity for {m_type} metrics', y=yt+0.02)\n",
    "    plt.subplots_adjust(wspace=wspace, hspace=hspace+0.2)\n",
    "    for i, control_col in enumerate(control_cols):\n",
    "        ax = axes[i, 0] if len(control_cols) > 1 else axes[0]\n",
    "        name = control_col_names[i]\n",
    "        d_c = prep_horizontal_pointplot_errobar_data(df['panss_o'].loc[m_type], control_col)\n",
    "\n",
    "        pointplot_horizontal(d_c, control_col, ax=ax)\n",
    "        ax.set_title(f'correlation with {name}');\n",
    "        ax.set_xlabel('r');\n",
    "        add_grey(ax)\n",
    "\n",
    "        ax_2 = axes[i, 1] if len(control_cols) > 1 else axes[1]\n",
    "        pointplot_horizontal(d_t, x='t', ax=ax_2)\n",
    "        ax_2.set_title('group difference (t-test)')\n",
    "        add_grey(ax_2, r=2)\n",
    "    plt.savefig(f'{path}{m_type}/t_test_corr_verbosity.png', dpi=dpi, bbox_inches = 'tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "fa827fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m_type in reformed_d.index.unique(level=0):\n",
    "    plot_all(reformed_d_w_verbosity, m_type, plot_abs=True,\n",
    "                                 control_cols=verbosity_control_cols, control_col_names=control_col_names)\n",
    "    plot_all(reformed_d_w_verbosity, m_type, plot_abs=False,\n",
    "                                 control_cols=verbosity_control_cols, control_col_names=control_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "629b6a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m_type in reformed_d.index.unique(level=0):\n",
    "    plot_all(reformed_d, m_type, plot_abs=True)\n",
    "    plot_all(reformed_d, m_type, plot_abs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365d42f1",
   "metadata": {},
   "source": [
    "### Plot vertical bar plots for LMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f7c289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['bert', 'glove_tf', 'glove_avg', 'w2v_tf', 'w2v_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "841b7554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_LM_scales(df, title, measure='r', plot_abs=False, figsize=(18, 18), order=order):\n",
    "    ab = 'abs ' if plot_abs else ''\n",
    "    absolute_value = f' (absolute {measure} value)' if plot_abs else ''\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 2, figsize=figsize, sharey=True)\n",
    "    fig.suptitle(title + absolute_value, y=0.91)\n",
    "    plt.subplots_adjust(wspace=0.075)\n",
    "    \n",
    "    axs = axes.flatten()\n",
    "    for i, scale in enumerate(ORDERED_SCALES):\n",
    "        ax = axs[i]\n",
    "        d = prep_LM_pointplot(df.loc['LM', scale], measure, plot_abs=plot_abs)\n",
    "        pointplot(d, x='model', y=measure, hue='metric', ax=ax, order=order, use_errorbar=True)\n",
    "        ax.set_title(f'{ab}{measure} {scale}')\n",
    "    \n",
    "    add_grey(axes, line_dir='h')\n",
    "    if plot_abs:\n",
    "        for ax in axes.reshape(-1): \n",
    "            ax.set_ylabel('abs ' + measure);\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "abdcefe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_LM(df, path=PATH_FIG, dpi=150, plot_abs=False, figsize=(9, 9), measure='r',\n",
    "                         control_cols=['r_corr_w_control'], control_col_names=['mean sentence length'],\n",
    "               figparams=figprms):\n",
    "    \n",
    "    ab = 'abs_' if plot_abs else ''\n",
    "    if len(control_cols) != len(control_col_names):\n",
    "        raise ValueError('The names of the columns must match the columns in length.')\n",
    "    \n",
    "    fig = plot_LM_scales(df, 'cross-scale comparison of LM metrcis across models', plot_abs=plot_abs)\n",
    "    plt.savefig(f'{path}LM/model/{ab}scale_r.png', dpi=dpi, bbox_inches = 'tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    d_lm_t = prep_LM_pointplot(df.loc['LM', 'panss_o'], 't')\n",
    "    d_lm_t['t'] = d_lm_t['t'] * -1\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    fig.suptitle('group difference (t-test) for LM metrcis across models')\n",
    "    pointplot(d_lm_t, x='model', y='t', hue='metric', ax=ax, order=order, use_errorbar=True)\n",
    "    add_grey(ax, r=2, line_dir='h')\n",
    "    plt.savefig(f'{path}LM/model/t.png', dpi=dpi, bbox_inches = 'tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    absolute_value = f' (absolute {measure} value)' if plot_abs else ''\n",
    "    figsize, wspace, hspace, yt = get_fparams(m_type, len(control_cols), 1, figparams)\n",
    "    fig, axes = plt.subplots(len(control_cols), 1, figsize=(9, 15))\n",
    "    fig.suptitle('correlation with verbosity for LM metrcis across models' + absolute_value, y=yt-0.01)\n",
    "    plt.subplots_adjust(hspace=hspace+0.1)\n",
    "    for i, control_col in enumerate(control_cols):\n",
    "        name = control_col_names[i]\n",
    "        ax = axes[i] if len(control_cols) > 1 else axes\n",
    "        d_lm_c = prep_LM_pointplot(df.loc['LM', 'panss_o'], control_col, plot_abs=plot_abs)\n",
    "        pointplot(d_lm_c, x='model', y=control_col, hue='metric', ax=ax, order=order, use_errorbar=True)\n",
    "        ax.set_title(f'correlation with {name}')\n",
    "        add_grey(ax, line_dir='h');\n",
    "    plt.savefig(f'{path}LM/model/{ab}corr_verbosity.png', dpi=dpi, bbox_inches = 'tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "\n",
    "    figsize, wspace, hspace, yt = get_fparams(m_type, len(control_cols), 2, figparams)\n",
    "    fig, axes = plt.subplots(len(control_cols), 2, figsize=(18, 15))\n",
    "    fig.suptitle('correlation with verbosity for LM metrcis across models' + absolute_value, y=yt-0.01)\n",
    "    plt.subplots_adjust(wspace=wspace-0.18, hspace=hspace+0.08)\n",
    "    for i, control_col in enumerate(control_cols):\n",
    "        name = control_col_names[i]\n",
    "        ax = axes[i, 0] if len(control_cols) > 1 else axes[0]\n",
    "        d_lm_c = prep_LM_pointplot(df.loc['LM', 'panss_o'], control_col, plot_abs=plot_abs)\n",
    "        pointplot(d_lm_c, x='model', y=control_col, hue='metric', ax=ax, order=order, use_errorbar=True)\n",
    "        ax.set_title(f'correlation with {name}')\n",
    "        add_grey(ax, line_dir='h');\n",
    "\n",
    "        ax_2 = axes[i, 1] if len(control_cols) > 1 else axes[1]\n",
    "        pointplot(d_lm_t, x='model', y='t', hue='metric', ax=ax_2, order=order, use_errorbar=True)\n",
    "        ax_2.set_title('group difference (t-test)')\n",
    "        add_grey(ax_2, r=2, line_dir='h')\n",
    "    plt.savefig(f'{path}LM/model/t_test_corr_verbosity.png', dpi=dpi, bbox_inches = 'tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "a4a1626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_LM(reformed_d_w_verbosity, plot_abs=True, \n",
    "            control_cols=verbosity_control_cols, control_col_names=control_col_names)\n",
    "plot_all_LM(reformed_d_w_verbosity, plot_abs=False,\n",
    "            control_cols=verbosity_control_cols, control_col_names=control_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "48e9cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_LM(reformed_d, plot_abs=True)\n",
    "plot_all_LM(reformed_d, plot_abs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd53290",
   "metadata": {},
   "source": [
    "## Cross-metric comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3495b9db",
   "metadata": {},
   "source": [
    "### R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "ea673ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ok_metrics(row, t=1, r=0.3, rc=0.3):\n",
    "    ok_corr = False\n",
    "    ok_t = abs(row['saps_total', 't']) >= t\n",
    "    ok_len = pd.isna(row['saps_total', 'r_corr_w_control']) or abs(row['saps_total', 'r_corr_w_control']) <= rc\n",
    "    for scale in scale_cols:\n",
    "        if abs(row[scale, 'r']) >= r:\n",
    "            ok_corr = True \n",
    "            break\n",
    "    return (ok_corr or ok_t) and ok_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "e17cc068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ok_metrics_for_one_scale(row, scale, r=0.3, rc=0.3):\n",
    "    ok_corr = False\n",
    "    ok_len = pd.isna(row['panss_total', 'r_corr_w_control']) or abs(row['panss_total', 'r_corr_w_control']) <= rc\n",
    "    ok_corr = abs(row[scale, 'r']) >= r\n",
    "    return ok_corr and ok_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "c3770c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_control_corr_ms_better_than_len(row, row_len, r=0.3, rc=0.3):\n",
    "    if select_ok_metrics(row, r=r, rc=rc):\n",
    "        return False\n",
    "    ok_len = pd.isna(row['saps_total', 'r_corr_w_control']) or abs(row['saps_total', 'r_corr_w_control']) <= rc\n",
    "    if ok_len:\n",
    "        return False\n",
    "    else:\n",
    "        for scale in scales_:\n",
    "            if abs(row[scale, 'r']) >= abs(row_len[scale, 'r']):\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "0991fd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_control_corr_ms_better_than_len_for_one_scale(row, row_len, scale, r=0.3, rc=0.3):\n",
    "    if select_ok_metrics(row, r=r, rc=rc):\n",
    "        return False\n",
    "    ok_len = pd.isna(row['saps_total', 'r_corr_w_control']) or abs(row['saps_total', 'r_corr_w_control']) <= rc\n",
    "    if ok_len:\n",
    "        return False\n",
    "    else:\n",
    "        if abs(row[scale, 'r']) >= abs(row_len[scale, 'r']) and abs(row[scale, 'r']) > r:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "7f38a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_bad_len_metrics(row, rc=0.3):\n",
    "    ok_len = pd.isna(row['panss_total', 'r_corr_w_control']) or abs(row['panss_total', 'r_corr_w_control']) <= rc\n",
    "    return not ok_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6e5758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_d = reformed_d.applymap(np.nanmedian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab309874",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs_scale = {}\n",
    "idxs_bad_bet_len = {}\n",
    "for scale in scale_cols:\n",
    "    ids = median_d[median_d.apply(lambda x: select_ok_metrics_for_one_scale(x, scale=scale), axis=1)].index\n",
    "    idxs_scale[scale] = ids\n",
    "    idsl = median_d[median_d.apply(lambda x: select_control_corr_ms_better_than_len_for_one_scale(x, \n",
    "                                                                                                  row_len=median_d.loc[('syntactic', 'mean_sent_len')], \n",
    "                                                                                                  scale=scale), axis=1)].index\n",
    "    idxs_bad_bet_len[scale] = idsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f30dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_ms = sorted(list(set([y for x in idxs_scale.values() for y in x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbb915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ms_better_than_len = sorted(list(set([y for x in idxs_bad_bet_len.values() for y in x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c511c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ms = median_d[median_d.apply(select_bad_len_metrics, axis=1)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "471d1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), sharex=True)\n",
    "fig.suptitle('cross-type metric comparison for correlation with mean sent len')\n",
    "measure = 'r_corr_w_control'\n",
    "plot_abs = False\n",
    "\n",
    "\n",
    "d = prep_horizontal_pointplot_errobar_data(reformed_d['panss_pos'].loc[bad_ms], measure, plot_abs=plot_abs)\n",
    "pointplot_horizontal(d, x=measure, ax=ax)\n",
    "ax.set_xlabel('r')\n",
    "add_grey(ax)\n",
    "plt.savefig(f'{PATH_FIG}/compare_corr_len.png', dpi=150, bbox_inches = 'tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "d80e8215",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_to_plot = sorted(bad_ms_better_than_len + good_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "66d863ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ms_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "9daee90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "5ac133cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'saps_total': 4,\n",
       " 'sans_total': 10,\n",
       " 'panss_pos': 1,\n",
       " 'panss_neg': 14,\n",
       " 'panss_o': 14,\n",
       " 'panss_total': 17}"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{s: len(idxs_scale[s]) + len(idxs_bad_bet_len[s]) for s in idxs_scale}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "c5f78c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'saps_total': 1,\n",
       " 'sans_total': 3,\n",
       " 'panss_pos': 0,\n",
       " 'panss_neg': 4,\n",
       " 'panss_o': 2,\n",
       " 'panss_total': 3}"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{s: len(idxs_scale[s]) for s in idxs_scale}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a00e2e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_index(idxs):\n",
    "    ms = sorted(idxs)\n",
    "    for s in ('syntactic: mean_sent_len', 'mean_sent_len', ('syntactic', 'mean_sent_len')):\n",
    "        if s in ms:\n",
    "            ms.remove(s)\n",
    "            ms.append(s)\n",
    "    return ms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "396c397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_marker(m, scale, idxs_scale):\n",
    "    if m in idxs_scale[scale]:\n",
    "        return 'o'\n",
    "    else: \n",
    "        return 'x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "51b2c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_len_lines(ax, median_d, scale, measure='r'):\n",
    "    ax.axvline(median_d.loc[('syntactic', 'mean_sent_len')][scale, measure], linestyle='--')\n",
    "    ax.axvline(-median_d.loc[('syntactic', 'mean_sent_len')][scale, measure], linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "c0b4f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_scale(ax, scale, idxs_scale, reformed_d, ms_to_plot, measure, plot_abs, use_markers=True):\n",
    "    markers = [map_marker(m, scale, idxs_scale) for m in ms_to_plot]\n",
    "    if ('syntactic', 'mean_sent_len') in idxs_scale[scale]:\n",
    "        add_len_lines(ax, median_d, scale)\n",
    "    d = prep_horizontal_pointplot_errobar_data(reformed_d[scale].loc[ms_to_plot], measure, plot_abs=plot_abs)\n",
    "    pointplot_horizontal(d, x=measure, ax=ax, markers=markers if use_markers else 'o')\n",
    "    ax.set_title(f'{measure} {scale}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "8aa39de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(18, 14), sharex=True)\n",
    "fig.suptitle('cross-scale cross-type metric comparison', y=0.915)\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.1) #left=None, bottom=None, right=None, top=None, wspace=None, hspace=None)\n",
    "measure = 'r'\n",
    "plot_abs = False\n",
    "idxs = sort_index(ms_to_plot)\n",
    "axs = axes.flatten()\n",
    "\n",
    "for i, scale in enumerate(ORDERED_SCALES):\n",
    "    ax = axs[i]\n",
    "    plot_one_scale(ax, scale, idxs_scale, reformed_d, ms_to_plot, measure, plot_abs)\n",
    "    \n",
    "add_grey(axes)\n",
    "plt.savefig(f'{PATH_FIG}/compare_r.png', dpi=150, bbox_inches = 'tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0297c8be",
   "metadata": {},
   "source": [
    "#### Images for the Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "1ac6d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_plot = [m for m in ms_to_plot if m not in [('syntactic', 'AUX'),  ('LM', 'w2v_tf_cgcoh')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "b7721cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(18, 4))\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "fig.suptitle('cross-type metric comparison for correlation with SANS and inverse mean sentence length', y=1)\n",
    "\n",
    "dcr = reformed_d['sans_total'].loc[idx_to_plot].drop([('syntactic', 'mean_sent_len')])\n",
    "d_c = prep_horizontal_pointplot_errobar_data(dcr, 'r_corr_w_control', plot_abs=False)\n",
    "d_c['r_corr_w_control'] = -1 * d_c['r_corr_w_control']\n",
    "\n",
    "plot_one_scale(axes[0], 'sans_total', idxs_scale, reformed_d, idx_to_plot, measure, plot_abs, use_markers=False)\n",
    "\n",
    "pointplot_horizontal(d_c, x='r_corr_w_control', ax=axes[1], palette='tab20')\n",
    "axes[1].set_title('-1 * r mean sentence length')\n",
    "axes[1].set_xlabel('-r');\n",
    "add_grey(axes)\n",
    "plt.savefig(f'{PATH_FIG}/compare_sans_to_minus_corr_len_more_metrics.png', dpi=150, bbox_inches = 'tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "62166576",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs_sans = sorted([m for m in idxs_scale['sans_total']] + [m for m in idxs_bad_bet_len['sans_total']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "f69e0f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(18, 4))\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "fig.suptitle('cross-type metric comparison for correlation with SANS and inverse mean sentence length', y=1)\n",
    "\n",
    "dcr = reformed_d['sans_total'].loc[idxs_sans].drop([('syntactic', 'mean_sent_len')])\n",
    "d_c = prep_horizontal_pointplot_errobar_data(dcr, 'r_corr_w_control', plot_abs=False)\n",
    "d_c['r_corr_w_control'] = -1 * d_c['r_corr_w_control']\n",
    "\n",
    "plot_one_scale(axes[0], 'sans_total', idxs_scale, reformed_d, idxs_sans, measure, plot_abs, use_markers=False)\n",
    "\n",
    "pointplot_horizontal(d_c, x='r_corr_w_control', ax=axes[1], palette='tab20')\n",
    "axes[1].set_title('-1 * r mean sentence length')\n",
    "axes[1].set_xlabel('-r');\n",
    "add_grey(axes)\n",
    "plt.savefig(f'{PATH_FIG}/compare_sans_to_minus_corr_len.png', dpi=150, bbox_inches = 'tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5187b3d8",
   "metadata": {},
   "source": [
    "### t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "a93233d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ok_metrics_t(row):\n",
    "    q25 = np.quantile(row['saps_total', 't'], 0.25)\n",
    "    q75 = np.quantile(row['saps_total', 't'], 0.75)\n",
    "    return q25 > 0 or q75 < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "7e924871",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_comp_t = reformed_d[reformed_d.apply(select_ok_metrics_t, axis=1)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "dd2e2a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(18, 4))\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "fig.suptitle('cross-type metric comparison for group difference and correlation with mean sentence length', y=1)\n",
    "\n",
    "dcr = reformed_d['sans_total'].loc[idx_comp_t].drop([('syntactic', 'mean_sent_len')])\n",
    "d_c = prep_horizontal_pointplot_errobar_data(dcr, 'r_corr_w_control', plot_abs=False)\n",
    "d_t = prep_horizontal_pointplot_errobar_data(reformed_d['sans_total'].loc[idx_comp_t], 't', plot_abs=False)\n",
    "d_t['t'] = d_t['t'] * -1\n",
    "\n",
    "pointplot_horizontal(d_t, x='t', ax=axes[0])\n",
    "axes[0].set_title('t')\n",
    "axes[0].set_title('group difference (t-test)')\n",
    "add_len_lines(axes[0], median_d, scale, 't')\n",
    "\n",
    "pointplot_horizontal(d_c, x='r_corr_w_control', ax=axes[1])\n",
    "axes[1].set_title('correlation with mean sentence length')\n",
    "axes[1].set_xlabel('r');\n",
    "add_grey(axes[0], r=2)\n",
    "add_grey(axes[1])\n",
    "plt.savefig(f'{PATH_FIG}/compare_t.png', dpi=150, bbox_inches = 'tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec56767b",
   "metadata": {},
   "source": [
    "#### Images for the Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "ab6b7ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(18, 4))\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "fig.suptitle('cross-type metric comparison for group difference and correlation with inverse mean sentence length', y=1)\n",
    "\n",
    "dcr = reformed_d['sans_total'].loc[idx_comp_t].drop([('syntactic', 'mean_sent_len')])\n",
    "d_c = prep_horizontal_pointplot_errobar_data(dcr, 'r_corr_w_control', plot_abs=False)\n",
    "d_t = prep_horizontal_pointplot_errobar_data(reformed_d['sans_total'].loc[idx_comp_t], 't', plot_abs=False)\n",
    "d_t['t'] = d_t['t'] * -1\n",
    "d_c['r_corr_w_control'] = -1 * d_c['r_corr_w_control']\n",
    "\n",
    "pointplot_horizontal(d_t, x='t', ax=axes[0])\n",
    "axes[0].set_title('t')\n",
    "axes[0].set_title('t-test')\n",
    "add_len_lines(axes[0], median_d, scale, 't')\n",
    "\n",
    "pointplot_horizontal(d_c, x='r_corr_w_control', ax=axes[1])\n",
    "axes[1].set_title('-1 * r mean sentence length')\n",
    "axes[1].set_xlabel('-r');\n",
    "add_grey(axes[0], r=2)\n",
    "add_grey(axes[1])\n",
    "plt.savefig(f'{PATH_FIG}/compare_t_minus_corr_len.png', dpi=150, bbox_inches = 'tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3192fd",
   "metadata": {},
   "source": [
    "### average LM model / metric performance medians across scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "c17728bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales_ = ('sans_total', 'saps_total', 'panss_pos', 'panss_neg', 'panss_o', 'panss_total')\n",
    "sc_ind_ = ('t', 'r_corr_w_control')\n",
    "models_ = ('bert', 'glove_tf', 'glove_avg', 'w2v_tf', 'w2v_avg')\n",
    "metrics_ = ('cgcoh', 'gcoh', 'lcoh', 'scoh', 'sprob', 'pppl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "bca23d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_model_metric_medians(median_df, leave_out=()):\n",
    "    resp_d_model = pd.DataFrame(columns=[f'{sc} abs r' for sc in scales_] + list(sc_ind_), index=models_)\n",
    "    resp_d_metric = pd.DataFrame(columns=[f'{sc} abs r' for sc in scales_] + list(sc_ind_), index=metrics_)\n",
    "    for scale in scales_:\n",
    "        ex_d = prep_LM_pointplot(median_df.loc['LM', scale], col='r', use_errorbar=False, plot_abs=True)\n",
    "        for model in models_:\n",
    "            leave_out_ = ex_d[ex_d['model'] == model]\n",
    "            leave_out_ = leave_out_[~leave_out_['metric'].isin(leave_out)]\n",
    "            resp_d_model.loc[model, f'{scale} abs r'] = np.nanmean(leave_out_['r'])\n",
    "        for metric in metrics_:\n",
    "            resp_d_metric.loc[metric, f'{scale} abs r'] = np.nanmean(ex_d[ex_d['metric'] == metric]['r'])\n",
    "    for sc_ind in sc_ind_:\n",
    "        for model in models_:\n",
    "            leave_out_ = ex_d[ex_d['model'] == model]\n",
    "            leave_out_ = leave_out_[~leave_out_['metric'].isin(leave_out)]\n",
    "            resp_d_model.loc[model, sc_ind] = np.nanmean(leave_out_[sc_ind])\n",
    "        for metric in metrics_:\n",
    "            resp_d_metric.loc[metric, sc_ind] = np.nanmean(ex_d[ex_d['metric'] == metric][sc_ind])\n",
    "    return resp_d_model, resp_d_metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d4f823",
   "metadata": {},
   "source": [
    "#### only including cosine-similarity based metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "11a1f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_d_model, resp_d_metric = mean_model_metric_medians(median_d, leave_out=('pppl', 'sprob'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "1fbe1e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_eccb4_row0_col0 {\n",
       "  background-color: #6aaed6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eccb4_row0_col1, #T_eccb4_row0_col2, #T_eccb4_row0_col7, #T_eccb4_row1_col0, #T_eccb4_row1_col3, #T_eccb4_row1_col4, #T_eccb4_row1_col5, #T_eccb4_row1_col6 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eccb4_row0_col3 {\n",
       "  background-color: #bfd8ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eccb4_row0_col4 {\n",
       "  background-color: #083776;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eccb4_row0_col5 {\n",
       "  background-color: #ccdff1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eccb4_row0_col6 {\n",
       "  background-color: #a5cde3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eccb4_row1_col1, #T_eccb4_row4_col2 {\n",
       "  background-color: #4090c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eccb4_row1_col2 {\n",
       "  background-color: #09529d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eccb4_row1_col7 {\n",
       "  background-color: #4e9acb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eccb4_row2_col0 {\n",
       "  background-color: #8dc1dd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eccb4_row2_col1 {\n",
       "  background-color: #4f9bcb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eccb4_row2_col2 {\n",
       "  background-color: #3181bd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eccb4_row2_col3 {\n",
       "  background-color: #a9cfe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eccb4_row2_col4 {\n",
       "  background-color: #cadef0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eccb4_row2_col5 {\n",
       "  background-color: #c1d9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eccb4_row2_col6 {\n",
       "  background-color: #f5fafe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eccb4_row2_col7 {\n",
       "  background-color: #084d96;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eccb4_row3_col0 {\n",
       "  background-color: #1460a8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eccb4_row3_col1, #T_eccb4_row3_col2, #T_eccb4_row3_col4, #T_eccb4_row3_col5, #T_eccb4_row3_col6, #T_eccb4_row4_col0, #T_eccb4_row4_col3, #T_eccb4_row4_col7 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eccb4_row3_col3 {\n",
       "  background-color: #083573;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eccb4_row3_col7 {\n",
       "  background-color: #083e81;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eccb4_row4_col1 {\n",
       "  background-color: #1b69af;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eccb4_row4_col4 {\n",
       "  background-color: #1e6db2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eccb4_row4_col5 {\n",
       "  background-color: #2474b7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eccb4_row4_col6 {\n",
       "  background-color: #3989c1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_eccb4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_eccb4_level0_col0\" class=\"col_heading level0 col0\" >sans_total abs r</th>\n",
       "      <th id=\"T_eccb4_level0_col1\" class=\"col_heading level0 col1\" >saps_total abs r</th>\n",
       "      <th id=\"T_eccb4_level0_col2\" class=\"col_heading level0 col2\" >panss_pos abs r</th>\n",
       "      <th id=\"T_eccb4_level0_col3\" class=\"col_heading level0 col3\" >panss_neg abs r</th>\n",
       "      <th id=\"T_eccb4_level0_col4\" class=\"col_heading level0 col4\" >panss_o abs r</th>\n",
       "      <th id=\"T_eccb4_level0_col5\" class=\"col_heading level0 col5\" >panss_total abs r</th>\n",
       "      <th id=\"T_eccb4_level0_col6\" class=\"col_heading level0 col6\" >t</th>\n",
       "      <th id=\"T_eccb4_level0_col7\" class=\"col_heading level0 col7\" >r_corr_w_control</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_eccb4_level0_row0\" class=\"row_heading level0 row0\" >bert</th>\n",
       "      <td id=\"T_eccb4_row0_col0\" class=\"data row0 col0\" >0.236577</td>\n",
       "      <td id=\"T_eccb4_row0_col1\" class=\"data row0 col1\" >0.044180</td>\n",
       "      <td id=\"T_eccb4_row0_col2\" class=\"data row0 col2\" >0.070790</td>\n",
       "      <td id=\"T_eccb4_row0_col3\" class=\"data row0 col3\" >0.225726</td>\n",
       "      <td id=\"T_eccb4_row0_col4\" class=\"data row0 col4\" >0.252314</td>\n",
       "      <td id=\"T_eccb4_row0_col5\" class=\"data row0 col5\" >0.226234</td>\n",
       "      <td id=\"T_eccb4_row0_col6\" class=\"data row0 col6\" >0.511409</td>\n",
       "      <td id=\"T_eccb4_row0_col7\" class=\"data row0 col7\" >0.157991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eccb4_level0_row1\" class=\"row_heading level0 row1\" >glove_tf</th>\n",
       "      <td id=\"T_eccb4_row1_col0\" class=\"data row1 col0\" >0.165904</td>\n",
       "      <td id=\"T_eccb4_row1_col1\" class=\"data row1 col1\" >0.208092</td>\n",
       "      <td id=\"T_eccb4_row1_col2\" class=\"data row1 col2\" >0.234331</td>\n",
       "      <td id=\"T_eccb4_row1_col3\" class=\"data row1 col3\" >0.192519</td>\n",
       "      <td id=\"T_eccb4_row1_col4\" class=\"data row1 col4\" >0.164074</td>\n",
       "      <td id=\"T_eccb4_row1_col5\" class=\"data row1 col5\" >0.198569</td>\n",
       "      <td id=\"T_eccb4_row1_col6\" class=\"data row1 col6\" >0.391710</td>\n",
       "      <td id=\"T_eccb4_row1_col7\" class=\"data row1 col7\" >0.429151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eccb4_level0_row2\" class=\"row_heading level0 row2\" >glove_avg</th>\n",
       "      <td id=\"T_eccb4_row2_col0\" class=\"data row2 col0\" >0.224203</td>\n",
       "      <td id=\"T_eccb4_row2_col1\" class=\"data row2 col1\" >0.195832</td>\n",
       "      <td id=\"T_eccb4_row2_col2\" class=\"data row2 col2\" >0.200804</td>\n",
       "      <td id=\"T_eccb4_row2_col3\" class=\"data row2 col3\" >0.234329</td>\n",
       "      <td id=\"T_eccb4_row2_col4\" class=\"data row2 col4\" >0.184796</td>\n",
       "      <td id=\"T_eccb4_row2_col5\" class=\"data row2 col5\" >0.232160</td>\n",
       "      <td id=\"T_eccb4_row2_col6\" class=\"data row2 col6\" >0.394616</td>\n",
       "      <td id=\"T_eccb4_row2_col7\" class=\"data row2 col7\" >0.567291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eccb4_level0_row3\" class=\"row_heading level0 row3\" >w2v_tf</th>\n",
       "      <td id=\"T_eccb4_row3_col0\" class=\"data row3 col0\" >0.280315</td>\n",
       "      <td id=\"T_eccb4_row3_col1\" class=\"data row3 col1\" >0.303707</td>\n",
       "      <td id=\"T_eccb4_row3_col2\" class=\"data row3 col2\" >0.258881</td>\n",
       "      <td id=\"T_eccb4_row3_col3\" class=\"data row3 col3\" >0.312226</td>\n",
       "      <td id=\"T_eccb4_row3_col4\" class=\"data row3 col4\" >0.254946</td>\n",
       "      <td id=\"T_eccb4_row3_col5\" class=\"data row3 col5\" >0.324928</td>\n",
       "      <td id=\"T_eccb4_row3_col6\" class=\"data row3 col6\" >0.729381</td>\n",
       "      <td id=\"T_eccb4_row3_col7\" class=\"data row3 col7\" >0.592533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eccb4_level0_row4\" class=\"row_heading level0 row4\" >w2v_avg</th>\n",
       "      <td id=\"T_eccb4_row4_col0\" class=\"data row4 col0\" >0.306171</td>\n",
       "      <td id=\"T_eccb4_row4_col1\" class=\"data row4 col1\" >0.246063</td>\n",
       "      <td id=\"T_eccb4_row4_col2\" class=\"data row4 col2\" >0.189779</td>\n",
       "      <td id=\"T_eccb4_row4_col3\" class=\"data row4 col3\" >0.314721</td>\n",
       "      <td id=\"T_eccb4_row4_col4\" class=\"data row4 col4\" >0.233608</td>\n",
       "      <td id=\"T_eccb4_row4_col5\" class=\"data row4 col5\" >0.291453</td>\n",
       "      <td id=\"T_eccb4_row4_col6\" class=\"data row4 col6\" >0.613459</td>\n",
       "      <td id=\"T_eccb4_row4_col7\" class=\"data row4 col7\" >0.618035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fdab491a400>"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style(resp_d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "6cb92e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bert         0.175970\n",
       "glove_tf     0.193915\n",
       "glove_avg    0.212021\n",
       "w2v_avg      0.263633\n",
       "w2v_tf       0.289167\n",
       "dtype: float64"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_d_model[['sans_total abs r',\n",
    " 'saps_total abs r',\n",
    " 'panss_pos abs r',\n",
    " 'panss_neg abs r',\n",
    " 'panss_o abs r',\n",
    " 'panss_total abs r']].mean(axis=1).sort_values() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "e3acee3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bert         0.157991\n",
       "glove_tf     0.429151\n",
       "glove_avg    0.567291\n",
       "w2v_tf       0.592533\n",
       "w2v_avg      0.618035\n",
       "Name: r_corr_w_control, dtype: object"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_d_model['r_corr_w_control']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "ab0158ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cgcoh    0.292816\n",
       "gcoh     0.493656\n",
       "lcoh     0.549157\n",
       "scoh     0.556372\n",
       "sprob    0.576114\n",
       "pppl     0.529623\n",
       "Name: r_corr_w_control, dtype: object"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_d_metric['r_corr_w_control']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bd5633",
   "metadata": {},
   "source": [
    "#### including feature based metrics for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "1ce80db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_d_model, resp_d_metric = mean_model_metric_medians(median_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "1cad0500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bf212_row0_col0, #T_bf212_row0_col3, #T_bf212_row0_col4, #T_bf212_row0_col5, #T_bf212_row0_col7, #T_bf212_row1_col6, #T_bf212_row4_col1, #T_bf212_row5_col2 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bf212_row0_col1 {\n",
       "  background-color: #4e9acb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bf212_row0_col2 {\n",
       "  background-color: #d6e5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bf212_row0_col6 {\n",
       "  background-color: #99c7e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bf212_row1_col0 {\n",
       "  background-color: #d0e2f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bf212_row1_col1 {\n",
       "  background-color: #66abd4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bf212_row1_col2 {\n",
       "  background-color: #b0d2e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bf212_row1_col3 {\n",
       "  background-color: #bdd7ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bf212_row1_col4 {\n",
       "  background-color: #cde0f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bf212_row1_col5 {\n",
       "  background-color: #a9cfe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bf212_row1_col7 {\n",
       "  background-color: #2c7cba;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bf212_row2_col0 {\n",
       "  background-color: #539ecd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bf212_row2_col1, #T_bf212_row2_col2, #T_bf212_row4_col7, #T_bf212_row5_col0, #T_bf212_row5_col3, #T_bf212_row5_col4, #T_bf212_row5_col5, #T_bf212_row5_col6 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bf212_row2_col3 {\n",
       "  background-color: #3d8dc4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bf212_row2_col4 {\n",
       "  background-color: #4a98c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bf212_row2_col5 {\n",
       "  background-color: #1967ad;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bf212_row2_col6 {\n",
       "  background-color: #b2d2e8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bf212_row2_col7 {\n",
       "  background-color: #084990;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bf212_row3_col0 {\n",
       "  background-color: #2575b7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bf212_row3_col1, #T_bf212_row4_col2, #T_bf212_row4_col6 {\n",
       "  background-color: #4896c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bf212_row3_col2 {\n",
       "  background-color: #4b98ca;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bf212_row3_col3 {\n",
       "  background-color: #125ea6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bf212_row3_col4 {\n",
       "  background-color: #2a7ab9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bf212_row3_col5 {\n",
       "  background-color: #09529d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bf212_row3_col6 {\n",
       "  background-color: #deebf7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bf212_row3_col7 {\n",
       "  background-color: #084285;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bf212_row4_col0 {\n",
       "  background-color: #9ac8e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bf212_row4_col3 {\n",
       "  background-color: #4695c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bf212_row4_col4 {\n",
       "  background-color: #58a1cf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bf212_row4_col5 {\n",
       "  background-color: #3181bd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bf212_row5_col1 {\n",
       "  background-color: #c8dcf0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bf212_row5_col7 {\n",
       "  background-color: #105ba4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bf212\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bf212_level0_col0\" class=\"col_heading level0 col0\" >sans_total abs r</th>\n",
       "      <th id=\"T_bf212_level0_col1\" class=\"col_heading level0 col1\" >saps_total abs r</th>\n",
       "      <th id=\"T_bf212_level0_col2\" class=\"col_heading level0 col2\" >panss_pos abs r</th>\n",
       "      <th id=\"T_bf212_level0_col3\" class=\"col_heading level0 col3\" >panss_neg abs r</th>\n",
       "      <th id=\"T_bf212_level0_col4\" class=\"col_heading level0 col4\" >panss_o abs r</th>\n",
       "      <th id=\"T_bf212_level0_col5\" class=\"col_heading level0 col5\" >panss_total abs r</th>\n",
       "      <th id=\"T_bf212_level0_col6\" class=\"col_heading level0 col6\" >t</th>\n",
       "      <th id=\"T_bf212_level0_col7\" class=\"col_heading level0 col7\" >r_corr_w_control</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bf212_level0_row0\" class=\"row_heading level0 row0\" >cgcoh</th>\n",
       "      <td id=\"T_bf212_row0_col0\" class=\"data row0 col0\" >0.105246</td>\n",
       "      <td id=\"T_bf212_row0_col1\" class=\"data row0 col1\" >0.190676</td>\n",
       "      <td id=\"T_bf212_row0_col2\" class=\"data row0 col2\" >0.142618</td>\n",
       "      <td id=\"T_bf212_row0_col3\" class=\"data row0 col3\" >0.101842</td>\n",
       "      <td id=\"T_bf212_row0_col4\" class=\"data row0 col4\" >0.085081</td>\n",
       "      <td id=\"T_bf212_row0_col5\" class=\"data row0 col5\" >0.098206</td>\n",
       "      <td id=\"T_bf212_row0_col6\" class=\"data row0 col6\" >0.872924</td>\n",
       "      <td id=\"T_bf212_row0_col7\" class=\"data row0 col7\" >0.292816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf212_level0_row1\" class=\"row_heading level0 row1\" >gcoh</th>\n",
       "      <td id=\"T_bf212_row1_col0\" class=\"data row1 col0\" >0.176989</td>\n",
       "      <td id=\"T_bf212_row1_col1\" class=\"data row1 col1\" >0.182976</td>\n",
       "      <td id=\"T_bf212_row1_col2\" class=\"data row1 col2\" >0.163138</td>\n",
       "      <td id=\"T_bf212_row1_col3\" class=\"data row1 col3\" >0.200634</td>\n",
       "      <td id=\"T_bf212_row1_col4\" class=\"data row1 col4\" >0.159281</td>\n",
       "      <td id=\"T_bf212_row1_col5\" class=\"data row1 col5\" >0.204929</td>\n",
       "      <td id=\"T_bf212_row1_col6\" class=\"data row1 col6\" >0.134382</td>\n",
       "      <td id=\"T_bf212_row1_col7\" class=\"data row1 col7\" >0.493656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf212_level0_row2\" class=\"row_heading level0 row2\" >lcoh</th>\n",
       "      <td id=\"T_bf212_row2_col0\" class=\"data row2 col0\" >0.314356</td>\n",
       "      <td id=\"T_bf212_row2_col1\" class=\"data row2 col1\" >0.232184</td>\n",
       "      <td id=\"T_bf212_row2_col2\" class=\"data row2 col2\" >0.256773</td>\n",
       "      <td id=\"T_bf212_row2_col3\" class=\"data row2 col3\" >0.328579</td>\n",
       "      <td id=\"T_bf212_row2_col4\" class=\"data row2 col4\" >0.292895</td>\n",
       "      <td id=\"T_bf212_row2_col5\" class=\"data row2 col5\" >0.344763</td>\n",
       "      <td id=\"T_bf212_row2_col6\" class=\"data row2 col6\" >0.729779</td>\n",
       "      <td id=\"T_bf212_row2_col7\" class=\"data row2 col7\" >0.549157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf212_level0_row3\" class=\"row_heading level0 row3\" >scoh</th>\n",
       "      <td id=\"T_bf212_row3_col0\" class=\"data row3 col0\" >0.373945</td>\n",
       "      <td id=\"T_bf212_row3_col1\" class=\"data row3 col1\" >0.192464</td>\n",
       "      <td id=\"T_bf212_row3_col2\" class=\"data row3 col2\" >0.201138</td>\n",
       "      <td id=\"T_bf212_row3_col3\" class=\"data row3 col3\" >0.392562</td>\n",
       "      <td id=\"T_bf212_row3_col4\" class=\"data row3 col4\" >0.334534</td>\n",
       "      <td id=\"T_bf212_row3_col5\" class=\"data row3 col5\" >0.370777</td>\n",
       "      <td id=\"T_bf212_row3_col6\" class=\"data row3 col6\" >0.375375</td>\n",
       "      <td id=\"T_bf212_row3_col7\" class=\"data row3 col7\" >0.556372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf212_level0_row4\" class=\"row_heading level0 row4\" >sprob</th>\n",
       "      <td id=\"T_bf212_row4_col0\" class=\"data row4 col0\" >0.245612</td>\n",
       "      <td id=\"T_bf212_row4_col1\" class=\"data row4 col1\" >0.131085</td>\n",
       "      <td id=\"T_bf212_row4_col2\" class=\"data row4 col2\" >0.202997</td>\n",
       "      <td id=\"T_bf212_row4_col3\" class=\"data row4 col3\" >0.318265</td>\n",
       "      <td id=\"T_bf212_row4_col4\" class=\"data row4 col4\" >0.278489</td>\n",
       "      <td id=\"T_bf212_row4_col5\" class=\"data row4 col5\" >0.314706</td>\n",
       "      <td id=\"T_bf212_row4_col6\" class=\"data row4 col6\" >1.287450</td>\n",
       "      <td id=\"T_bf212_row4_col7\" class=\"data row4 col7\" >0.576114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf212_level0_row5\" class=\"row_heading level0 row5\" >pppl</th>\n",
       "      <td id=\"T_bf212_row5_col0\" class=\"data row5 col0\" >0.471239</td>\n",
       "      <td id=\"T_bf212_row5_col1\" class=\"data row5 col1\" >0.155275</td>\n",
       "      <td id=\"T_bf212_row5_col2\" class=\"data row5 col2\" >0.119219</td>\n",
       "      <td id=\"T_bf212_row5_col3\" class=\"data row5 col3\" >0.454768</td>\n",
       "      <td id=\"T_bf212_row5_col4\" class=\"data row5 col4\" >0.432778</td>\n",
       "      <td id=\"T_bf212_row5_col5\" class=\"data row5 col5\" >0.412121</td>\n",
       "      <td id=\"T_bf212_row5_col6\" class=\"data row5 col6\" >2.038195</td>\n",
       "      <td id=\"T_bf212_row5_col7\" class=\"data row5 col7\" >0.529623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fdaceb1f940>"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style(resp_d_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "bc74eb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "glove_tf     0.193915\n",
       "glove_avg    0.212021\n",
       "bert         0.215551\n",
       "w2v_avg      0.263633\n",
       "w2v_tf       0.289167\n",
       "dtype: float64"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_d_model[['sans_total abs r',\n",
    " 'saps_total abs r',\n",
    " 'panss_pos abs r',\n",
    " 'panss_neg abs r',\n",
    " 'panss_o abs r',\n",
    " 'panss_total abs r']].mean(axis=1).sort_values() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "a4fea5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bert         0.289617\n",
       "glove_tf     0.429151\n",
       "glove_avg    0.567291\n",
       "w2v_tf       0.592533\n",
       "w2v_avg      0.618035\n",
       "Name: r_corr_w_control, dtype: object"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_d_model['r_corr_w_control']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "155b6368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cgcoh    0.292816\n",
       "gcoh     0.493656\n",
       "lcoh     0.549157\n",
       "scoh     0.556372\n",
       "sprob    0.576114\n",
       "pppl     0.529623\n",
       "Name: r_corr_w_control, dtype: object"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_d_metric['r_corr_w_control']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae3cf50",
   "metadata": {},
   "source": [
    "## Plot and analyze across parts of NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e354a52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r_corr_w_mean_sent_len', 'r_corr_w_n_sents', 'r_corr_w_n_words']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbosity_control_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02c3a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_horizontal_tasks(df, title, scale, measure, xname=None, m_type='syntactic', \n",
    "                          plot_abs=False, r=0.3, figparams=figprms, \n",
    "                          control_cols = ['r_corr_w_control'], control_col_names=['mean sentence length']):\n",
    "    absolute_value = f' (absolute r value)' if plot_abs else ''\n",
    "    if len(control_cols) != len(control_col_names):\n",
    "        raise ValueError('The names of the columns must match the columns in length.')\n",
    "    \n",
    "    figsize, wspace, hspace, yt = get_fparams(m_type, 2, 2, figparams)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=figsize, sharex=True)\n",
    "    fig.suptitle(title + absolute_value, y=yt)\n",
    "    plt.subplots_adjust(wspace=wspace, hspace=hspace)\n",
    "    \n",
    "    axs = axes.flatten()\n",
    "    \n",
    "    for i, task in enumerate(TASKS):\n",
    "        ax = axs[i]\n",
    "        data_task = df.loc[m_type, (task, scale)]\n",
    "        if m_type == 'syntactic':\n",
    "            if measure == 'r_corr_w_mean_sent_len' or measure == 'r_corr_w_control':\n",
    "                data_task = df.loc[m_type, (task, scale)].drop('mean_sent_len')\n",
    "            elif measure == 'r_corr_w_mean_sent_len':\n",
    "                data_task = df.loc[m_type, (task, scale)].drop('n_sents')\n",
    "        elif m_type == 'lexical' and measure == 'r_corr_w_n_words':\n",
    "            data_task = df.loc[m_type, (task, scale)].drop('n_words')\n",
    "            \n",
    "        data = prep_horizontal_pointplot_errobar_data(data_task, col=measure, plot_abs=plot_abs)\n",
    "        if measure == 't':\n",
    "            data['t'] = data['t'] * -1\n",
    "        pointplot_horizontal(data, x=measure, ax=ax)\n",
    "        ax.set_title(task)\n",
    "\n",
    "    add_grey(axes, r=r)\n",
    "    if xname is None:\n",
    "        xname = measure\n",
    "    \n",
    "    for ax in axes.reshape(-1): \n",
    "        label = 'abs ' + xname if plot_abs else xname\n",
    "        ax.set_xlabel(label)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "f915bd44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_type = 'syntactic'\n",
    "fig = plot_horizontal_tasks(reformed_tasks, \n",
    "                      f'cross-task comparison for {m_type} metrics on group difference (t-test)', \n",
    "                      scale='panss_o', measure='t', m_type=m_type, r=2, figparams=figprms)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "90569d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_horizontal_tasks(reformed_tasks, \n",
    "                      f'cross-task comparison for {m_type} metrics on sans_total', \n",
    "                      scale='sans_total', measure='r', m_type=m_type, figparams=figprms)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "b834810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_horizontal_tasks(reformed_tasks, \n",
    "                            f'cross-task comparison for {m_type} metrics on correlation with mean sentence length', \n",
    "                            scale='panss_o', measure='r_corr_w_control', \n",
    "                            xname='r', m_type=m_type, figparams=figprms)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "63ccc6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_scales(reformed_d, m_type='syntactic', path=PATH_FIG, plot_abs=True, dpi=150, figparams=figprms,\n",
    "                    control_cols=['r_corr_w_control'], control_col_names=['mean sentence length']):\n",
    "    \n",
    "    fig = plot_horizontal_tasks(reformed_d, \n",
    "                                f'cross-task comparison for {m_type} metrics on group difference (t-test)', \n",
    "                                scale='panss_o', measure='t', m_type=m_type, r=2, figparams=figparams)\n",
    "    plt.savefig(f'{path}{m_type}/t_across_tasks.png', dpi=dpi, bbox_inches = 'tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    ab = 'abs_' if plot_abs else ''\n",
    "    \n",
    "    upfig = figparams.copy()\n",
    "    if m_type == 'lexical':\n",
    "        upfig[m_type]['yt'] += 0.05\n",
    "    for i, control_col in enumerate(control_cols):\n",
    "        name = control_col_names[i]\n",
    "        fig = plot_horizontal_tasks(reformed_d, \n",
    "                                f'cross-task comparison for {m_type} metrics on correlation with {name}', \n",
    "                                scale='panss_o', measure=control_col, plot_abs=plot_abs, \n",
    "                                xname='r', m_type=m_type, figparams=upfig)\n",
    "        plt.savefig(f'{path}{m_type}/{ab}corr_{\"_\".join(name.split())}_across_tasks.png', \n",
    "                    dpi=dpi, bbox_inches = 'tight')\n",
    "        plt.close(fig)\n",
    "    \n",
    "    for scale in ORDERED_SCALES:\n",
    "        fig = plot_horizontal_tasks(reformed_d, \n",
    "                                    f'cross-task comparison for {m_type} metrics on {scale}', \n",
    "                                    scale=scale, measure='r', \n",
    "                                    plot_abs=plot_abs, m_type=m_type, figparams=figparams)\n",
    "        plt.savefig(f'{path}{m_type}/{ab}r_{scale}_across_tasks.png', dpi=dpi, bbox_inches = 'tight')\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "825fd57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m_type in reformed_tasks.index.unique(level=0):\n",
    "    plot_all_scales(reformed_tasks, m_type, plot_abs=True)\n",
    "    plot_all_scales(reformed_tasks, m_type, plot_abs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "17d71375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lm_tasks(df, title, scale, measure, order=order, plot_abs=False, use_errorbar=True,\n",
    "                 figsize=(15, 10), yname=None, r=0.3):\n",
    "    absolute_value = f' (absolute {measure} value)' if plot_abs else ''\n",
    "    fig, axes = plt.subplots(2, 2, figsize=figsize, sharey=True)\n",
    "    fig.suptitle(title+absolute_value, y=0.925)\n",
    "    plt.subplots_adjust(wspace=0.1)\n",
    "    \n",
    "    axs = axes.flatten()\n",
    "    for i, task in enumerate(TASKS):\n",
    "        ax = axs[i]\n",
    "        d = prep_LM_pointplot(df.loc['LM', (task, scale)], col=measure, plot_abs=plot_abs)\n",
    "        if measure == 't':\n",
    "            d['t'] = d['t'] * -1\n",
    "        pointplot(d, x='model', y=measure, hue='metric', ax=ax, order=order, use_errorbar=use_errorbar)\n",
    "        ax.set_title(task)\n",
    "\n",
    "    add_grey(axes, line_dir='h', r=r)\n",
    "    \n",
    "    if yname is None:\n",
    "        yname = measure\n",
    "    for ax in axes.reshape(-1): \n",
    "        label = 'abs ' + yname if plot_abs else yname\n",
    "        ax.set_ylabel(label)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "9daa6de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_lm_tasks(reformed_tasks, \n",
    "                    'cross-task comparison for LM metrics across models on group difference (t-test)',\n",
    "                    scale='panss_o', measure='t', use_errorbar=True, figsize=(15, 10), r=2)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "916d2b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_lm_tasks(reformed_tasks, \n",
    "                    'cross-task comparison for LM metrics across models on sans_total',\n",
    "                    scale='sans_total', measure='r', use_errorbar=True, figsize=(15, 10))\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "55302623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_LM_across_tasks(reformed_d, m_type='LM', path=PATH_FIG, plot_abs=False, figsize=(18, 12), dpi = 150,\n",
    "                    control_cols=['r_corr_w_control'], control_col_names=['mean sentence length']):\n",
    "    ab = 'abs_' if plot_abs else ''\n",
    "    absolute_value = f' (absolute r value)' if plot_abs else ''\n",
    "    \n",
    "    fig = plot_lm_tasks(reformed_d, \n",
    "                        'cross-task comparison for LM metrics across models on group difference (t-test)',\n",
    "                        scale='panss_o', measure='t', use_errorbar=True, figsize=figsize, r=2)\n",
    "    plt.savefig(f'{path}{m_type}/model/t_across_tasks.png', dpi=dpi, bbox_inches = 'tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    for i, control_col in enumerate(control_cols):\n",
    "        name = control_col_names[i]\n",
    "        fig = plot_lm_tasks(reformed_d, \n",
    "                            f'cross-task comparison for LM metrics across models on correlation with {name}',\n",
    "                            scale='panss_o', measure=control_col, yname='r',\n",
    "                            plot_abs=plot_abs, use_errorbar=True, figsize=figsize)\n",
    "        plt.savefig(f'{path}{m_type}/model/{ab}corr_{\"_\".join(name.split())}_across_tasks.png', \n",
    "                    dpi=dpi, bbox_inches = 'tight')\n",
    "        plt.close(fig)\n",
    "    \n",
    "    for scale in ORDERED_SCALES:\n",
    "        fig = plot_lm_tasks(reformed_d, \n",
    "                            f'cross-task comparison for LM metrics across models on {scale}{absolute_value}', \n",
    "                            scale=scale, measure='r', \n",
    "                            plot_abs=plot_abs, use_errorbar=True, figsize=figsize)\n",
    "        plt.savefig(f'{path}{m_type}/model/{ab}r_{scale}_across_tasks.png', dpi=dpi, bbox_inches = 'tight')\n",
    "        plt.close(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "dc3525c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_LM_across_tasks(reformed_tasks, plot_abs=True)\n",
    "plot_all_LM_across_tasks(reformed_tasks, plot_abs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800425da",
   "metadata": {},
   "source": [
    "# Reform the dataset to long format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7cdc87",
   "metadata": {},
   "source": [
    "index: unique\n",
    "\n",
    "langugae: de / ru\n",
    "\n",
    "task: (de tasks) / (ru tasks) - 4 for each\n",
    "\n",
    "scale: (de: panss sans saps t test) / (ru: panss dep td t test)\n",
    "\n",
    "metric: name\n",
    "\n",
    "matric_group: 4\n",
    "\n",
    "values: median CI_low CI_high corr_mean_sent_len corr_n_sent corr_n_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "478de643",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_corr_names = ['r_corr_w_mean_sent_len', 'r_corr_w_n_sents', 'r_corr_w_n_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1cc6fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "low = 0.25\n",
    "high = 0.75\n",
    "lang = 'de'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83691433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'fear', 'happiness', 'sadness']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f5d119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_data = []\n",
    "for task in TASKS:\n",
    "    for scale_ in ORDERED_SCALES + ['group_diff', 'sample_raw']:\n",
    "        performance_metric_d = {'sample_raw': 'sample_raw', 'group_diff': 't'}\n",
    "        performance_metric = 'r' if scale_ not in performance_metric_d else performance_metric_d[scale_] \n",
    "        scale_key = 'panss_total' if scale_ not in ORDERED_SCALES else scale_\n",
    "        for metric in cols_av:\n",
    "            metric_group, metric_name = metric\n",
    "            data = reform_tasks_v[(task, scale_key, performance_metric)][(metric_group, metric_name)]\n",
    "            median = np.nanmedian(data)\n",
    "            mean = np.nanmean(data)\n",
    "            CI_low = np.nanquantile(np.array(data), low)\n",
    "            CI_high = np.nanquantile(np.array(data), high)\n",
    "#             if np.isnan(median):\n",
    "#                 print('nan median in: ', task, scale_, performance_metric, metric_group, metric_name)\n",
    "#             line = (lang, task, scale_, metric_name)\n",
    "            control_cols_medians, control_cols_means, control_cols_CI_lows, control_cols_CI_highs = {}, {}, {}, {}\n",
    "            for control_col in control_corr_names:\n",
    "                control_data = reform_tasks_v[(task, scale_key, control_col)][metric]\n",
    "                if control_data[0]:\n",
    "                    c_median = np.nanmedian(control_data)\n",
    "                    c_mean = np.nanmean(control_data)\n",
    "                    c_CI_low = np.nanquantile(np.array(control_data), low)\n",
    "                    c_CI_high = np.nanquantile(np.array(control_data), high)\n",
    "                else:\n",
    "                    c_median, c_mean, c_CI_high, c_CI_low = np.nan, np.nan, np.nan, np.nan\n",
    "                control_cols_medians[control_col] = c_median\n",
    "                control_cols_means[control_col] = c_mean\n",
    "                control_cols_CI_lows[control_col] = c_CI_low\n",
    "                control_cols_CI_highs[control_col] = c_CI_high\n",
    "            long_line = (lang, task, scale_, performance_metric, metric_group, metric_name, \n",
    "                         median, mean, CI_low, CI_high)\n",
    "            for control_col in control_corr_names:\n",
    "                long_line += (control_cols_medians[control_col], control_cols_means[control_col], \n",
    "                              control_cols_CI_lows[control_col], control_cols_CI_highs[control_col])\n",
    "            if long_line not in long_data:\n",
    "                long_data.append(long_line)\n",
    "            else:\n",
    "                print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8e0694b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>task</th>\n",
       "      <th>scale</th>\n",
       "      <th>performance_metric</th>\n",
       "      <th>metric_group</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>CI_low</th>\n",
       "      <th>CI_high</th>\n",
       "      <th>...</th>\n",
       "      <th>corr_mean_sent_len_CI_low</th>\n",
       "      <th>corr_mean_sent_len_CI_high</th>\n",
       "      <th>corr_n_sents_median</th>\n",
       "      <th>corr_n_sents_mean</th>\n",
       "      <th>corr_n_sents_CI_low</th>\n",
       "      <th>corr_n_sents_CI_high</th>\n",
       "      <th>corr_n_words_median</th>\n",
       "      <th>corr_n_words_mean</th>\n",
       "      <th>corr_n_words_CI_low</th>\n",
       "      <th>corr_n_words_CI_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>de</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sample_raw</td>\n",
       "      <td>sample_raw</td>\n",
       "      <td>graph</td>\n",
       "      <td>PE</td>\n",
       "      <td>0.072718</td>\n",
       "      <td>0.092412</td>\n",
       "      <td>0.028025</td>\n",
       "      <td>0.144375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161599</td>\n",
       "      <td>0.301020</td>\n",
       "      <td>0.482556</td>\n",
       "      <td>0.483487</td>\n",
       "      <td>0.430986</td>\n",
       "      <td>0.540829</td>\n",
       "      <td>0.413537</td>\n",
       "      <td>0.414719</td>\n",
       "      <td>0.368688</td>\n",
       "      <td>0.460928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>de</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sample_raw</td>\n",
       "      <td>sample_raw</td>\n",
       "      <td>graph</td>\n",
       "      <td>degree_average</td>\n",
       "      <td>0.053097</td>\n",
       "      <td>0.080566</td>\n",
       "      <td>0.014317</td>\n",
       "      <td>0.124021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231586</td>\n",
       "      <td>0.390299</td>\n",
       "      <td>0.434464</td>\n",
       "      <td>0.432834</td>\n",
       "      <td>0.386642</td>\n",
       "      <td>0.482012</td>\n",
       "      <td>0.411861</td>\n",
       "      <td>0.410253</td>\n",
       "      <td>0.367080</td>\n",
       "      <td>0.455254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>de</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sample_raw</td>\n",
       "      <td>sample_raw</td>\n",
       "      <td>graph</td>\n",
       "      <td>degree_std</td>\n",
       "      <td>0.100820</td>\n",
       "      <td>0.117550</td>\n",
       "      <td>0.044424</td>\n",
       "      <td>0.174172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309745</td>\n",
       "      <td>0.450923</td>\n",
       "      <td>0.463002</td>\n",
       "      <td>0.460349</td>\n",
       "      <td>0.414120</td>\n",
       "      <td>0.509225</td>\n",
       "      <td>0.466058</td>\n",
       "      <td>0.464205</td>\n",
       "      <td>0.423372</td>\n",
       "      <td>0.503094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>de</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sample_raw</td>\n",
       "      <td>sample_raw</td>\n",
       "      <td>graph</td>\n",
       "      <td>number_of_edges</td>\n",
       "      <td>0.209177</td>\n",
       "      <td>0.212705</td>\n",
       "      <td>0.144147</td>\n",
       "      <td>0.277617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402361</td>\n",
       "      <td>0.510313</td>\n",
       "      <td>0.530675</td>\n",
       "      <td>0.529984</td>\n",
       "      <td>0.499753</td>\n",
       "      <td>0.560742</td>\n",
       "      <td>0.560653</td>\n",
       "      <td>0.561677</td>\n",
       "      <td>0.528005</td>\n",
       "      <td>0.592891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>de</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sample_raw</td>\n",
       "      <td>sample_raw</td>\n",
       "      <td>graph</td>\n",
       "      <td>number_of_nodes</td>\n",
       "      <td>0.207853</td>\n",
       "      <td>0.209475</td>\n",
       "      <td>0.143152</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339156</td>\n",
       "      <td>0.452717</td>\n",
       "      <td>0.412672</td>\n",
       "      <td>0.404037</td>\n",
       "      <td>0.358598</td>\n",
       "      <td>0.452844</td>\n",
       "      <td>0.453008</td>\n",
       "      <td>0.452813</td>\n",
       "      <td>0.410813</td>\n",
       "      <td>0.496868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lang     task       scale performance_metric metric_group  \\\n",
       "1627   de  sadness  sample_raw         sample_raw        graph   \n",
       "1628   de  sadness  sample_raw         sample_raw        graph   \n",
       "1629   de  sadness  sample_raw         sample_raw        graph   \n",
       "1630   de  sadness  sample_raw         sample_raw        graph   \n",
       "1631   de  sadness  sample_raw         sample_raw        graph   \n",
       "\n",
       "          metric_name    median      mean    CI_low   CI_high  ...  \\\n",
       "1627               PE  0.072718  0.092412  0.028025  0.144375  ...   \n",
       "1628   degree_average  0.053097  0.080566  0.014317  0.124021  ...   \n",
       "1629       degree_std  0.100820  0.117550  0.044424  0.174172  ...   \n",
       "1630  number_of_edges  0.209177  0.212705  0.144147  0.277617  ...   \n",
       "1631  number_of_nodes  0.207853  0.209475  0.143152  0.270386  ...   \n",
       "\n",
       "      corr_mean_sent_len_CI_low  corr_mean_sent_len_CI_high  \\\n",
       "1627                   0.161599                    0.301020   \n",
       "1628                   0.231586                    0.390299   \n",
       "1629                   0.309745                    0.450923   \n",
       "1630                   0.402361                    0.510313   \n",
       "1631                   0.339156                    0.452717   \n",
       "\n",
       "      corr_n_sents_median  corr_n_sents_mean  corr_n_sents_CI_low  \\\n",
       "1627             0.482556           0.483487             0.430986   \n",
       "1628             0.434464           0.432834             0.386642   \n",
       "1629             0.463002           0.460349             0.414120   \n",
       "1630             0.530675           0.529984             0.499753   \n",
       "1631             0.412672           0.404037             0.358598   \n",
       "\n",
       "      corr_n_sents_CI_high  corr_n_words_median  corr_n_words_mean  \\\n",
       "1627              0.540829             0.413537           0.414719   \n",
       "1628              0.482012             0.411861           0.410253   \n",
       "1629              0.509225             0.466058           0.464205   \n",
       "1630              0.560742             0.560653           0.561677   \n",
       "1631              0.452844             0.453008           0.452813   \n",
       "\n",
       "      corr_n_words_CI_low  corr_n_words_CI_high  \n",
       "1627             0.368688              0.460928  \n",
       "1628             0.367080              0.455254  \n",
       "1629             0.423372              0.503094  \n",
       "1630             0.528005              0.592891  \n",
       "1631             0.410813              0.496868  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_df = pd.DataFrame(long_data, columns=('lang', 'task', 'scale', 'performance_metric',\n",
    "                                           'metric_group', 'metric_name', 'median', 'mean', 'CI_low', 'CI_high',\n",
    "                                           'corr_mean_sent_len_median', 'corr_mean_sent_len_mean', \n",
    "                                           'corr_mean_sent_len_CI_low', 'corr_mean_sent_len_CI_high',\n",
    "                                           'corr_n_sents_median', 'corr_n_sents_mean',\n",
    "                                           'corr_n_sents_CI_low', 'corr_n_sents_CI_high',\n",
    "                                           'corr_n_words_median', 'corr_n_words_mean',\n",
    "                                           'corr_n_words_CI_low', 'corr_n_words_CI_high',))\n",
    "long_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "09c0a686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>task</th>\n",
       "      <th>scale</th>\n",
       "      <th>performance_metric</th>\n",
       "      <th>metric_group</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>CI_low</th>\n",
       "      <th>CI_high</th>\n",
       "      <th>...</th>\n",
       "      <th>corr_mean_sent_len_CI_low</th>\n",
       "      <th>corr_mean_sent_len_CI_high</th>\n",
       "      <th>corr_n_sents_median</th>\n",
       "      <th>corr_n_sents_mean</th>\n",
       "      <th>corr_n_sents_CI_low</th>\n",
       "      <th>corr_n_sents_CI_high</th>\n",
       "      <th>corr_n_words_median</th>\n",
       "      <th>corr_n_words_mean</th>\n",
       "      <th>corr_n_words_CI_low</th>\n",
       "      <th>corr_n_words_CI_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [lang, task, scale, performance_metric, metric_group, metric_name, median, mean, CI_low, CI_high, corr_mean_sent_len_median, corr_mean_sent_len_mean, corr_mean_sent_len_CI_low, corr_mean_sent_len_CI_high, corr_n_sents_median, corr_n_sents_mean, corr_n_sents_CI_low, corr_n_sents_CI_high, corr_n_words_median, corr_n_words_mean, corr_n_words_CI_low, corr_n_words_CI_high]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 22 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_df[long_df[['lang', 'task', 'scale', 'metric_group', 'metric_name']].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "62e4b44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['panss_pos', 'panss_neg', 'panss_o', 'panss_total', 'saps_total',\n",
       "       'sans_total', 'group_diff', 'sample_raw'], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_df.scale.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ec9ba500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['r', 't', 'sample_raw'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_df.performance_metric.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d91bafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df.to_csv(PATH + '/long_de.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
