% Chapter 1

\chapter{Introduction} % Main chapter title
\label{chap:1:intro}

The aim of the present work is to benchmark the commonly used natural language processing methods of detecting psychosis and its symptoms. The introduction is structured as follows. First, I discuss psychotic disorders, the role that incoherent language plays in diagnosing and detecting them, the ways of conceptualizing the incoherence, and the possible psychiatric explanations for the origin of the incoherent language (\ref{sec:intro:psychosis}). Then, I turn to the various NLP approaches that have been suggested for psychosis detection over the years, indicating for each approach, which symptoms or conceptualizations of psychotic incoherence the approach tries to approximate (\ref{sec:intro:NLP}). Finally, I review some issues with both internal and external validity of the suggested approaches (\ref{sec:intro:validity}) and conclude with a short motivation for the present work (\ref{sec:intro:motivation}).


%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Incoherent Language in Psychosis}
\label{sec:intro:psychosis}

Psychosis is a common functionally disruptive symptom of many psychiatric conditions. It is characterised by delusions, hallucinations, and formal thought disorder.  Psychosis is the defining feature of schizophrenia spectrum disorders (SSD), such as schizophrenia, schizoaffective disorder, and schizotypal disorder, and a common but variable feature of mood disorders, such as bipolar disorder \citep{arciniegas2015psychosis}\footnote{As most papers test the methods on schizophrenia spectrum disorders, I will use the terms SSD and psychotic disorder interchangeably and specify separately if non-SSD disorders are included in a study.}.

\citet{kraepelin1919dementia}, defining what would later be referred to as schizophrenia, stated that derailment, loose associations, and incoherence of thought manifest themselves through disordered speech, and Bleuler stressed the importance of aberrant language as an important feature of schizophrenia \citep{bleuler1911dementia}. These features of psychotic speech and thought are covered by the term formal thought disorder (FTD) introduced by \citet{andreasen1986tlc}. Importantly, incoherent or disordered speech serves as a key diagnostic criterion for schizophrenia spectrum disorders in the two major diagnostic manuals, the International Classification of Diseases (\href{https://icd.who.int/browse10/2016/en#/F20-F29}{ICD-10}\footnote{\cite{world1992icd}}) and the Diagnostic and Statistical Manual of Mental Disorders (DSM-5\footnote{\cite{american2013dsm}}). A general overview of language anomalies characteristic of schizophrenia can be found in \citet{kuperberg2010language_a, kuperberg2010language_b, de2020anomalies}. 

%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\subsection{Psychosis and Formal Thought Disorder}

Formal thought disorder conceptualization of speech and thought anomalies observed in psychosis is often used as the guiding principle for developing automated psychosis detection tools. Formal thought disorder is defined as a set of specific disturbances in thought, speech, and communication that are typical of psychosis \citep{hart2017rethinking}. The symptoms of thought disorder can be divided into positive and negative. 

In general, positive symptoms are the symptoms that are not experienced normally but are typically present during a psychotic episode. These include delusions, hallucinations, and disorganized thoughts and speech. Positive thought disorder is the respective subset of FTD features that includes positive symptoms manifesting in speech and thought such as \textit{incoherence}, \textit{tangentiality}, \textit{circumstantiality}, and \textit{peculiar word use}. 

Negative symptoms are the symptoms that manifest deficits in emotional responses or thought processes. Negative thought disorder includes such negative symptoms of FTD as \textit{poverty of speech and speech content}, \textit{blocking}, and \textit{perseveration}.

The positive and negative symptoms that are typical of psychotic disorders are usually assessed with the positive and negative syndrome scale (PANSS, \cite{kay1987positive}) or using the two scales for the assessment of positive and negative symptoms, abbreviated as SAPS \citep{andreasen1984saps} and SANS \citep{andreasen1984sans}. While PANSS only identifies the language-specific disturbances very broadly (using \textit{conceptual disorganization} for all positive speech disturbances and \textit{lack of spontaneity and flow of conversation} and \textit{stereotyped thinking} for the negative ones), SAPS and SANS include detailed subscales to assess the most common positive and negative anomalies of speech and thought typical of positive and negative FTD. 

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------

\subsection{Conceptualizations of Incoherent Language}

There is no unified linguistic theory to encompass all the features that contribute to coherence. Defining incoherence as `speech that is essentially incomprehensible at times', \citet{andreasen1986tlc} states that incoherence may arise through `several different mechanisms, which may sometimes all occur simultaneously'. This is because coherence is normally maintained simultaneously on many levels, including lexical connectors, syntactic structure, intonation, reference, and logical structure of a text. As a result, different researchers rely on different conceptualizations when they develop automated psychosis detection tools. 

Some researchers rely on broad conceptualizations, such as \textit{global coherence} defined as the relationship of every clause to the overall topic of the text \citep{glosser1991patterns}, \textit{local coherence} defined as similarity in content and logical connectedness of adjacent sentences, or \textit{cohesion} which encompasses grammatical and lexical linking within a text that holds it together. 

Others use the scales aimed at measuring formal thought disorder as a source of conceptualization. There are a number of scales that aim at identifying different features of formal thought disorder: including TLC\footnote{Thought Language and Communication scale \citet{andreasen1986tlc}}, SANS \& SAPS\footnote{\cite{andreasen1984sans, andreasen1984saps}}, TLI\footnote{Thought and Language Index, \citet{liddle2002tli}}, TALD\footnote{Thought and Language Disorder Scale, \citet{kircher2014tald}}, and K-FTDS\footnote{Kiddie Formal Thought Disorder Rating Scale, \citet{caplan1989kftds}}. There are several linguistic features that are underlined in all of these scales and are commonly used in automated psychosis detection research, which I discuss below. I cover these features here so that in discussing the existing metrics, I can refer to them, indicating which manifestations of positive and negative thought disorder could potentially be detected by higher or lower metric values.

Commonly used positive FTD features in these scales include many features indicating some form of inability to stay on topic. It may come in the form of being distracted by nearby stimuli interrupting the flow of speech (\textit{distractible speech}); in the form of ideas slipping off track onto ideas obliquely related or unrelated (\textit{derailment}, as well as \textit{loosening of associations} and \textit{flight of ideas}); or in the form replying in an oblique or irrelevant manner (\textit{tangentiality}). Additionally, the inability to stay on topic can take the form of \textit{circumstatiality}, where speech is very indirect and delayed in reaching its goal idea. The disconnectedness between speech fragments may take the form of \textit{illogicality}, where the conclusions are reached that do not follow logically from the premises, or general \textit{incoherence}, indicating speech that is essentially incomprehensible at times and may manifest in its severest form as schizophasia. Incoherence may stem from syntactic or grammatical errors, semantically unmotivated word choices, and lack of proper cohesion devices, such as coordinating and subordinating conjunctions or coreferences. Additionally, the rate and amount of speech might be increased, which is referred to as \textit{pressured speech}. Some of the common positive FTD features also emphasize peculiar word choice, manifesting as incorrect or unconventional word use and phonetic associations (\textit{paraphasias}), as well as the invention of new words (\textit{neologisms}).

Commonly used negative FTD features in these scales include general \textit{poverty of speech}, which indicates decreased amount and rate of speech, brevity, low verbosity; \textit{poverty of speech content} referring to vague, overly concrete or overly generalized speech, conveying little information\footnote{Both poverty of speech and poverty of content may be sometimes referred to as \textit{alogia}.}; and inability to reach the goal, which may be a result of sudden interruption (\textit{blocking}) or slow drift  (\textit{loss of goal}). The patients may also have a tendency to repeat ideas or words over and over, which is referred to as \textit{perseveration} or \textit{verbigeration}.

Finally, some researchers test a broad variety of linguistic features to identify the ones that might help detect psychosis without referring to any pre-existing theories regarding these features.

It is not entirely clear whether negative or positive FTD aspects of language are more easily detected by NLP methods. In the present work, I set out to analyze the most commonly utilized features regardless of their conceptualization. For the features that clearly correspond to a facet of FTD, it is reported whether they are expected to be higher or lower in patients and whether this, in general, holds true across the features corresponding to an FTD symptom. 

% To this date, there is no universal set of guidelines for identifying disordered speech. Various existing techniques of quantifying speech incoherence are quite subjective, as they rely on the judgment and experience of an individual psychiatrist. “Disorganized speech” as a symptom lacks linguistic insight (Cohen et al., 2017), as this terminology fails to reflect the fact that language has multiple interdependent levels of organization (phonetics, morphology, syntax, discourse, pragmatics, and interactional markers).


%-----------------------------------
%	SUBSECTION 3
%-----------------------------------
\subsection{Theories of Incoherence in Psychosis}

In a dedicated review, \citet{ditman2010building} outline two main types of theoretical frameworks explaining the origins of discourse incoherence observed in schizophrenia: executive dysfunction theories (also known as impaired cognition theories); and loose association theories. The former theories state that the lack of control over the process of thinking, typical of negative thought disorder, is the driving reason for the observed incoherence of speech in FTD. The latter, on the other hand, explain the incoherence in terms of tangentiality and loose associations that are characteristic of positive thought disorder. However, there is no definitive evidence for either theory being the main cause of the speech incoherence seen in schizophrenia spectrum disorders. Moreover, aspects of both positive and negative formal thought disorder may be contributing to incoherence in any given patient. The lack of clear evidence for either theory is partially due to the inter-dependency between processes involved in speech production and partially due to the multiplicity of processes reflected in speech. It is further complicated by the fact that coherence heavily depends on both textual and social context \citep{cohen2017can}. Interestingly, there is modelling evidence for different NLP methods being more sensitive to different aspects of FTD, which could be regarded as indirect evidence for both mechanisms contributing to the incoherence that is typical of psychosis \citep{fradkin2023theory}.


%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------

\section{Natural Language Processing for Psychosis Detection}
\label{sec:intro:NLP}

Natural language processing offers a variety of automated methods and tools for working with various aspects of language. Utilizing these tools for psychosis detection has been pioneered by \citet{elvevaag2007quantifying} and many different metrics have been developed since, though reproducibility remained limited \citep{hitczenko2021understanding, parola2022speech, fradkin2023theory}. In the present work, psychosis detection is used as a general term for several somewhat different tasks: firstly, distinguishing between healthy controls and patients with a psychotic disorder, secondly, predicting conversion in populations at high risk for psychosis, and, finally, predicting the differences in symptom prevalence or severity between different patients. Natural language processing approaches to psychosis detection supposedly offer a fast, sensitive, and objective solution to psychosis detection and symptom severity assessment. However, such approaches must be applied with great caution, as prognostic assessment may significantly affect or even stigmatize the patients and the results may be sensitive to many external factors \citep{just2023validation}, a topic further discussed in section \ref{sec:intro:validity}.
% However, the clinical relevance and therapeutic value of NLP methods in psychiatry still needs to be proven – especially against the background that a prognostic assessment may significantly affect or even stigmatize individuals (22) and that patients may be triggered by stressful situations including clinical settings (23).

Below, I introduce some of the natural language processing methods that have been applied to the task of psychosis detection. The methods are grouped, according to the type of linguistic material they operate on, into lexical, syntactic, and semantic. The metrics are discussed in greater detail in the next chapter, \ref{chap:2:review}. Note, that this work is mostly concerned with the linguistic features that occur both in written and spoken texts, leaving the acoustic\footnote{Acoustic features, such as spectral, frequency, and amplitude parameters were explored in \citet{voppel2023semantic, tang2023latent, de2023acoustic, wouts2021belabbert}.} and temporal\footnote{Such temporal features as speech rate and pausation patterns were used by \citet{aich2022towards, liebenthal2022linguistic, de2023acoustic, tang2023latent} to distinguish between patients and controls as well as predict symptom severity assessed by psychiatric scales.} features outside of the scope of the present work. 
% , as well as discourse\footnote{Such features as false-starts, self-repairs, repetitions, as well as hesitation pauses have been used successfully to detect psychosis, psychotic symptoms, or social cognition in psychotic patients \citep{vail2018toward, liebenthal2022linguistic, girard2022computational, tang2022clinical, tang2023latent}.}

%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\subsection{Lexical Methods}

Under lexical methods I include all the methods that operate over words and focus on word use. These include \textit{verbosity} or word count; \textit{lexical diversity} metrics, such as type-token ratio (TTR) or average word frequency; \textit{sentiment analysis} metrics, such as use of negative or positive emotion words; and \textit{topic analysis}, usually assessed with a specified tool based on dictionaries. The tools used for lexical analysis often incorporate a variety of word-based metrics, \href{https://www.liwc.app} {LIWC} having 72 metrics \citep{tausczik2010psychological}, \href{https://www.linguisticanalysistools.org/taaco.html}{TAACO} - 34 \citep{crossley2019tool}, and \href{http://cohmetrix.memphis.edu/cohmetrixhome/documentation_indices.html}{Coh-Metrix L3} - 108 \citep{mcnamara2014automated}. 

The lexical methods may aim at capturing both positive and negative FTD features. Verbosity in penitents may either be increased (pressure of speech) or decreased (poverty of speech). Lexical diversity and density may be increased (paraphasias) or decreased (poverty of speech and content). Sentiment analysis may reveal the blunted affect which is a typical non-linguistic negative symptom of schizophrenia. Finally, topic analysis may reveal common topics shared between different patients which may be related to both negative and positive symptoms.

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------
\subsection{Syntactic Methods}

Under syntactic methods, I include methods relating to syntactic types and structures. These include \textit{part-of-speech} based metrics; \textit{referential} metrics, such as the use of ambiguous pronouns and cataphora\footnote{Cataphora is the use of the referential phrase that refers to or stands for a later word or phrase as in ``If you want \textit{them}, there are \textit{cookies} in the kitchen''.}; measures of \textit{syntactic complexity} calculated based on use of various syntactic structures such as coordinated or subordinated clauses as well as the use of negation or passive and active voice; and, finally, the \textit{lengths and counts} of various syntactic units, such as clauses and sentences.

The differences in the relative frequency of parts of speech use commonly indicate reduced syntactic complexity, which may be connected with negative FTD (poverty of speech), while reduced use of descriptive words (i.e. adjectives and adverbs) as well as reduced use of referential devices, which can be regarded as indicative of poverty of content. %\citep{corcoran2018prediction, bar2019semantic, tang2021natural, ziv2022morphological}. 
Similarly, reduced syntactic complexity may be indicative of poverty of speech or speech content. On the other hand, ambiguous pronouns may be one of the driving forces behind perceived incoherence, caused by the loosening of associations, typical of positive FTD.

%-----------------------------------
%	SUBSECTION 3
%-----------------------------------
\subsection{Semantic Methods}
Under semantic methods, I include methods operating on the level of the entire text and trying to assess some of its properties based on its meaning. The semantic methods can be further divided, methodologically, into the graph-based methods and the ones that use language models (LMs) to represent the text.


\subsubsection{Graph-Based Methods}
Graph-based methods include all the methods that represent a text with a graph and subsequently calculate properties of the graph, such as size or some measure of connectivity. The graph representations can be based on the \textit{co-occurrence} of words in the text, with words used as the nodes of the graph and neighbouring words being connected by a directed edge. Alternatively, the graphs may be based on a \textit{semantic} representation of the text, which can be obtained with semantic role labelling tools (SRL, \cite{gildea2002automatic}). 

% The graphs can also be built at the level of sentences rather than words, as in Rhetorical Structure Theory (RST, \cite{mann1988rhetorical}) and the distribution of edge types may be used as a predictive feature.

Reduced graph connectivity is typically regarded as indicative of positive FTD symptoms such as incoherence or derailment and flight of ideas, as, when very little is said on any given topic, the resulting graph is largely disconnected. On the other hand, very high connectivity may be indicative of negative FTD symptoms of poverty of speech content or perseveration.

\subsubsection{Language Model-Based Methods}
Language model-based methods use mathematical models to represent the texts numerically and consequently calculate some metric over the representation. The models are trained on large corpora to approximate probability distributions over sequences of linguistic units. They can learn and encode some of the semantic and syntactic features of the texts based on the co-occurrence of the words and sentences in the corpus. These models can be used to represent words or larger text fragments with vectors which are called \textit{embeddings} and which encode the properties learnt by the model. The embeddings can be divided into \textit{non-contextualized} which operate like dictionaries of words to vectors and \textit{contextualized} that let the context in which a word appears to influence the embedding vector, allowing for disambiguation and better handling of unseen words. Non-contextual embeddings include representations obtained from n-grams, latent semantic analysis (LSA, \citet{landauer1998introduction}), word2vec (w2v, \citet{mikolov2013distributed}), GloVe \citep{pennington2014glove} for word representation and sent2vec \citep{moghadasi2020sent2vec} for sentence representation. Contextualized embeddings can be obtained from BiLSTM and ELMo \citep{peters2017semi}, BERT \citep{devlin2018bert}, RoBERTa \citep{liu2019roberta} and other attention-based models \citep{vaswani2017attention, openai2023gpt4}.

There are several ways in which language models can be applied to psychosis detection. First, there are \textit{embedding-based metrics} that represent words or sentences with vectors using an LM and then calculate some metric over the vectors, usually based on the cosine similarity of these vectors. Such metrics include the similarity of consecutive units, the similarity of units at a fixed distance, the similarity of a given unit to some standard unit, and the slope of difference of units from the question or initial prompt. Secondly, LMs can provide some measure of \textit{text predictability} such as perplexity or probability from BERT next sentence prediction. Finally, LMs can be \textit{fine-tuned} to be used as \textit{classifiers} for psychosis detection or symptom severity assessment. The embeddings can also be used as the input to a simple classifier, which I will refer to as \textit{non-fine-tuned classifiers}.

The similarity-based metrics typically try to capture positive FTD symptoms such as incoherence or derailment as well as tangentiality. Lowered text predictability may also be seen as indicative of incoherence or derailment while higher values may indicate negative symptoms such as perseveration and poverty of speech content.

%----------------------------------------------------------------------------------------
%	SECTION 3
%----------------------------------------------------------------------------------------

\section{Theoretical Validity of NLP Approaches \\ to Psychosis Detection}
\label{sec:intro:validity}

In this section, I outline some of the questions about the validity of the proposed NLP approaches. In psychology, \textit{internal} validity examines whether a study answers the research questions without bias and \textit{external} validity examines whether the study findings can be generalized to other contexts \citep{andrade2018internal}. Applying these definitions to the context at hand, 
% the internal validity of a given metric is only defined if the metric is trying to approximate some psychiatric or linguistic concept. A
a metric would be internally valid if it successfully approximates the concept, such as coherence or poverty of speech (\textit{construct} validity); and is not biased by any known confounding factors. The external validity of a metric would refer to the ability of the metric to be applied in a variety of contexts, including such external factors as sensitivity to the choice of pre-processing, embedding model, and elicitation task (\ref{sec:intro:external-validity}), as well as cross-linguistic applicability (\ref{sec:intro:cross-linguitic-applicability}).

%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\subsection{Internal Validity}
\label{sec:intro:internal-validity}

In order to apply the NLP-derived metrics to clinical settings, it is important to assess the internal validity of the metrics that rely on the psychiatric or linguistic conceptualizations mentioned above. This could be achieved by correlating the metrics with human ratings, as suggested in the foundational study \citet{elvevaag2007quantifying}, or with the respective TLI, TLC, TALD, or SANS \& SAPS subscales (see \citet{bilgrami2022construct} for a study of construct validity in psychosis detection). Additionally, it is important to assess if the metric is associated with positive or negative FTD as would be expected based on the conceptualization. This could be achieved by measuring positive and negative symptoms in general using PANSS, as done in most % 45/62
studies in the field, or using the aforementioned thought disorder scales, such as SANS \& SAPS. Though many studies use some of the thought disorder scales %17/62
, few correlate the metrics with the TD subscales but rather use the overall score. While some studies report correlation with the expected subscales (e.g. \citet{vail2018toward, just2020modeling, jeong2023exploring}), many fail to find such relations (e.g. \citet{bedi2015automated, corcoran2018prediction, iter2018automatic, hitczenko2021understanding}). In fact, several reviews point out that the relations between psychiatric constructs of language disturbances and the metrics might not be straightforward \citep{cohen2017can, holmlund2022towards}.

As for confounding factors, introducing possible biases, many of the proposed metrics are known to be sensitive to such factors as sentence or text \textit{length}\footnote{\citet{elvevaag2007quantifying, mota2014graph, iter2018automatic, corcoran2018prediction, hitczenko2021understanding, parola2022speech, jeong2023exploring}}, \textit{repetitions}\footnote{\citet{elvevaag2007quantifying, iter2018automatic, just2019coherence}}, and \textit{preprocessing}, including sentence segmentation and removal of stop words and filler words\footnote{\citet{parola2022speech, holmlund2022towards}}. Such dependencies stem naturally from the definitions of some of the LM-based and graph-based metrics. For example, cosine similarity-based metrics yield higher results on more repetitive texts and longer sentences. Surprisal or perplexity is also known to be higher on longer sentences. The number of nodes in graph-based metrics is closely related to the total number of words. As for preprocessing, any metric that relies on sentence boundaries is reliant on the human annotator's decisions if the original text is spoken rather than written. All these factors are quite problematic in the context of psychosis detection. Patients with SSD are commonly reported to be less verbose, producing significantly fewer words in most studies that report verbosity and often produce significantly fewer or shorter sentences. The repetitiveness which may be indicative of schizophrenia (perseveration) could artificially drive the cosine-similarity metrics up. The verbal filler production may also be altered in some SSD patients introducing a problematic preprocessing dependence.

% PREPROCESSING (PAROLA et al 2022) We found no differences in the Danish corpus: results were robust to changes in the cleaning options. Instead, we found differences in the German corpus once we changed the cleaning options. In particular, including punctuations and fillers in the analysis, we found that the differences between patients with schizophrenia and controls in some coherence measures (Coherence 10, Coherence-k, Second-order coherence) varied. For the Chinese corpus, we found some variation in the Coherence-k and Second-order coherence when including punctuations and fillers in the analysis, but results were generally robust to changes in the cleaning options. Overall, these results show how NLP measures of coherence, and in particular cosine similarity derived measures, are sensitive to fillers and punctuations, and how these components can introduce bias in the analysis. As for transcript length, in line with previous literature (Elvevag et al., 2007; Iter et al., 2018; Corcoran et al., 2018; Hitczenko et al., 2022), we found that transcript length is positively associated with the various coherence measures, that is longer transcripts have generally higher coherence values. This confirms that the impact of transcript length should be controlled in the analysis in order to avoid possible bias in the results. 

Some metrics might also not be sensitive to features that they should presumably be sensitive to, such as word or sentence shuffling or word replacement. There are studies that explore artificial perturbations and language modelling as a way of testing construct validity of LM-based metrics assessed using correlation with manual scores \citep{fradkin2023theory} or test for differences introduced by perturbations of control texts \citep{bedi2015automated, hitczenko2021understanding}.
% bedi sent shuffling
% hitzenko effects of length

A notable complication for construct validity assessment for some of the metrics is the fact that the interpretation cannot be linear. While high scores along psychiatric dimensions of tangentiality or incoherence always indicate abnormality, the metrics might have `optimal' values, while both low and high values outside this range could be considered abnormal \citep{fradkin2023theory}. For example, very low perplexity would indicate repetitive or stereotyped speech and very high perplexity would indicate incoherence or word salad. Conversely, very low cosine similarity metric scores would indicate incoherence and very high scores would indicate high repetitiveness. Thus, unlike psychiatric scales, both high and low metric scores may indicate abnormality.

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------
\subsection{External Validity}
\label{sec:intro:external-validity}

The assessment of external validity for most metrics is limited by the diagnostic and design dissimilarities in the studies that report contradictory results for a given metric. 

First of all, the dissimilarities may concern the population the study was conducted on. The studies may investigate in- or out-patients, patients with or without manifest thought disorder, and with prevailing positive or negative symptoms. The diagnostic categories used in each study also vary from one diagnosis (e.g. schizophrenia) to broader diagnostic categories such as schizophrenia spectrum disorder or non-affective psychosis\footnote{Includes schizophrenia (SZ), schizoaffective disorder (SZA), schizophreniform disorder (SFD),  and schizotypal disorder (SD).} and psychotic disorder\footnote{Additionally includes the affective disorders with psychotic symptoms, such as some manifestations of bipolar disorder}. Additionally, some studies explore patients at high risk for psychotic disorders\footnote{\cite{bedi2015automated, rosenstein2015language, corcoran2018prediction, gupta2018automated, rezaii2019machine, haas2020linking, hitczenko2021understanding, bilgrami2022construct}} or healthy relatives \citep{elvevaag2010automated}. The proportion of female patients, as well as average age, racial identity, education, and income level, may also vary greatly from study to study, and some of the metrics are reported to be sensitive to such factors \citep{hitczenko2021understanding, palaniyappan2021more, minor2023automated}.

The study design may vary with respect to elicitation tasks used to obtain speech samples, with some studies using spoken and some written discourse, some utilizing monologue and some dialogue, and some obtaining very short and some very long speech samples. The speech may also be structured or unstructured, connected to some topic for all patients or entirely free from any prompt. The most typical tasks include picture description tasks and semi-structured interviews. The differences stemming from the elicitation tasks can be observed in most studies using several tasks\footnote{Such task dependence is observed in many studies including \cite{elvevaag2007quantifying, mota2016quantifying, mota2017thought, just2019coherence, ryazanskaya2020thesis}.}.

The psychosis detection tasks used in a study may include tests identifying group differences between patients and controls, correlation with symptom severity, or predictive models for either of these tasks. The studies with clinical high-risk populations also often feature prediction of conversion to psychosis, and longitudinal studies try to predict disease course or longitudinal symptom severity.

Finally, the studies also differ with respect to the suite of metrics applied in the study, including the choice of embedding models, as well as the choice of preprocessing, such as transcription protocols, punctuation, filler and stop word removal. Some of the differences observed in the studies may also stem from cross-linguistic differences or differences in the availability and quality of NLP tools for different languages.

It is worth noting, that even the models that do not aim at approximating any psychiatric construct and simply try to identify group differences or predict symptom severity are subject to external validity limitations. As the datasets in the field are typically small\footnote{Mode - 59 patients and 44 controls, mean - 20 patients and 21 controls.} and the study designs are very diverse, the trained classifiers are likely to be inapplicable to any other study or setting. Such models lack transferability, limiting their practical value, and could also lack interpretability, requiring additional analysis for any theoretical value. 

%-----------------------------------
%	SUBSECTION 3
%-----------------------------------
\subsection{Cross-Linguistic Applicability}
\label{sec:intro:cross-linguitic-applicability}

Another important consideration when it comes to external validity is the cross-linguistic applicability of the proposed methods. 

First of all, there are ways in which some methods are inherently inapplicable to some languages. For example, while the use of determiners has been used as an indicator in many papers analyzing English (e.g. \cite{bedi2015automated, tang2021natural, bilgrami2022construct}), Polish does not have an equally broad category of determiners and thus this metric can not be used on a Polish-speaking population \citep{sarzynska2021detecting}. Similarly, the frequency of use of some part of speech present in both languages or some construction, such as cataphora, may differ between the languages, making a metric that is useful in one language practically inapplicable in another. Incoherence may manifest differently in different languages, and what would be incoherent in one language may be more or less normal in another.

Secondly, there are some limitations imposed by the tools used for natural language processing. Many methods that may be applicable across languages, would require that the tools that calculate them be translated for every new language which is time-consuming and in many cases practically infeasible. Some tools are indeed translated, such as LIWC which is translated into 15 languages. However, it is not a free open-source tool, which is also a limiting factor. There are also methods that are applicable across languages but might be influenced by the training resources available for a given language. This is especially important for LM-based metrics, as LM performance is closely linked to the size of the training dataset (\cite{kaplan2020scaling}). It is crucial to take into account these limitations when applying the NLP methods of psychosis detection cross-linguistically.

Recently, many studies applied the NLP-based methods of psychosis detection to a variety of languages, including Chinese\footnote{\cite{parola2022speech}}, Danish\footnote{\cite{parola2022speech}}, Dutch\footnote{\cite{dore2019quantification, voppel2021quantified, wouts2021belabbert, corona2022assessing, voppel2023semantic, de2023acoustic}}, German\footnote{\cite{koranova2017analyzing, just2019coherence, just2020modeling, parola2022speech, schneider2023syntactic}}, Hebrew\footnote{\cite{bar2019semantic, ziv2022morphological, shriki2022masking}}, Polish\footnote{\cite{sarzynska2021detecting}}, Portuguese\footnote{\cite{mota2014graph, mota2017thought, mota2022happy, argolo2023burnishing}}, Russian\footnote{\cite{panicheva2019semantic, panicheva2020corpus, ryazanskaya2020automated}}, and Spanish\footnote{\cite{palominos2023coreference}}. Despite that, the vast majority of metrics were developed and tested for English, and the results for other languages are often mixed, negative, or even contradictory to the findings for English \citep{koranova2017analyzing, bar2019semantic, panicheva2019semantic, dore2019quantification, parola2022speech}. 

I believe it is important to aim for cross-linguistically applicable NLP methods of psychosis detection, as well as to thoroughly test the cross-linguistic applicability of existent methods, keeping in mind the robustness with respect to resource availability and training corpora size for various languages.

I believe it is also important to aim for metrics that would be interpretable, internally valid, and transferable to settings other than the original. That is, the metrics should approximate a meaningful concept, should correlate with human judgements of the approximated concept, and should be independent of or corrected for known linguistic confounding factors. To achieve this goal, the proposed metrics must be validated with respect to psychiatric scales, theoretical assumptions, known confounding factors, and transferability potential.


%----------------------------------------------------------------------------------------
%	SECTION 4
%----------------------------------------------------------------------------------------

\section{Motivation}
\label{sec:intro:motivation}

The goal of the present work is to compare some of the most frequently used methods across the groups described above on two psychotic speech samples in German and Russian languages, prioritizing the metrics that can potentially be applied cross-linguistically and cross-methodologically. Moreover, this work aims at theoretical validation of some of these methods, assessing how the length of a sentence or utterance affects the metrics, as some of the metrics were reported to be strongly dependent on this confounding factor.

The present study aims to accomplish the following research goals. First, to establish the relative performance of the most commonly used metrics in NLP-based psychosis detection, as well as the relative performance of metric groups, delineating patterns of correlation with negative and positive symptoms. Second, to check whether the best metrics perform consistently across languages, elicitation tasks, and other methodological choices, such as the choice of embedding model. Third, to investigate which of the commonly used metrics are associated with mean sentence length, checking also whether the previously suggested patterns of length dependence in LM-based metrics hold on the present samples. Finally, to check whether the commonly used NLP-based metrics of psychosis detection can outperform the simplest baseline metrics, such as word count, sentence count, and mean sentence length.

% which metrics work best
% which metrics work for which scales (positive vs negative)
% which metrics work on both languages
% which metrics work across tasks // models
% which metrics are associated with mean sentence length length
% which metrics outperform the simplest baselines (word count, sentence count, mean sentence length)

Taken together, this may shed some light on the relative robustness and methodological validity of the tested metrics.

% The planned theoretical validation will assess several distributional aspects of the selected metrics on a control corpus. First, how the size of the difference between the groups compares to normal variance in the metric on a comparable sample size. Second, how the length of text affects the variance in metrics, indicating what amount of material may be sufficient for robust assessment . Finally, how length of sentence or utterance affects the metrics, as some of the metrics were reported to be strongly dependent on this confounding factor. Together, this may shed some light on the relative robustness and methodological validity of the tested metrics.


% --- lexical --- 
% MATTR & LTR
% # words

% --- syntactic --- 
% POS: 
% - determiners and wh-words
% - adj 
% - adv
% - verb 
% - noun
% - pronoun
% sentence length
% sentence count

% --- graph ---
% ? # nodes in LSC
% ? # nodes in LCC
% ? # nodes
% ? # edges
% ? LSCz
% ? LCCz
% ? density
% ? diameter
% ? ASP


% --- LM - w2v + IDF & BERT --- 
% coherence 
% SOC
% centroid global & cumulative global coherence
% ? average window coherence
% ? adjacent word similarity

% ? perplexity
% ? next-sentence prediction 

% mean