% Chapter 1

\chapter{Introduction} % Main chapter title
\label{chap:1:intro}



%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Incoherent Language in Psychosis}

Psychosis is a common functionally disruptive symptom of many psychiatric conditions. It is characterised by delusions, hallucinations, and formal thought disorder.  Psychosis is the defining feature of schizophrenia spectrum disorders (SSD), such as schizophrenia, schizoaffective disorder, and schizotypal disorder, and a common but variable feature of mood disorders, such as bipolar disorder \citep{arciniegas2015psychosis}.\footnote{As most papers test the methods on schizophrenia spectrum disorders, I will use terms SSD and psychotic disorder interchangeably, and specify separately if non-SSD disorders are included in a study.}

\citet{kraepelin1919dementia}, defining psychotic disorders, stated that derailment, loose associations, and incoherence of thought manifest themselves through disordered speech, and Bleuler stressed the importance of aberrant language as a feature of schizophrenia \citep{bleuler1911dementia}. These features of psychotic speech and thought are covered by the term formal thought disorder (FTD) introduced by \citet{andreasen1986tlc}. Importantly, incoherent or disordered speech serves as a key diagnostic criterion for schizophrenia spectrum disorders in the two major diagnostic manuals, the International Classification of Diseases (\href{https://icd.who.int/browse10/2016/en#/F20-F29}{ICD-10}\footnote{\cite{world1992icd}}) and the Diagnostic and Statistical Manual of mental disorder (DSM-5\footnote{\cite{american2013dsm}}). A general overview of language anomalies characteristic of schizophrenia can be found in \citet{kuperberg2010language_a, kuperberg2010language_b, de2020anomalies}. 

%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\subsection{Psychosis and Formal Thought Disorder}

Formal thought disorder is a set of specific disturbances in thought, speech, and communication that is typical of psychosis \citep{hart2017rethinking}. The symptoms of thought disorder can be divided into positive (or psychotic) and negative. 

In general, positive symptoms are the symptoms that are not experienced normally but are typically present during a psychotic episode. These include delusions, hallucinations, and disorganized thoughts and speech. Positive thought disorder is the respective subset of FTD that includes positive speech and though symptoms such as \textit{incoherence}, \textit{tangentiality}, \textit{circumstantiality}, and \textit{peculiar word use}. 

Negative symptoms are the symptoms that manifest deficits of emotional responses or thought processes. Negative thought disorder includes negative speech and though symptoms of FTD, such as \textit{poverty of speech and speech content}, \textit{blocking}, and \textit{perseveration}.

The positive and negative symptoms that are typical of psychotic disorders are usually assessed with positive and negative syndrome scale (PANSS \cite{kay1987positive}) or using the two scales for the assessment of positive and negative symptoms (SAPS and SANS, \cite{andreasen1984saps, andreasen1984sans}). While PANSS only identifies the language-specific disturbances very broadly (using \textit{conceptual disorganization} for all positive speech disturbances and \textit{lack of spontaneity and flow of conversation} and \textit{stereotyped thinking} for the negative ones), SAPS and SANS include detailed subscales to assess the most common positive and negative anomalies of speech and thought typical of positive and negative FTD. 

Formal thought disorder conceptualisation of speech and thought anomalies observed in psychosis is often used as the guiding principle for developing automated psychosis detection tools.  

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------

\subsection{Conceptualizations of Incoherent Language}

There is no unified linguistic theory to encompass all the features that contribute to coherence. Defining incoherence as `speech that is essentially incomprehensible at times', \citet{andreasen1986tlc} states that incoherence may arise through `several different mechanisms, which may sometimes all occur simultaneously'. This is because coherence is normally maintained simultaneously on many levels, including lexical connectors, syntactic structure, intonation, reference, and logical structure of a text. As a result, different researches rely on different conceptualizations when they develop automated psychosis detection tools. 

Some researchers rely on broad logistic conceptualizations, such as \textit{global coherence} defined as  the relationship of every clause to the overall topic of the text \citep{glosser1991patterns}, \textit{local coherence} defined as  similarity in content and logical connectedness of adjacent sentences, or \textit{cohesion} which encompasses grammatical and lexical linking within a text that holds it together. 

Others use the scales aimed at measuring formal thought disorder as a source of conceptualization. There is a number of scales that aim at identifying different features of formal thought disorder: including TLC\footnote{Thought Language and Communication scale \citet{andreasen1986tlc}}, SANS \& SAPS\footnote{\citep{andreasen1984sans, andreasen1984saps}}, TLI\footnote{Thought and Language Index, \citet{liddle2002tli}}, TALD\footnote{Thought and Language Disorder Scale, \citet{kircher2014tald}}, and K-FTDS\footnote{Kiddie Formal Thought Disorder Rating Scale, \citet{caplan1989kftds}}. There are several linguistic features that are underlined in all of these scales and are commonly used in automated psychosis detection research, which I discuss below. 

Commonly used positive FTD features in these scales include many features indicating some form of inability to stay on topic. It may come in the form of being distracted by nearby stimuli interrupting the flow of speech (\textit{distractible speech}); in the form of ideas slipping off track onto ideas obliquely related or unrelated (\textit{derailment} also indicated by \textit{loosening of associations} and \textit{flight of ideas}); or in the form replying to a question in an oblique or irrelevant manner (\textit{tangentiality}). Additionally, the inability of staying on topic can take the form of \textit{circumstatiality}, where speech is very indirect and delayed in reaching its goal idea. The disconnectedness between speech fragments may take the form of \textit{illogicality}, where the the conclusions are reached that do not follow logically from the premises, or \textit{incoherence}, indicating speech that is essentially incomprehensible at times and may manifest in its severest form as schizophasia. Incoherence may stem from syntactic or grammatical errors, semantically unmotivated word choices, and lack of proper cohesion devices, such as coordinating and subordinating conjunctions or coreferences. Additionally, the rate and amount of speech might be increased, which is referred to as \textit{pressured speech}. Some of the common positive FTD features also emphasize peculiar word choice, manifesting as incorrect or unconventional word use and phonetic associations (\textit{paraphasias}), as well as invention of new words (\textit{neologisms}).

Commonly used negative FTD features in these scales include general \textit{poverty of speech}, which indicates decreased amount and rate of speech, brevity, low verbosity; \textit{poverty of speech content} referring to vague, over concrete or over generalized speech, conveying little information\footnote{Both poverty of speech and poverty of content may be sometimes referred to as \textit{alogia}.}; and inability to reach the goal, which may be a result of sudden interruption (\textit{blocking}) or slow drift  (\textit{loss of goal}). The patients may also have a tendency to repeat ideas or words over and over, which is referred to \textit{perseveration} or \textit{verbigeration}.

Finally, some researchers test a broad variety of linguistic features to identify the ones that might help detect psychosis without referring to any pre-existing theories regarding these features.

It is not entirely clear whether negative or positive FTD aspects of language can serve as a more robust basis for NLP approximation. In the present work we set out to analyze the most commonly utilized features regardless of their conceptualization.

% To this date, there is no universal set of guidelines for identifying disordered speech. Various existing techniques of quantifying speech incoherence are quite subjective, as they rely on the judgment and experience of an individual psychiatrist. “Disorganized speech” as a symptom lacks linguistic insight (Cohen et al., 2017), as this terminology fails to reflect the fact that language has multiple interdependent levels of organization (phonetics, morphology, syntax, discourse, pragmatics, and interactional markers).


%-----------------------------------
%	SUBSECTION 3
%-----------------------------------
\subsection{Theories of Incoherence in Psychosis}

There are two main types of theoretical frameworks explaining the origins of discourse incoherence observed in schizophrenia: executive dysfunction theories (also known as impaired cognition theories); and loose association theories (see \cite{ditman2010building} for a review). The former theories state that the lack of control over the process of thinking is typical of negative thought disorder is the driving reason for the observed incoherence of speech in FTD. The latter, on the other hand, explain the incoherence in terms of tangentiality and loose associations that are characteristic of positive thought disorder. However, there is no definitive evidence for either theory being the main cause for the speech incoherence seen in schizophrenia spectrum disorders. Moreover, aspects of both positive and negative formal thought disorder may be contributing to incoherence in any given patient. The lack of clear evidence for either theory is partially due to the inter-dependency between processes involved in speech production, partially due to the multiplicity of processes reflected in speech, and partially to the impossibility of separating meaning from its context \citep{cohen2017can}. Interestingly, there is modelling evidence for different NLP methods being more sensitive to different aspects of FTD. This could be regraded as indirect evidence for both mechanisms contributing to the incoherence that is typical of psychosis \citep{fradkin2023theory}.


%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------

\section{Natural Language Processing for Psychosis Detection}

Natural language processing includes a large array of automated methods and tools for working with various aspects of language. Utilizing these tools for psychosis detection has been pioneered by \citet{elvevaag2007quantifying} and a large variety of metrics has been developed since, though reproducibility remained limited \citep{hitczenko2021understanding, parola2022speech, fradkin2023theory}. Under psychosis detection I understand a variety of tasks including the ones trying to distinguish between healthy controls and patients with a psychotic disorder, the ones trying to predict conversion in populations at high risk for psychosis, and the ones predicting the differences in symptom prevalence or severity between patients. Natural language processing approaches to psychosis detection were suggested as a potentially fast, sensitive, and objective solution to psychosis detection and symptom assessment. However, such approaches must be applied with great caution, as  prognostic assessment may significantly affect or even stigmatize the patients and that the results may be sensitive to may external factors \citep{just2023validation}, which is further discussed in section \ref{sec:intro:validity}.
% However, the clinical relevance and therapeutic value of NLP methods in psychiatry still needs to be proven – especially against the background that a prognostic assessment may significantly affect or even stigmatize individuals (22) and that patients may be triggered by stressful situations including clinical settings (23).

Below, I introduce several the groups of natural language processing methods that have been applied to the task of psychosis detection. The methods are grouped according to the type of linguistic material they operate into lexical, syntactic, and semantic. The metrics are discussed in greater detail in section \ref{chap:2:review}. Note, that this work is mostly concerned with the linguistic features that occur both in written and spoken texts, leaving the acoustic\footnote{Acoustic features, such as spectral, frequency, and amplitude parameters were explored in \citet{voppel2023semantic, tang2023latent, de2023acoustic, wouts2021belabbert}.} and temporal\footnote{Such temporal features as speech rate and pausation patterns were used by \citet{aich2022towards, liebenthal2022linguistic, de2023acoustic, tang2023latent} to distinguish between patients and controls as well as predict symptoms as assessed by psychiatric scales.} features outside of the scope of the present work. 
% , as well as discourse\footnote{Such features as false-starts, self-repairs, repetitions, as well as hesitation pauses have been used successfully to detect psychosis, psychotic symptoms, or social cognition in psychotic patients \citep{vail2018toward, liebenthal2022linguistic, girard2022computational, tang2022clinical, tang2023latent}.}

%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\subsection{Lexical Methods}

Under lexical methods I include all the methods that operate over words and focus on word use. These include \textit{verbosity} or word count; \textit{lexical diversity} metrics, such as type token ratio (TTR) or average word frequency; \textit{sentiment analysis} metrics, such as use of negative or positive emotion words; and \textit{topic analysis}, usually assessed with a specified tool based on dictionaries or latent content analysis. The tools used for lexical analysis often incorporate a variety of word-based metrics, \href{https://www.liwc.app} {LIWC} having 72 metrics \citep{tausczik2010psychological}, \href{https://www.linguisticanalysistools.org/taaco.html}{TAACO} - 34 \citep{crossley2019tool}, and \href{http://cohmetrix.memphis.edu/cohmetrixhome/documentation_indices.html}{Coh-Metrix L3} - 108 \citep{mcnamara2014automated}. 

The lexical methods may aim at capturing both to positive and negative FTD features. Verbosity may be increased (pressure of speech) or decreased (poverty of speech). Lexical diversity and density may be increased (paraphasias) or decreased (poverty of speech and content). Sentiment analysis may reveal the blunted affect which is a typical non-linguistic negative symptom of schizophrenia. Finally, topic analysis may reveal common semantic features shared between different patients which may be related to both negative and positive symptoms.

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------
\subsection{Syntactic Methods}

Under syntactic methods I include methods relating to syntactic types and syntactic structures. These include \textit{part-of-speech} based metrics; \textit{referential} metrics, such as the use of ambiguous pronouns and cataphora\footnote{Cataphora is the use of the referential phrase that refers to or stands for a later word or phrase as in ``If you want \textit{them}, there are \textit{cookies} in the kitchen''.}; measures of \textit{syntactic complexity} calculated based on use of various syntactic structures such as coordinated or subordinated clauses as well as the use of negation or passive and active voice; and the \textit{lengths and counts} of various syntactic units, such as clauses and sentences.

The differences in the distributions of the parts of speech commonly indicate lowered syntactic complexity, which may be connected to negative FTD (poverty of speech), and lowered use of descriptive words (adjectives and adverbs) and lowered use of referential devices, which can be regarded as indicative of poverty of content %\citep{corcoran2018prediction, bar2019semantic, tang2021natural, ziv2022morphological}. 
Similarly, reduced syntactic complexity may be indicative of poverty of speech or speech content. On the other hand, ambiguous pronouns may be one of the driving forces behind perceived incoherence or be caused by loosening of associations, typical of positive FTD.

%-----------------------------------
%	SUBSECTION 3
%-----------------------------------
\subsection{Semantic Methods}
Under semantic methods I include methods operating on the level of the entire text and trying to assess some of its properties based on its meaning. The semantic methods can be further divided into the graph-based methods and the ones that use language models (LMs) to represent the text.


\subsubsection{Graph-Based Methods}
Graph-based methods include all the methods that represent a text with a graph and subsequently calculate properties of the graph, such as size or some measure of connectivity. The graph representations can be based on the \textit{co-occurrence} of words in the text, words being the nodes of the graph and neighbouring words being connected by a directed edge. Alternatively, the graphs may be based on a \textit{semantic} representation of the text, which can be obtained with semantic role labelling tools (SRL, \cite{gildea2002automatic}). 

% The graphs can also be built at the level of sentences rather than words, as in Rhetorical Structure Theory (RST, \cite{mann1988rhetorical}) and the distribution of edge types may be used as a predictive feature.

Reduced graph connectivity is typically regarded as indicative of positive FTD symptoms such as incoherence or derailment and flight of ideas, as if very little is said on any given topic it would result in a largely disconnected graph. On the other hand, very high connectivity may be indicative of negative FTD symptoms of poverty of speech content or perseveration.

\subsubsection{Language Model-Based Methods}
Language model-based methods use pre-trained models to represent the texts. Language models (LMs) are computational models that approximate probability distributions over sequences of linguistic units. They are usually trained on large corpora and they can learn the semantics and some syntactic features of the texts based on the co-occurrence of the words and sentences in the corpus. These models can be used to represent words or sentences with vectors which are called \textit{embeddings} and which encode the properties learnt by the model. The embeddings can be divided into \textit{non-contextualized} which operate like dictionaries of words to vectors and \textit{contextualized} that let the context in which a word appears influence the embedding vector, allowing for disambiguation and better handling of unseen words. Non-contextual embeddings include representations obtained from n-grams, latent semantic analysis (LSA, \citet{landauer1998introduction}), word2vec (w2v, \citet{mikolov2013distributed}), GloVe \citep{pennington2014glove} for word representation and sent2vec \citep{moghadasi2020sent2vec} for sentence representation. Contextualized embeddings can be obtained from BiLSTM and ELMo \citep{peters2017semi}, BERT \citep{devlin2018bert}, RoBERTa \citep{liu2019roberta} and other transformer-based models \citep{vaswani2017attention, openai2023gpt4}.

There are several ways in which language models can be applied to psychosis detection. First, there are \textit{embedding-based metrics} that represent words or sentences with vectors using an LM and then calculate some metric over the vectors, usually based on cosine similarity of these vectors. These include similarity of consecutive units, similarity of units at a fixed distance, similarity of a given unit to some standard unit, and the slope of difference of units from the question or initial prompt. Secondly, the LMs can provide some measure of \textit{text predictability} such as perplexity or probability from BERT next sentence prediction. Finally, the LMs can be \textit{fine-tuned} to be used as \textit{classifiers} for psychosis detection or symptom severity assessment. The embeddings can also be used as the input to a simple classifier, which I will refer to as \textit{non-fine-tuned classifiers}.

The similarity-based metrics typically try to capture positive FTD symptoms such as incoherence or derailment as well as tangentiality. Lowered text predictability may also be seen as indicative of incoherence or derailment while higher values may indicate of negative symptoms such as perseveration and poverty of speech content.

%----------------------------------------------------------------------------------------
%	SECTION 3
%----------------------------------------------------------------------------------------


\section{Theoretical Validity of NLP Approaches \\ to Psychosis Detection}
\label{sec:intro:validity}

In psychology, \textit{internal} validity examines whether a study answers the research questions without bias and \textit{external} validity examines whether the study findings can be generalized to other contexts \citep{andrade2018internal}. Applying these definitions to the context at hand, the internal validity of a given metric is only defined if the metric is trying to approximate some psychiatric or linguistic concept. A metric would be internally valid if it successfully approximates the concept, such as coherence or poverty of speech (\textit{construct} validity); and is not biased by any known confounding factors. The external validity of a metric would refer to the ability of the metric to be applied in a variety of contexts, including cross-linguistic applicability (\ref{sec:intro:cross-linguitic-applicability}) as well as such external factors as sensitivity to the choice of pre-processing, embedding model, and elicitation task (\ref{sec:intro:external-validity}).

%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\subsection{Internal Validity}
\label{sec:intro:internal-validity}

In order to apply the NLP derived metrics to clinical settings, it is important to assess the internal validity of the metrics that rely on the psychiatric or linguistic conceptualizations mentioned above. This could be achieved by correlating the metrics with human ratings, as suggested in the foundational study \citet{elvevaag2007quantifying}, or with the respective TLI, TLC, TALD, or SANS \& SAPS subscales (see \citet{bilgrami2022construct} for construct validity exploration). Additionally, it is important to assess if the metric is associated with positive or negative FTD as would be expected based on the conceptualization. This could be achieved by measuring positive and negative symptoms in general using PANSS, as done in most % 45/62
studies in the field, or using the aforementioned thought disorder scales. Though many studies use some of the thought disorder scales %17/62
, few correlate the metrics with the TD subscales. While some studies report correlation with the expected subscales (e.g. \citet{vail2018toward, just2020modeling, jeong2023exploring}), many fail to find such relations (e.g. \citet{bedi2015automated, corcoran2018prediction, iter2018automatic, hitczenko2021understanding}). In fact, several reviews point out that the relations between psychiatric constructs of language disturbances and the metrics might not be straightforward \citep{cohen2017can, holmlund2022towards}.

As for confounding factors, many of the proposed metrics are known to be sensitive to such factors as sentence or text \textit{length}\footnote{ \citet{elvevaag2007quantifying, mota2014graph, iter2018automatic, corcoran2018prediction, hitczenko2021understanding, parola2022speech, jeong2023exploring}}, \textit{repetitions}\footnote{\citet{elvevaag2007quantifying, iter2018automatic, just2019coherence}}, and \textit{preprocessing} (including punctuation and removal of verbal fillers\footnote{\citet{parola2022speech, holmlund2022towards}}). Such dependencies stem naturally from the definitions of some of the LM-based and graph-based metrics. For example, cosine similarity-based metrics yield higher results on more repetitive texts and on longer sentences. Surprisal or perplexity is also known to be higher on longer sentences. The number of nodes in graph-based metrics is closely related to the total number of words. As for preprocessing, any metric that relies on sentence boundaries is reliant on human annotator's decisions if the original text is spoken rather than written. All these factors are quite problematic in the context of psychosis detection. Patients with SSD are commonly reported to be less verbose, producing significantly fewer words in most studies, and often produce significantly shorter sentences. The repetitiveness which may be indicative of schizophrenia (perseveration) could artificially drive the cosine-similarity metrics up. The verbal filler production may also be altered in some SSD patients introducing a problematic preprocessing dependence. 

% PREPROCESSING (PAROLA et al 2022) We found no differences in the Danish corpus: results were robust to changes in the cleaning options. Instead, we found differences in the German corpus once we changed the cleaning options. In particular, including punctuations and fillers in the analysis, we found that the differences between patients with schizophrenia and controls in some coherence measures (Coherence 10, Coherence-k, Second-order coherence) varied. For the Chinese corpus, we found some variation in the Coherence-k and Second-order coherence when including punctuations and fillers in the analysis, but results were generally robust to changes in the cleaning options. Overall, these results show how NLP measures of coherence, and in particular cosine similarity derived measures, are sensitive to fillers and punctuations, and how these components can introduce bias in the analysis. As for transcript length, in line with previous literature (Elvevag et al., 2007; Iter et al., 2018; Corcoran et al., 2018; Hitczenko et al., 2022), we found that transcript length is positively associated with the various coherence measures, that is longer transcripts have generally higher coherence values. This confirms that the impact of transcript length should be controlled in the analysis in order to avoid possible bias in the results. 


Some metrics might also not be sensitive to features that they should presumably be sensitive to, such as word or sentence shuffling or word replacement. There are studies that explore artificial perturbations and language modelling as a way of testing construct validity of LM-based metrics assessed using correlation with manual scores \citep{fradkin2023theory} or test for differences introduced by perturbations of control texts \citep{bedi2015automated, hitczenko2021understanding}.
% bedi sent shuffling
% hitzenko effects of length

A notable indication for the lack of construct validity for some of the metrics is the fact that the interpretation cannot be linear. While high scores along psychiatric dimensions of tangentiality or incoherence always indicate abnormality, the metrics might have `optimal' values, where both low and high values outside this range could be considered abnormal \citep{fradkin2023theory}. For example, very low perplexity would indicate repetitive or stereotyped speech and very high perplexity would indicate incoherence or word salad. Conversely, very low cosine similarity metric scores would indicate incoherence and very high scores would indicate high repetitiveness. Thus, unlike psychiatric scales, both high and low metric scores may indicate abnormality.

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------
\subsection{External Validity}
\label{sec:intro:external-validity}

The assessment of external validity of most metrics is limited by the diagnostic and design dissimilarities in the studies that report contradictory results for a given metric. 

First of all, the dissimilarities may concern the populations of the study. The studies may investigate in- or out-patients, patients with or without TD, with prevailing positive or negative symptoms. The diagnostic categories used also vary form one diagnosis (like schizophrenia), to broader diagnostic categories such as schizophrenia spectrum disorder or non-affective psychosis\footnote{Includes schizophrenia (SZ), schizoaffective disorder (SZA), schizophreniform disorder (SFD),  and schizotypal disorder (SD).} and psychotic disorders\footnote{Additionally includes the affective disorders with psychotic symptoms, such as some manifestations of bipolar disorder (BD)}. Additionally, some studies explore patients at high risk for psychotic disorders\footnote{\cite{bedi2015automated, rosenstein2015language, corcoran2018prediction, gupta2018automated, rezaii2019machine, haas2020linking, hitczenko2021understanding, bilgrami2022construct}} or healthy relatives \citep{elvevaag2010automated}. The proportion of female patients, as well as average age, racial identity, education and income level may also vary greatly from study to study, and some of the metrics are known to be sensitive to such factors \citep{hitczenko2021understanding, palaniyappan2021more, minor2023automated}.

The study design may vary with respect to elicitation tasks used to obtain speech samples, with some studies using spoken and some written discourse, some utilizing monologue and some dialogue, some obtaining very short and some very long speech samples. The speech may also be structured or unstructured, connected to some topic or not. The most typical tasks include picture description tasks and semi-structured interviews yet the differences stemming from the elicitation tasks can be observed in most studies using several tasks \footnote{Such task dependence is observed in many studies including \cite{elvevaag2007quantifying, mota2016quantifying, mota2017thought, just2019coherence, ryazanskaya2020thesis}.}.

The psychosis detection tasks used in the study may include tests identifying group differences between patients and controls, correlation with symptom severity, or predictive models for either of these tasks. The studies with clinical high risk populations also often feature prediction of conversion, and longitudinal studies try to predict prognosis or longitudinal symptom severity.

Finally, the studies also differ with respect to the suite of metrics applied in the study, including choice of embedding models, as well as the choice of preprocessing, such as transcription protocols, punctuation, filler and stopword removal. Some of the differences observed in the studies may also stem from cross-linguistic differences or differences in the availability and quality of NLP tools.

It is worth noting, that even the models that do not aim at approximating any psychiatric construct and simply try to identify group differences or predict symptom severity are subject to external validity limitations. As the datasets in the field are typically small\footnote{Mode - 59 patients and 44 controls, mean - 20 patients and 21 controls.} %\textcolor{red}{59 patients 44 controls} 
and the study designs really diverse, the trained classifiers are likely to be inapplicable to any other study or setting. Such models lack transferability limiting their practical value and could also lack interpretability, requiring additional analysis for any theoretical value. 

%-----------------------------------
%	SUBSECTION 3
%-----------------------------------
\subsection{Cross-Linguistic Applicability}
\label{sec:intro:cross-linguitic-applicability}

Another important consideration when it comes to external validity is cross linguistic applicability of the proposed methods. 

First of all, there are ways in which some methods are inherently inapplicable to some languages. For example, while the use of determiners has been used as an indicator in many papers analyzing English (e.g. \cite{bedi2015automated, tang2021natural, bilgrami2022construct}), Polish does not have a clearly defined category of determiners and thus this metric may be inapplicable \citep{sarzynska2021detecting}. Similarly, the frequency of use of some part of speech present in both languages or some construction, such as cataphora, may differ between the languages, making a metric useful in one language practically inapplicable in the other. Incoherence may manifest differently in different languages, and what would be incoherent in one language may be more or less normal in another.

Secondly, there are some limitations imposed by the tools used for natural language processing. Many methods that may be applicable across languages, would require that the tools that calculate them are translated for every new language which is time-consuming and in many cases practically infeasible. There are some tools that are indeed translated, such as LIWC which is translated into 15 languages. However, it is also not a free open-source tool, which is also a limiting factor. There are also methods that are applicable across languages, but might be influenced by the training resources available for a give language. This is especially important for LM-based metrics, as LM performance is closely linked to the size of the training dataset (\cite{kaplan2020scaling}). It is crucial to take into account these limitations when applying the NLP methods of psychosis detection cross-linguistically.

Recently, many studies applied the NLP-based methods of psychosis detection to a variety of languages including Chinese\footnote{\cite{parola2022speech}}, Danish\footnote{\cite{parola2022speech}}, Dutch\footnote{\cite{dore2019quantification, voppel2021quantified, wouts2021belabbert, corona2022assessing, voppel2023semantic, de2023acoustic}}, German\footnote{\cite{koranova2017analyzing, just2019coherence, just2020modeling, parola2022speech, schneider2023syntactic}}, Hebrew\footnote{\cite{bar2019semantic, ziv2022morphological, shriki2022masking}}, Polish\footnote{\cite{sarzynska2021detecting}}, Portuguese\footnote{\cite{mota2014graph, mota2017thought, mota2022happy, argolo2023burnishing}}, Russian\footnote{\cite{panicheva2019semantic, panicheva2020corpus, ryazanskaya2020automated}}, and Spanish\footnote{\cite{palominos2023coreference}}. Despite that, the vast majority of metrics were developed and tested for English, and the results for other languages are often mixed, negative, or even contradictory to the findings for English \citep{koranova2017analyzing, bar2019semantic, panicheva2019semantic, dore2019quantification, parola2022speech}. 

I believe it is important to aim for cross-linguistically applicable NLP methods of psychosis detection, as well as to thoroughly test cross-linguistic applicability of existent methods, keeping in mind the robustness with respect to resource availability and training corpora size for various languages.

I believe it is also important to aim for metrics that would be both interpretable, internally valid, and transferable to settings other than the original. That is, the metrics should approximate a meaningful concept, should correlated with human judgements of the approximated concept, and should be independent of or corrected for known linguistic confounding factors. To achieve this goal, the proposed metrics must be validated with respect to psychiatric scales, theoretical assumptions, known confounding factors, and  transferability potential.


%----------------------------------------------------------------------------------------
%	SECTION 4
%----------------------------------------------------------------------------------------

\section{Motivation}

\textcolor{red}{The goal of the present work is to compare some of the most frequently used methods across the groups described above as a way of bench-marking them on a psychotic speech sample. Moreover, this work aims at theoretical validation of some of these methods on a healthy corpus, prioritizing the metrics that can potentially be applied cross-linguistically and cross-methodologically. The planned theoretical validation will assess several distributional aspects of the selected metrics on a control corpus. First, how the size of the difference between the groups compares to normal variance in the metric on a comparable sample size. Second, how the length of text affects the variance in metrics, indicating what amount of material may be sufficient for robust assessment . Finally, how length of sentence or utterance affects the metrics, as some of the metrics were reported to be strongly dependent on this confounding factor. Together, this may shed some light on the relative robustness and methodological validity of the tested metrics.}


% --- lexical --- 
% MATTR & LTR
% # words

% --- syntactic --- 
% POS: 
% - determiners and wh-words
% - adj 
% - adv
% - verb 
% - noun
% - pronoun
% sentence length
% sentence count

% --- graph ---
% ? # nodes in LSC
% ? # nodes in LCC
% ? # nodes
% ? # edges
% ? LSCz
% ? LCCz
% ? density
% ? diameter
% ? ASP


% --- LM - w2v + IDF & BERT --- 
% coherence 
% SOC
% centroid global & cumulative global coherence
% ? average window coherence
% ? adjacent word similarity

% ? perplexity
% ? next-sentence prediction 

% mean